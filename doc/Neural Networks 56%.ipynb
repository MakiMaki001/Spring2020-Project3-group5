{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%run ../lib/load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.205993890762329 seconds ---\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/zhaoziqin/Desktop/train_set/'\n",
    "data = load.load_data(path+'label.csv')\n",
    "points_path = '/Users/zhaoziqin/Desktop/train_set/points/'\n",
    "X = load.load_points(points_path,data)\n",
    "y= data['emotion_idx'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 6006)\n",
      "(500, 6006)\n",
      "(2000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learningï¼šNeural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set predictors\n",
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(y)\n",
    "Y = Y[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Input,Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization()(input_layer) \n",
    "x = Dense(96,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(16,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=None))(x) \n",
    "model = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 3.4637 - accuracy: 0.0610 - val_loss: 67.7700 - val_accuracy: 0.0420\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 542us/step - loss: 3.1020 - accuracy: 0.0725 - val_loss: 4.7246 - val_accuracy: 0.0640\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 3.0335 - accuracy: 0.0900 - val_loss: 3.7354 - val_accuracy: 0.0360\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 2.9648 - accuracy: 0.1060 - val_loss: 4.2387 - val_accuracy: 0.0360\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 519us/step - loss: 2.8940 - accuracy: 0.1175 - val_loss: 2.9861 - val_accuracy: 0.0440\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 2.8024 - accuracy: 0.1345 - val_loss: 2.9994 - val_accuracy: 0.0780\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 2.7490 - accuracy: 0.1435 - val_loss: 3.0311 - val_accuracy: 0.0680\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 654us/step - loss: 2.6742 - accuracy: 0.1605 - val_loss: 2.9439 - val_accuracy: 0.1120\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 2.6015 - accuracy: 0.1695 - val_loss: 2.6577 - val_accuracy: 0.2040\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 2.5348 - accuracy: 0.1860 - val_loss: 2.5487 - val_accuracy: 0.2100\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 2.4404 - accuracy: 0.2095 - val_loss: 2.5220 - val_accuracy: 0.2060\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 2.4129 - accuracy: 0.2010 - val_loss: 2.3996 - val_accuracy: 0.1920\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 2.3603 - accuracy: 0.2010 - val_loss: 2.2322 - val_accuracy: 0.2460\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 2.3152 - accuracy: 0.2220 - val_loss: 2.1543 - val_accuracy: 0.2520\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 2.2850 - accuracy: 0.2165 - val_loss: 2.1287 - val_accuracy: 0.2460\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 2.2501 - accuracy: 0.2175 - val_loss: 2.0497 - val_accuracy: 0.2800\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 720us/step - loss: 2.1790 - accuracy: 0.2580 - val_loss: 1.9650 - val_accuracy: 0.3080\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 2s 759us/step - loss: 2.1971 - accuracy: 0.2430 - val_loss: 1.9172 - val_accuracy: 0.3200\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 2.1125 - accuracy: 0.2665 - val_loss: 1.9061 - val_accuracy: 0.3280\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 501us/step - loss: 2.1130 - accuracy: 0.2610 - val_loss: 1.9339 - val_accuracy: 0.3200\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 491us/step - loss: 2.1111 - accuracy: 0.2705 - val_loss: 1.8771 - val_accuracy: 0.3560\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 2.0615 - accuracy: 0.2850 - val_loss: 1.8734 - val_accuracy: 0.3320\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 497us/step - loss: 2.0378 - accuracy: 0.2850 - val_loss: 1.8305 - val_accuracy: 0.3580\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 2.0187 - accuracy: 0.2890 - val_loss: 1.7826 - val_accuracy: 0.3880\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 691us/step - loss: 1.9872 - accuracy: 0.2950 - val_loss: 1.7968 - val_accuracy: 0.3840\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 2.0083 - accuracy: 0.2940 - val_loss: 1.7683 - val_accuracy: 0.3780\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.9583 - accuracy: 0.3040 - val_loss: 1.8175 - val_accuracy: 0.3820\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.9706 - accuracy: 0.3120 - val_loss: 1.7439 - val_accuracy: 0.3720\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.9587 - accuracy: 0.3050 - val_loss: 1.7075 - val_accuracy: 0.3840\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 515us/step - loss: 1.9237 - accuracy: 0.3100 - val_loss: 1.7068 - val_accuracy: 0.3960\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 550us/step - loss: 1.9270 - accuracy: 0.3235 - val_loss: 1.6868 - val_accuracy: 0.4340\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.8949 - accuracy: 0.3270 - val_loss: 1.6485 - val_accuracy: 0.4420\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.8295 - accuracy: 0.3425 - val_loss: 1.6704 - val_accuracy: 0.4040\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.8619 - accuracy: 0.3175 - val_loss: 1.6551 - val_accuracy: 0.4100\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.8519 - accuracy: 0.3405 - val_loss: 1.6482 - val_accuracy: 0.4080\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 733us/step - loss: 1.8548 - accuracy: 0.3315 - val_loss: 1.6261 - val_accuracy: 0.4140\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 2s 805us/step - loss: 1.8635 - accuracy: 0.3095 - val_loss: 1.6303 - val_accuracy: 0.4160\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 593us/step - loss: 1.8395 - accuracy: 0.3350 - val_loss: 1.6257 - val_accuracy: 0.4040\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 552us/step - loss: 1.8230 - accuracy: 0.3330 - val_loss: 1.6257 - val_accuracy: 0.4200\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.7885 - accuracy: 0.3390 - val_loss: 1.6059 - val_accuracy: 0.4100\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.7908 - accuracy: 0.3555 - val_loss: 1.5864 - val_accuracy: 0.4100\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.7630 - accuracy: 0.3470 - val_loss: 1.5704 - val_accuracy: 0.4180\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.7620 - accuracy: 0.3465 - val_loss: 1.5602 - val_accuracy: 0.4300\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 643us/step - loss: 1.7722 - accuracy: 0.3410 - val_loss: 1.5591 - val_accuracy: 0.4160\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 663us/step - loss: 1.7516 - accuracy: 0.3575 - val_loss: 1.5465 - val_accuracy: 0.4360\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 511us/step - loss: 1.7436 - accuracy: 0.3585 - val_loss: 1.5576 - val_accuracy: 0.4440\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 502us/step - loss: 1.7213 - accuracy: 0.3640 - val_loss: 1.5666 - val_accuracy: 0.4160\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 504us/step - loss: 1.6808 - accuracy: 0.3670 - val_loss: 1.5467 - val_accuracy: 0.4240\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.7051 - accuracy: 0.3740 - val_loss: 1.5494 - val_accuracy: 0.4220\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 509us/step - loss: 1.6795 - accuracy: 0.3605 - val_loss: 1.5307 - val_accuracy: 0.4360\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.6913 - accuracy: 0.3755 - val_loss: 1.5106 - val_accuracy: 0.4640\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 580us/step - loss: 1.6497 - accuracy: 0.3960 - val_loss: 1.5050 - val_accuracy: 0.4560\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.6219 - accuracy: 0.3925 - val_loss: 1.4977 - val_accuracy: 0.4540\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.6388 - accuracy: 0.4030 - val_loss: 1.4959 - val_accuracy: 0.4520\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.6489 - accuracy: 0.3950 - val_loss: 1.4938 - val_accuracy: 0.4580\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.5729 - accuracy: 0.4135 - val_loss: 1.4921 - val_accuracy: 0.4620\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 2s 769us/step - loss: 1.6267 - accuracy: 0.4060 - val_loss: 1.4880 - val_accuracy: 0.4640\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 547us/step - loss: 1.5889 - accuracy: 0.4140 - val_loss: 1.4904 - val_accuracy: 0.4580\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 506us/step - loss: 1.6329 - accuracy: 0.4035 - val_loss: 1.4925 - val_accuracy: 0.4600\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.6006 - accuracy: 0.3920 - val_loss: 1.4884 - val_accuracy: 0.4500\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.5788 - accuracy: 0.4125 - val_loss: 1.4867 - val_accuracy: 0.4460\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 684us/step - loss: 1.5866 - accuracy: 0.4035 - val_loss: 1.4864 - val_accuracy: 0.4540\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 1.5774 - accuracy: 0.4055 - val_loss: 1.4882 - val_accuracy: 0.4500\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 713us/step - loss: 1.5660 - accuracy: 0.4155 - val_loss: 1.4908 - val_accuracy: 0.4540\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 507us/step - loss: 1.5656 - accuracy: 0.4115 - val_loss: 1.4913 - val_accuracy: 0.4540\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 508us/step - loss: 1.5534 - accuracy: 0.4345 - val_loss: 1.4905 - val_accuracy: 0.4580\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 503us/step - loss: 1.5655 - accuracy: 0.4235 - val_loss: 1.4865 - val_accuracy: 0.4520\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.5792 - accuracy: 0.4245 - val_loss: 1.4843 - val_accuracy: 0.4620\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.5826 - accuracy: 0.4115 - val_loss: 1.4844 - val_accuracy: 0.4640\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 509us/step - loss: 1.5458 - accuracy: 0.4180 - val_loss: 1.4859 - val_accuracy: 0.4560\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 1.5457 - accuracy: 0.4185 - val_loss: 1.4856 - val_accuracy: 0.4540\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 2s 776us/step - loss: 1.5538 - accuracy: 0.4115 - val_loss: 1.4785 - val_accuracy: 0.4520\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 608us/step - loss: 1.5261 - accuracy: 0.4435 - val_loss: 1.4732 - val_accuracy: 0.4640\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 580us/step - loss: 1.5265 - accuracy: 0.4270 - val_loss: 1.4690 - val_accuracy: 0.4680\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 616us/step - loss: 1.5263 - accuracy: 0.4150 - val_loss: 1.4655 - val_accuracy: 0.4680\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.5136 - accuracy: 0.4415 - val_loss: 1.4644 - val_accuracy: 0.4760\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 687us/step - loss: 1.4838 - accuracy: 0.4420 - val_loss: 1.4713 - val_accuracy: 0.4660\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.4913 - accuracy: 0.4440 - val_loss: 1.4759 - val_accuracy: 0.4660\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.5152 - accuracy: 0.4425 - val_loss: 1.4744 - val_accuracy: 0.4680\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 711us/step - loss: 1.5155 - accuracy: 0.4370 - val_loss: 1.4767 - val_accuracy: 0.4720\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 669us/step - loss: 1.5520 - accuracy: 0.4360 - val_loss: 1.4799 - val_accuracy: 0.4500\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 748us/step - loss: 1.5068 - accuracy: 0.4510 - val_loss: 1.4823 - val_accuracy: 0.4540\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 2s 821us/step - loss: 1.5008 - accuracy: 0.4350 - val_loss: 1.4793 - val_accuracy: 0.4520\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 549us/step - loss: 1.5325 - accuracy: 0.4300 - val_loss: 1.4771 - val_accuracy: 0.4560\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 505us/step - loss: 1.4879 - accuracy: 0.4450 - val_loss: 1.4824 - val_accuracy: 0.4480\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 690us/step - loss: 1.5010 - accuracy: 0.4555 - val_loss: 1.4839 - val_accuracy: 0.4560\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.4922 - accuracy: 0.4305 - val_loss: 1.4850 - val_accuracy: 0.4520\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 642us/step - loss: 1.4666 - accuracy: 0.4435 - val_loss: 1.4839 - val_accuracy: 0.4660\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 742us/step - loss: 1.5099 - accuracy: 0.4685 - val_loss: 1.4826 - val_accuracy: 0.4720\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 698us/step - loss: 1.4989 - accuracy: 0.4240 - val_loss: 1.4848 - val_accuracy: 0.4740\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 641us/step - loss: 1.4877 - accuracy: 0.4460 - val_loss: 1.4773 - val_accuracy: 0.4720\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 2s 767us/step - loss: 1.5076 - accuracy: 0.4445 - val_loss: 1.4752 - val_accuracy: 0.4680\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 720us/step - loss: 1.4762 - accuracy: 0.4470 - val_loss: 1.4779 - val_accuracy: 0.4680\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 689us/step - loss: 1.4376 - accuracy: 0.4625 - val_loss: 1.4804 - val_accuracy: 0.4700\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 704us/step - loss: 1.4990 - accuracy: 0.4310 - val_loss: 1.4862 - val_accuracy: 0.4780\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 1.5233 - accuracy: 0.4415 - val_loss: 1.4884 - val_accuracy: 0.4700\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 2s 760us/step - loss: 1.4865 - accuracy: 0.4400 - val_loss: 1.4857 - val_accuracy: 0.4640\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 1.4535 - accuracy: 0.4595 - val_loss: 1.4775 - val_accuracy: 0.4620\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 508us/step - loss: 1.4993 - accuracy: 0.4435 - val_loss: 1.4690 - val_accuracy: 0.4640\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 507us/step - loss: 1.4799 - accuracy: 0.4415 - val_loss: 1.4656 - val_accuracy: 0.4700\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 508us/step - loss: 1.5022 - accuracy: 0.4390 - val_loss: 1.4676 - val_accuracy: 0.4660\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.4569 - accuracy: 0.4390 - val_loss: 1.4757 - val_accuracy: 0.4700\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 519us/step - loss: 1.4578 - accuracy: 0.4590 - val_loss: 1.4767 - val_accuracy: 0.4740\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 507us/step - loss: 1.4743 - accuracy: 0.4360 - val_loss: 1.4803 - val_accuracy: 0.4820\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 506us/step - loss: 1.4353 - accuracy: 0.4550 - val_loss: 1.4860 - val_accuracy: 0.4820\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 504us/step - loss: 1.5009 - accuracy: 0.4360 - val_loss: 1.4784 - val_accuracy: 0.4620\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 1.4476 - accuracy: 0.4670 - val_loss: 1.4711 - val_accuracy: 0.4620\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 508us/step - loss: 1.4760 - accuracy: 0.4440 - val_loss: 1.4712 - val_accuracy: 0.4580\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 508us/step - loss: 1.4720 - accuracy: 0.4675 - val_loss: 1.4753 - val_accuracy: 0.4760\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 505us/step - loss: 1.4797 - accuracy: 0.4530 - val_loss: 1.4805 - val_accuracy: 0.4860\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 549us/step - loss: 1.4476 - accuracy: 0.4595 - val_loss: 1.4831 - val_accuracy: 0.4760\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.4591 - accuracy: 0.4425 - val_loss: 1.4834 - val_accuracy: 0.4700\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 2s 770us/step - loss: 1.4421 - accuracy: 0.4470 - val_loss: 1.4823 - val_accuracy: 0.4720\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.4472 - accuracy: 0.4610 - val_loss: 1.4802 - val_accuracy: 0.4800\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.4507 - accuracy: 0.4555 - val_loss: 1.4807 - val_accuracy: 0.4820\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.4470 - accuracy: 0.4510 - val_loss: 1.4791 - val_accuracy: 0.4780\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.4467 - accuracy: 0.4620 - val_loss: 1.4808 - val_accuracy: 0.4760\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.4428 - accuracy: 0.4445 - val_loss: 1.4788 - val_accuracy: 0.4740\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.4440 - accuracy: 0.4555 - val_loss: 1.4824 - val_accuracy: 0.4700\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.4411 - accuracy: 0.4530 - val_loss: 1.4779 - val_accuracy: 0.4840\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.4345 - accuracy: 0.4560 - val_loss: 1.4692 - val_accuracy: 0.4920\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.4327 - accuracy: 0.4510 - val_loss: 1.4733 - val_accuracy: 0.4800\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.4455 - accuracy: 0.4590 - val_loss: 1.4808 - val_accuracy: 0.4760\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.4192 - accuracy: 0.4630 - val_loss: 1.4895 - val_accuracy: 0.4760\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.4447 - accuracy: 0.4470 - val_loss: 1.4861 - val_accuracy: 0.4780\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.4313 - accuracy: 0.4555 - val_loss: 1.4926 - val_accuracy: 0.4760\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.4367 - accuracy: 0.4685 - val_loss: 1.4923 - val_accuracy: 0.4700\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 592us/step - loss: 1.3906 - accuracy: 0.4735 - val_loss: 1.4895 - val_accuracy: 0.4720\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.3917 - accuracy: 0.4730 - val_loss: 1.4883 - val_accuracy: 0.4740\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.4215 - accuracy: 0.4495 - val_loss: 1.4810 - val_accuracy: 0.4840\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 588us/step - loss: 1.4290 - accuracy: 0.4620 - val_loss: 1.4771 - val_accuracy: 0.4860\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.3911 - accuracy: 0.4720 - val_loss: 1.4846 - val_accuracy: 0.4880\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 612us/step - loss: 1.4166 - accuracy: 0.4705 - val_loss: 1.4951 - val_accuracy: 0.4820\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 743us/step - loss: 1.4495 - accuracy: 0.4585 - val_loss: 1.4951 - val_accuracy: 0.4680\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.4192 - accuracy: 0.4710 - val_loss: 1.4900 - val_accuracy: 0.4560\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 644us/step - loss: 1.4313 - accuracy: 0.4650 - val_loss: 1.4815 - val_accuracy: 0.4640\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.4030 - accuracy: 0.4620 - val_loss: 1.4813 - val_accuracy: 0.4720\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.4221 - accuracy: 0.4630 - val_loss: 1.4886 - val_accuracy: 0.4680\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.3936 - accuracy: 0.4715 - val_loss: 1.4969 - val_accuracy: 0.4680\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.4333 - accuracy: 0.4615 - val_loss: 1.5082 - val_accuracy: 0.4640\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.3794 - accuracy: 0.4690 - val_loss: 1.5079 - val_accuracy: 0.4720\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 632us/step - loss: 1.3840 - accuracy: 0.4780 - val_loss: 1.5047 - val_accuracy: 0.4720\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 649us/step - loss: 1.4167 - accuracy: 0.4835 - val_loss: 1.4952 - val_accuracy: 0.4800\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 1.4353 - accuracy: 0.4720 - val_loss: 1.4949 - val_accuracy: 0.4840\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.3907 - accuracy: 0.4645 - val_loss: 1.4985 - val_accuracy: 0.4820\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.3821 - accuracy: 0.4695 - val_loss: 1.4988 - val_accuracy: 0.4740\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.3832 - accuracy: 0.4745 - val_loss: 1.4922 - val_accuracy: 0.4920\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3935 - accuracy: 0.4695 - val_loss: 1.4875 - val_accuracy: 0.4900\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.3854 - accuracy: 0.4740 - val_loss: 1.4864 - val_accuracy: 0.4980\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 552us/step - loss: 1.4171 - accuracy: 0.4775 - val_loss: 1.4890 - val_accuracy: 0.4920\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.3889 - accuracy: 0.4765 - val_loss: 1.4956 - val_accuracy: 0.4900\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.4048 - accuracy: 0.4730 - val_loss: 1.4998 - val_accuracy: 0.4880\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 599us/step - loss: 1.3832 - accuracy: 0.4540 - val_loss: 1.5049 - val_accuracy: 0.4880\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 620us/step - loss: 1.4071 - accuracy: 0.4610 - val_loss: 1.5135 - val_accuracy: 0.4800\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.3767 - accuracy: 0.4660 - val_loss: 1.5205 - val_accuracy: 0.4900\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 1.3718 - accuracy: 0.4695 - val_loss: 1.5256 - val_accuracy: 0.4900\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 742us/step - loss: 1.3936 - accuracy: 0.4810 - val_loss: 1.5210 - val_accuracy: 0.4920\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.3452 - accuracy: 0.4825 - val_loss: 1.5240 - val_accuracy: 0.5020\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.3442 - accuracy: 0.4705 - val_loss: 1.5272 - val_accuracy: 0.4940\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.4024 - accuracy: 0.4625 - val_loss: 1.5256 - val_accuracy: 0.4780\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.3676 - accuracy: 0.4860 - val_loss: 1.5128 - val_accuracy: 0.4900\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 511us/step - loss: 1.3700 - accuracy: 0.4875 - val_loss: 1.5120 - val_accuracy: 0.4860\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 515us/step - loss: 1.3842 - accuracy: 0.4805 - val_loss: 1.5102 - val_accuracy: 0.4860\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 513us/step - loss: 1.3659 - accuracy: 0.4835 - val_loss: 1.5017 - val_accuracy: 0.4860\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 512us/step - loss: 1.3442 - accuracy: 0.4905 - val_loss: 1.4971 - val_accuracy: 0.4820\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 517us/step - loss: 1.3546 - accuracy: 0.4805 - val_loss: 1.5053 - val_accuracy: 0.4780\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.3419 - accuracy: 0.4845 - val_loss: 1.5102 - val_accuracy: 0.4840\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.3617 - accuracy: 0.4745 - val_loss: 1.5030 - val_accuracy: 0.4980\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.3443 - accuracy: 0.4940 - val_loss: 1.4921 - val_accuracy: 0.4880\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 1.3587 - accuracy: 0.4850 - val_loss: 1.4953 - val_accuracy: 0.4820\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.3234 - accuracy: 0.5035 - val_loss: 1.5055 - val_accuracy: 0.4840\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.3638 - accuracy: 0.4875 - val_loss: 1.5207 - val_accuracy: 0.4860\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.3454 - accuracy: 0.4820 - val_loss: 1.5247 - val_accuracy: 0.4960\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.3766 - accuracy: 0.4800 - val_loss: 1.5215 - val_accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.3499 - accuracy: 0.4995 - val_loss: 1.5289 - val_accuracy: 0.4940\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.3679 - accuracy: 0.4865 - val_loss: 1.5382 - val_accuracy: 0.4880\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.3490 - accuracy: 0.4895 - val_loss: 1.5414 - val_accuracy: 0.4860\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.3183 - accuracy: 0.4940 - val_loss: 1.5374 - val_accuracy: 0.4900\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.3444 - accuracy: 0.5000 - val_loss: 1.5311 - val_accuracy: 0.4860\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.3326 - accuracy: 0.4990 - val_loss: 1.5387 - val_accuracy: 0.4880\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.3312 - accuracy: 0.5065 - val_loss: 1.5423 - val_accuracy: 0.4900\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.3264 - accuracy: 0.5105 - val_loss: 1.5329 - val_accuracy: 0.4920\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.3196 - accuracy: 0.4875 - val_loss: 1.5327 - val_accuracy: 0.4960\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.3352 - accuracy: 0.4880 - val_loss: 1.5416 - val_accuracy: 0.4780\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2955 - accuracy: 0.5025 - val_loss: 1.5384 - val_accuracy: 0.4860\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.3211 - accuracy: 0.4840 - val_loss: 1.5460 - val_accuracy: 0.4900\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.3802 - accuracy: 0.4770 - val_loss: 1.5561 - val_accuracy: 0.4900\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.3198 - accuracy: 0.4920 - val_loss: 1.5581 - val_accuracy: 0.4980\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.2846 - accuracy: 0.5115 - val_loss: 1.5552 - val_accuracy: 0.5020\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.3159 - accuracy: 0.5065 - val_loss: 1.5450 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.3322 - accuracy: 0.4830 - val_loss: 1.5447 - val_accuracy: 0.4880\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.2773 - accuracy: 0.5120 - val_loss: 1.5570 - val_accuracy: 0.4780\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.3099 - accuracy: 0.4925 - val_loss: 1.5308 - val_accuracy: 0.4800\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.3057 - accuracy: 0.5070 - val_loss: 1.5195 - val_accuracy: 0.4900\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.3153 - accuracy: 0.5105 - val_loss: 1.5341 - val_accuracy: 0.4840\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 549us/step - loss: 1.3106 - accuracy: 0.4995 - val_loss: 1.5409 - val_accuracy: 0.4920\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.3307 - accuracy: 0.4975 - val_loss: 1.5446 - val_accuracy: 0.4920\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3042 - accuracy: 0.5040 - val_loss: 1.5380 - val_accuracy: 0.4880\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.3359 - accuracy: 0.4905 - val_loss: 1.5469 - val_accuracy: 0.4920\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.3118 - accuracy: 0.4970 - val_loss: 1.5528 - val_accuracy: 0.4860\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3036 - accuracy: 0.5015 - val_loss: 1.5627 - val_accuracy: 0.4880\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3096 - accuracy: 0.4975 - val_loss: 1.5511 - val_accuracy: 0.4920\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.3083 - accuracy: 0.5090 - val_loss: 1.5409 - val_accuracy: 0.4960\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.3162 - accuracy: 0.4990 - val_loss: 1.5352 - val_accuracy: 0.5020\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.3058 - accuracy: 0.4820 - val_loss: 1.5439 - val_accuracy: 0.4860\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.3040 - accuracy: 0.5045 - val_loss: 1.5439 - val_accuracy: 0.4900\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3295 - accuracy: 0.4990 - val_loss: 1.5341 - val_accuracy: 0.4880\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.3201 - accuracy: 0.4890 - val_loss: 1.5203 - val_accuracy: 0.4940\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.2919 - accuracy: 0.5065 - val_loss: 1.5271 - val_accuracy: 0.4920\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 544us/step - loss: 1.2962 - accuracy: 0.5125 - val_loss: 1.5304 - val_accuracy: 0.4920\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.2860 - accuracy: 0.4975 - val_loss: 1.5421 - val_accuracy: 0.4880\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.3370 - accuracy: 0.4925 - val_loss: 1.5784 - val_accuracy: 0.4800\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.3267 - accuracy: 0.4850 - val_loss: 1.5937 - val_accuracy: 0.4880\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.2847 - accuracy: 0.4990 - val_loss: 1.5882 - val_accuracy: 0.4940\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.2877 - accuracy: 0.5080 - val_loss: 1.5845 - val_accuracy: 0.4920\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.2739 - accuracy: 0.5170 - val_loss: 1.5810 - val_accuracy: 0.4760\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3230 - accuracy: 0.4860 - val_loss: 1.5846 - val_accuracy: 0.4780\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.2911 - accuracy: 0.5125 - val_loss: 1.5631 - val_accuracy: 0.5040\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.3306 - accuracy: 0.4880 - val_loss: 1.5510 - val_accuracy: 0.4820\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.2998 - accuracy: 0.5005 - val_loss: 1.5548 - val_accuracy: 0.4840\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.2704 - accuracy: 0.5125 - val_loss: 1.5693 - val_accuracy: 0.4820\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.3116 - accuracy: 0.5195 - val_loss: 1.5772 - val_accuracy: 0.4760\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.2746 - accuracy: 0.5060 - val_loss: 1.5816 - val_accuracy: 0.4860\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.2972 - accuracy: 0.5075 - val_loss: 1.5720 - val_accuracy: 0.4800\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.2561 - accuracy: 0.5320 - val_loss: 1.5597 - val_accuracy: 0.4880\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.2633 - accuracy: 0.5250 - val_loss: 1.5667 - val_accuracy: 0.4860\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 1.2558 - accuracy: 0.5180 - val_loss: 1.5680 - val_accuracy: 0.4880\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.2931 - accuracy: 0.5140 - val_loss: 1.5706 - val_accuracy: 0.4780\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.2568 - accuracy: 0.5185 - val_loss: 1.5677 - val_accuracy: 0.4820\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.2756 - accuracy: 0.5100 - val_loss: 1.5889 - val_accuracy: 0.4840\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.2723 - accuracy: 0.5135 - val_loss: 1.5825 - val_accuracy: 0.4960\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.2734 - accuracy: 0.5110 - val_loss: 1.5684 - val_accuracy: 0.4980\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2607 - accuracy: 0.5340 - val_loss: 1.5737 - val_accuracy: 0.4900\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 618us/step - loss: 1.2341 - accuracy: 0.5205 - val_loss: 1.5798 - val_accuracy: 0.4860\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 1.2687 - accuracy: 0.5265 - val_loss: 1.5773 - val_accuracy: 0.4920\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2775 - accuracy: 0.5130 - val_loss: 1.5796 - val_accuracy: 0.4800\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2652 - accuracy: 0.5270 - val_loss: 1.5909 - val_accuracy: 0.4880\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2632 - accuracy: 0.5270 - val_loss: 1.5936 - val_accuracy: 0.4820\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.2634 - accuracy: 0.5125 - val_loss: 1.5944 - val_accuracy: 0.4840\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.2330 - accuracy: 0.5340 - val_loss: 1.5883 - val_accuracy: 0.5020\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.2805 - accuracy: 0.5180 - val_loss: 1.5781 - val_accuracy: 0.5040\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.2808 - accuracy: 0.5210 - val_loss: 1.5711 - val_accuracy: 0.5080\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.2451 - accuracy: 0.5295 - val_loss: 1.5740 - val_accuracy: 0.5120\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.2876 - accuracy: 0.5105 - val_loss: 1.5737 - val_accuracy: 0.4920\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.2667 - accuracy: 0.5200 - val_loss: 1.5782 - val_accuracy: 0.4860\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.2692 - accuracy: 0.5250 - val_loss: 1.5912 - val_accuracy: 0.4920\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2449 - accuracy: 0.5160 - val_loss: 1.5931 - val_accuracy: 0.4940\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2389 - accuracy: 0.5360 - val_loss: 1.5904 - val_accuracy: 0.4920\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2427 - accuracy: 0.5250 - val_loss: 1.5899 - val_accuracy: 0.4900\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2362 - accuracy: 0.5250 - val_loss: 1.5991 - val_accuracy: 0.4940\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.2646 - accuracy: 0.5160 - val_loss: 1.5959 - val_accuracy: 0.4940\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.3080 - accuracy: 0.5145 - val_loss: 1.5923 - val_accuracy: 0.4960\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.2078 - accuracy: 0.5375 - val_loss: 1.5907 - val_accuracy: 0.4940\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 610us/step - loss: 1.2406 - accuracy: 0.5280 - val_loss: 1.5919 - val_accuracy: 0.4920\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 650us/step - loss: 1.2924 - accuracy: 0.4995 - val_loss: 1.5935 - val_accuracy: 0.4860\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 611us/step - loss: 1.2687 - accuracy: 0.5075 - val_loss: 1.5955 - val_accuracy: 0.4940\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.2435 - accuracy: 0.5095 - val_loss: 1.5963 - val_accuracy: 0.4920\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2419 - accuracy: 0.5170 - val_loss: 1.5957 - val_accuracy: 0.4960\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.2443 - accuracy: 0.5175 - val_loss: 1.5945 - val_accuracy: 0.4960\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.2420 - accuracy: 0.5290 - val_loss: 1.5927 - val_accuracy: 0.4980\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2318 - accuracy: 0.5350 - val_loss: 1.5924 - val_accuracy: 0.4920\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2688 - accuracy: 0.5170 - val_loss: 1.5918 - val_accuracy: 0.4980\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.2712 - accuracy: 0.5160 - val_loss: 1.5903 - val_accuracy: 0.4960\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.2425 - accuracy: 0.5265 - val_loss: 1.5914 - val_accuracy: 0.4920\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.2665 - accuracy: 0.5230 - val_loss: 1.5931 - val_accuracy: 0.4960\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 611us/step - loss: 1.2394 - accuracy: 0.5230 - val_loss: 1.5949 - val_accuracy: 0.4920\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.2462 - accuracy: 0.5300 - val_loss: 1.5973 - val_accuracy: 0.4920\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2308 - accuracy: 0.5260 - val_loss: 1.5973 - val_accuracy: 0.4920\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2881 - accuracy: 0.5015 - val_loss: 1.5972 - val_accuracy: 0.4920\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2655 - accuracy: 0.5220 - val_loss: 1.5970 - val_accuracy: 0.4940\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2384 - accuracy: 0.5215 - val_loss: 1.5959 - val_accuracy: 0.4980\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.2134 - accuracy: 0.5440 - val_loss: 1.5952 - val_accuracy: 0.4940\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.1987 - accuracy: 0.5440 - val_loss: 1.5972 - val_accuracy: 0.4960\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2970 - accuracy: 0.4950 - val_loss: 1.6008 - val_accuracy: 0.4980\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2596 - accuracy: 0.5160 - val_loss: 1.6026 - val_accuracy: 0.4980\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.2145 - accuracy: 0.5350 - val_loss: 1.6030 - val_accuracy: 0.4980\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2094 - accuracy: 0.5290 - val_loss: 1.6027 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2568 - accuracy: 0.5275 - val_loss: 1.6031 - val_accuracy: 0.4980\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.2506 - accuracy: 0.5145 - val_loss: 1.6033 - val_accuracy: 0.5020\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 634us/step - loss: 1.2317 - accuracy: 0.5220 - val_loss: 1.6042 - val_accuracy: 0.5020\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 612us/step - loss: 1.2505 - accuracy: 0.5260 - val_loss: 1.6035 - val_accuracy: 0.4980\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 1.2358 - accuracy: 0.5400 - val_loss: 1.6036 - val_accuracy: 0.4960\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 651us/step - loss: 1.2665 - accuracy: 0.5190 - val_loss: 1.6047 - val_accuracy: 0.4960\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 656us/step - loss: 1.2124 - accuracy: 0.5415 - val_loss: 1.6031 - val_accuracy: 0.4940\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.2131 - accuracy: 0.5545 - val_loss: 1.6022 - val_accuracy: 0.4980\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 588us/step - loss: 1.2445 - accuracy: 0.5285 - val_loss: 1.6011 - val_accuracy: 0.4980\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 679us/step - loss: 1.2299 - accuracy: 0.5345 - val_loss: 1.6004 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 676us/step - loss: 1.2167 - accuracy: 0.5335 - val_loss: 1.6007 - val_accuracy: 0.5020\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 596us/step - loss: 1.1917 - accuracy: 0.5310 - val_loss: 1.6018 - val_accuracy: 0.5020\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 748us/step - loss: 1.2306 - accuracy: 0.5305 - val_loss: 1.6029 - val_accuracy: 0.5020\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 2s 865us/step - loss: 1.2377 - accuracy: 0.5140 - val_loss: 1.6029 - val_accuracy: 0.5020\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 662us/step - loss: 1.2226 - accuracy: 0.5300 - val_loss: 1.6030 - val_accuracy: 0.5040\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 682us/step - loss: 1.2331 - accuracy: 0.5270 - val_loss: 1.6021 - val_accuracy: 0.5040\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 689us/step - loss: 1.2550 - accuracy: 0.5290 - val_loss: 1.6018 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.2315 - accuracy: 0.5375 - val_loss: 1.6007 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.2151 - accuracy: 0.5235 - val_loss: 1.6004 - val_accuracy: 0.5020\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.2538 - accuracy: 0.5230 - val_loss: 1.5987 - val_accuracy: 0.5020\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.2255 - accuracy: 0.5230 - val_loss: 1.5981 - val_accuracy: 0.5040\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.2126 - accuracy: 0.5285 - val_loss: 1.5986 - val_accuracy: 0.5060\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.2670 - accuracy: 0.5115 - val_loss: 1.5989 - val_accuracy: 0.5060\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 552us/step - loss: 1.1791 - accuracy: 0.5365 - val_loss: 1.5981 - val_accuracy: 0.5020\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 2s 812us/step - loss: 1.2075 - accuracy: 0.5255 - val_loss: 1.5993 - val_accuracy: 0.5020\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2195 - accuracy: 0.5385 - val_loss: 1.6009 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2114 - accuracy: 0.5355 - val_loss: 1.6010 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 1.2329 - accuracy: 0.5365 - val_loss: 1.6004 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 648us/step - loss: 1.2288 - accuracy: 0.5365 - val_loss: 1.6006 - val_accuracy: 0.4980\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 622us/step - loss: 1.2184 - accuracy: 0.5270 - val_loss: 1.6008 - val_accuracy: 0.4960\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 638us/step - loss: 1.2333 - accuracy: 0.5265 - val_loss: 1.6008 - val_accuracy: 0.4980\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 635us/step - loss: 1.2343 - accuracy: 0.5380 - val_loss: 1.6028 - val_accuracy: 0.4920\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 635us/step - loss: 1.2385 - accuracy: 0.5205 - val_loss: 1.6045 - val_accuracy: 0.4940\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.2027 - accuracy: 0.5345 - val_loss: 1.6063 - val_accuracy: 0.4920\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.2126 - accuracy: 0.5435 - val_loss: 1.6079 - val_accuracy: 0.4960\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 628us/step - loss: 1.2389 - accuracy: 0.5300 - val_loss: 1.6081 - val_accuracy: 0.4980\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2368 - accuracy: 0.5285 - val_loss: 1.6073 - val_accuracy: 0.5020\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2451 - accuracy: 0.5330 - val_loss: 1.6072 - val_accuracy: 0.4980\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2097 - accuracy: 0.5285 - val_loss: 1.6075 - val_accuracy: 0.4980\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2100 - accuracy: 0.5410 - val_loss: 1.6103 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.2075 - accuracy: 0.5315 - val_loss: 1.6096 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.1954 - accuracy: 0.5365 - val_loss: 1.6105 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2073 - accuracy: 0.5210 - val_loss: 1.6112 - val_accuracy: 0.4960\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2045 - accuracy: 0.5335 - val_loss: 1.6126 - val_accuracy: 0.4960\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1936 - accuracy: 0.5395 - val_loss: 1.6137 - val_accuracy: 0.4960\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2154 - accuracy: 0.5300 - val_loss: 1.6133 - val_accuracy: 0.4960\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2164 - accuracy: 0.5335 - val_loss: 1.6124 - val_accuracy: 0.4940\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.1879 - accuracy: 0.5435 - val_loss: 1.6105 - val_accuracy: 0.4980\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2205 - accuracy: 0.5305 - val_loss: 1.6102 - val_accuracy: 0.4980\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2566 - accuracy: 0.5175 - val_loss: 1.6092 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.1923 - accuracy: 0.5425 - val_loss: 1.6082 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1868 - accuracy: 0.5460 - val_loss: 1.6090 - val_accuracy: 0.5020\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2127 - accuracy: 0.5305 - val_loss: 1.6098 - val_accuracy: 0.5020\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.2482 - accuracy: 0.5245 - val_loss: 1.6109 - val_accuracy: 0.5020\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2029 - accuracy: 0.5400 - val_loss: 1.6122 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2417 - accuracy: 0.5230 - val_loss: 1.6128 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2581 - accuracy: 0.5295 - val_loss: 1.6136 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 607us/step - loss: 1.2337 - accuracy: 0.5225 - val_loss: 1.6134 - val_accuracy: 0.4960\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 592us/step - loss: 1.2328 - accuracy: 0.5295 - val_loss: 1.6113 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2261 - accuracy: 0.5370 - val_loss: 1.6106 - val_accuracy: 0.5040\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2224 - accuracy: 0.5320 - val_loss: 1.6117 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2321 - accuracy: 0.5265 - val_loss: 1.6104 - val_accuracy: 0.4960\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2456 - accuracy: 0.5240 - val_loss: 1.6098 - val_accuracy: 0.4980\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2560 - accuracy: 0.5305 - val_loss: 1.6093 - val_accuracy: 0.4980\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2170 - accuracy: 0.5330 - val_loss: 1.6069 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2263 - accuracy: 0.5345 - val_loss: 1.6059 - val_accuracy: 0.5020\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2285 - accuracy: 0.5395 - val_loss: 1.6068 - val_accuracy: 0.4980\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2143 - accuracy: 0.5510 - val_loss: 1.6080 - val_accuracy: 0.4980\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2543 - accuracy: 0.5130 - val_loss: 1.6074 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2370 - accuracy: 0.5345 - val_loss: 1.6074 - val_accuracy: 0.5020\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2226 - accuracy: 0.5225 - val_loss: 1.6053 - val_accuracy: 0.4960\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1965 - accuracy: 0.5605 - val_loss: 1.6054 - val_accuracy: 0.4960\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2179 - accuracy: 0.5295 - val_loss: 1.6055 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 592us/step - loss: 1.2225 - accuracy: 0.5135 - val_loss: 1.6051 - val_accuracy: 0.5040\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2222 - accuracy: 0.5275 - val_loss: 1.6051 - val_accuracy: 0.5020\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2093 - accuracy: 0.5345 - val_loss: 1.6062 - val_accuracy: 0.5040\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.1931 - accuracy: 0.5545 - val_loss: 1.6059 - val_accuracy: 0.5040\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 596us/step - loss: 1.2084 - accuracy: 0.5335 - val_loss: 1.6045 - val_accuracy: 0.5060\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 656us/step - loss: 1.1806 - accuracy: 0.5475 - val_loss: 1.6026 - val_accuracy: 0.5040\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.1928 - accuracy: 0.5455 - val_loss: 1.6038 - val_accuracy: 0.5040\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2033 - accuracy: 0.5480 - val_loss: 1.6055 - val_accuracy: 0.5020\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2100 - accuracy: 0.5430 - val_loss: 1.6061 - val_accuracy: 0.5080\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2324 - accuracy: 0.5290 - val_loss: 1.6046 - val_accuracy: 0.5040\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2425 - accuracy: 0.5310 - val_loss: 1.6029 - val_accuracy: 0.5040\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2089 - accuracy: 0.5415 - val_loss: 1.6027 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1886 - accuracy: 0.5440 - val_loss: 1.6026 - val_accuracy: 0.4980\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2095 - accuracy: 0.5385 - val_loss: 1.6022 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1822 - accuracy: 0.5535 - val_loss: 1.6041 - val_accuracy: 0.5020\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1876 - accuracy: 0.5555 - val_loss: 1.6061 - val_accuracy: 0.5080\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2230 - accuracy: 0.5270 - val_loss: 1.6068 - val_accuracy: 0.5040\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.2395 - accuracy: 0.5380 - val_loss: 1.6105 - val_accuracy: 0.5060\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 595us/step - loss: 1.2077 - accuracy: 0.5415 - val_loss: 1.6132 - val_accuracy: 0.5040\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 593us/step - loss: 1.2352 - accuracy: 0.5225 - val_loss: 1.6145 - val_accuracy: 0.5040\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 601us/step - loss: 1.1956 - accuracy: 0.5360 - val_loss: 1.6151 - val_accuracy: 0.5120\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2331 - accuracy: 0.5350 - val_loss: 1.6166 - val_accuracy: 0.5100\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.2280 - accuracy: 0.5330 - val_loss: 1.6166 - val_accuracy: 0.5080\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2131 - accuracy: 0.5445 - val_loss: 1.6168 - val_accuracy: 0.5060\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.1820 - accuracy: 0.5460 - val_loss: 1.6178 - val_accuracy: 0.5040\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2100 - accuracy: 0.5415 - val_loss: 1.6185 - val_accuracy: 0.5040\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.1971 - accuracy: 0.5525 - val_loss: 1.6175 - val_accuracy: 0.5040\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 588us/step - loss: 1.2197 - accuracy: 0.5330 - val_loss: 1.6163 - val_accuracy: 0.5080\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.1890 - accuracy: 0.5415 - val_loss: 1.6140 - val_accuracy: 0.5040\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.1811 - accuracy: 0.5505 - val_loss: 1.6116 - val_accuracy: 0.5020\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2004 - accuracy: 0.5410 - val_loss: 1.6108 - val_accuracy: 0.5020\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2315 - accuracy: 0.5345 - val_loss: 1.6117 - val_accuracy: 0.5060\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2095 - accuracy: 0.5440 - val_loss: 1.6129 - val_accuracy: 0.5100\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2186 - accuracy: 0.5295 - val_loss: 1.6138 - val_accuracy: 0.5080\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.1862 - accuracy: 0.5415 - val_loss: 1.6132 - val_accuracy: 0.5120\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2166 - accuracy: 0.5425 - val_loss: 1.6123 - val_accuracy: 0.5140\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2567 - accuracy: 0.5250 - val_loss: 1.6126 - val_accuracy: 0.5100\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.2057 - accuracy: 0.5495 - val_loss: 1.6121 - val_accuracy: 0.5040\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.2156 - accuracy: 0.5350 - val_loss: 1.6119 - val_accuracy: 0.5040\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2019 - accuracy: 0.5460 - val_loss: 1.6120 - val_accuracy: 0.5020\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2277 - accuracy: 0.5290 - val_loss: 1.6137 - val_accuracy: 0.4980\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.2339 - accuracy: 0.5305 - val_loss: 1.6122 - val_accuracy: 0.4980\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2059 - accuracy: 0.5315 - val_loss: 1.6123 - val_accuracy: 0.4980\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.1875 - accuracy: 0.5370 - val_loss: 1.6126 - val_accuracy: 0.5020\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.2037 - accuracy: 0.5355 - val_loss: 1.6119 - val_accuracy: 0.5040\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2453 - accuracy: 0.5295 - val_loss: 1.6116 - val_accuracy: 0.5040\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2029 - accuracy: 0.5410 - val_loss: 1.6129 - val_accuracy: 0.5060\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2198 - accuracy: 0.5345 - val_loss: 1.6141 - val_accuracy: 0.5100\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 629us/step - loss: 1.2225 - accuracy: 0.5380 - val_loss: 1.6154 - val_accuracy: 0.5100\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 1.2294 - accuracy: 0.5240 - val_loss: 1.6173 - val_accuracy: 0.5100\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 593us/step - loss: 1.2206 - accuracy: 0.5320 - val_loss: 1.6188 - val_accuracy: 0.5060\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2587 - accuracy: 0.5195 - val_loss: 1.6196 - val_accuracy: 0.5060\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2064 - accuracy: 0.5230 - val_loss: 1.6190 - val_accuracy: 0.5080\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2012 - accuracy: 0.5440 - val_loss: 1.6191 - val_accuracy: 0.5120\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2119 - accuracy: 0.5430 - val_loss: 1.6193 - val_accuracy: 0.5080\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2134 - accuracy: 0.5215 - val_loss: 1.6201 - val_accuracy: 0.5100\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2095 - accuracy: 0.5410 - val_loss: 1.6212 - val_accuracy: 0.5100\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.2081 - accuracy: 0.5505 - val_loss: 1.6195 - val_accuracy: 0.5140\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.1955 - accuracy: 0.5310 - val_loss: 1.6169 - val_accuracy: 0.5100\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.1991 - accuracy: 0.5340 - val_loss: 1.6166 - val_accuracy: 0.5160\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.1960 - accuracy: 0.5365 - val_loss: 1.6172 - val_accuracy: 0.5160\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2002 - accuracy: 0.5375 - val_loss: 1.6194 - val_accuracy: 0.5160\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.2037 - accuracy: 0.5510 - val_loss: 1.6192 - val_accuracy: 0.5180\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.2313 - accuracy: 0.5290 - val_loss: 1.6165 - val_accuracy: 0.5220\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.1880 - accuracy: 0.5370 - val_loss: 1.6180 - val_accuracy: 0.5200\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1746 - accuracy: 0.5595 - val_loss: 1.6192 - val_accuracy: 0.5180\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.2001 - accuracy: 0.5475 - val_loss: 1.6204 - val_accuracy: 0.5200\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2048 - accuracy: 0.5410 - val_loss: 1.6226 - val_accuracy: 0.5120\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1926 - accuracy: 0.5330 - val_loss: 1.6238 - val_accuracy: 0.5120\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.1925 - accuracy: 0.5420 - val_loss: 1.6228 - val_accuracy: 0.5080\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 589us/step - loss: 1.2213 - accuracy: 0.5255 - val_loss: 1.6244 - val_accuracy: 0.5060\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 1.1952 - accuracy: 0.5460 - val_loss: 1.6253 - val_accuracy: 0.5080\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.1683 - accuracy: 0.5585 - val_loss: 1.6257 - val_accuracy: 0.5080\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.2071 - accuracy: 0.5320 - val_loss: 1.6257 - val_accuracy: 0.5080\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2407 - accuracy: 0.5230 - val_loss: 1.6253 - val_accuracy: 0.5080\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 593us/step - loss: 1.1804 - accuracy: 0.5490 - val_loss: 1.6247 - val_accuracy: 0.5100\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 588us/step - loss: 1.1787 - accuracy: 0.5420 - val_loss: 1.6229 - val_accuracy: 0.5080\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 636us/step - loss: 1.1845 - accuracy: 0.5390 - val_loss: 1.6235 - val_accuracy: 0.5060\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 616us/step - loss: 1.1872 - accuracy: 0.5350 - val_loss: 1.6240 - val_accuracy: 0.5080\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 607us/step - loss: 1.2150 - accuracy: 0.5210 - val_loss: 1.6241 - val_accuracy: 0.5060\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 604us/step - loss: 1.2359 - accuracy: 0.5245 - val_loss: 1.6236 - val_accuracy: 0.5040\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2523 - accuracy: 0.5405 - val_loss: 1.6222 - val_accuracy: 0.5080\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 626us/step - loss: 1.2143 - accuracy: 0.5455 - val_loss: 1.6221 - val_accuracy: 0.5020\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 676us/step - loss: 1.2163 - accuracy: 0.5445 - val_loss: 1.6240 - val_accuracy: 0.5020\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 661us/step - loss: 1.2349 - accuracy: 0.5295 - val_loss: 1.6273 - val_accuracy: 0.5020\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.2494 - accuracy: 0.5425 - val_loss: 1.6287 - val_accuracy: 0.5040\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.1920 - accuracy: 0.5400 - val_loss: 1.6294 - val_accuracy: 0.5040\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.2258 - accuracy: 0.5305 - val_loss: 1.6316 - val_accuracy: 0.5020\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.1962 - accuracy: 0.5265 - val_loss: 1.6343 - val_accuracy: 0.5040\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.1947 - accuracy: 0.5360 - val_loss: 1.6358 - val_accuracy: 0.5080\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2254 - accuracy: 0.5185 - val_loss: 1.6343 - val_accuracy: 0.5060\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2111 - accuracy: 0.5305 - val_loss: 1.6303 - val_accuracy: 0.5040\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1749 - accuracy: 0.5565 - val_loss: 1.6297 - val_accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.2170 - accuracy: 0.5275 - val_loss: 1.6274 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.1906 - accuracy: 0.5305 - val_loss: 1.6259 - val_accuracy: 0.5040\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2271 - accuracy: 0.5370 - val_loss: 1.6253 - val_accuracy: 0.5040\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1855 - accuracy: 0.5375 - val_loss: 1.6250 - val_accuracy: 0.5040\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2012 - accuracy: 0.5320 - val_loss: 1.6256 - val_accuracy: 0.5080\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1820 - accuracy: 0.5620 - val_loss: 1.6261 - val_accuracy: 0.5100\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.2201 - accuracy: 0.5405 - val_loss: 1.6257 - val_accuracy: 0.5120\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.1664 - accuracy: 0.5455 - val_loss: 1.6267 - val_accuracy: 0.5120\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1876 - accuracy: 0.5350 - val_loss: 1.6268 - val_accuracy: 0.5100\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.2269 - accuracy: 0.5140 - val_loss: 1.6270 - val_accuracy: 0.5100\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2174 - accuracy: 0.5360 - val_loss: 1.6270 - val_accuracy: 0.5120\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1815 - accuracy: 0.5525 - val_loss: 1.6266 - val_accuracy: 0.5120\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2070 - accuracy: 0.5455 - val_loss: 1.6268 - val_accuracy: 0.5140\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.2051 - accuracy: 0.5410 - val_loss: 1.6271 - val_accuracy: 0.5160\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2093 - accuracy: 0.5460 - val_loss: 1.6273 - val_accuracy: 0.5140\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2122 - accuracy: 0.5185 - val_loss: 1.6275 - val_accuracy: 0.5140\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2061 - accuracy: 0.5420 - val_loss: 1.6270 - val_accuracy: 0.5080\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1854 - accuracy: 0.5455 - val_loss: 1.6269 - val_accuracy: 0.5080\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.2272 - accuracy: 0.5270 - val_loss: 1.6270 - val_accuracy: 0.5080\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2243 - accuracy: 0.5355 - val_loss: 1.6270 - val_accuracy: 0.5080\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2268 - accuracy: 0.5220 - val_loss: 1.6273 - val_accuracy: 0.5080\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.2306 - accuracy: 0.5340 - val_loss: 1.6267 - val_accuracy: 0.5100\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 588us/step - loss: 1.1785 - accuracy: 0.5500 - val_loss: 1.6271 - val_accuracy: 0.5100\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 622us/step - loss: 1.1866 - accuracy: 0.5530 - val_loss: 1.6280 - val_accuracy: 0.5100\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 600us/step - loss: 1.2113 - accuracy: 0.5375 - val_loss: 1.6281 - val_accuracy: 0.5100\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 1.1784 - accuracy: 0.5545 - val_loss: 1.6273 - val_accuracy: 0.5100\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1995 - accuracy: 0.5260 - val_loss: 1.6269 - val_accuracy: 0.5100\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.2082 - accuracy: 0.5365 - val_loss: 1.6271 - val_accuracy: 0.5120\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.1413 - accuracy: 0.5415 - val_loss: 1.6268 - val_accuracy: 0.5120\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2085 - accuracy: 0.5460 - val_loss: 1.6269 - val_accuracy: 0.5140\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.1948 - accuracy: 0.5330 - val_loss: 1.6262 - val_accuracy: 0.5120\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2237 - accuracy: 0.5230 - val_loss: 1.6265 - val_accuracy: 0.5080\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2064 - accuracy: 0.5425 - val_loss: 1.6272 - val_accuracy: 0.5100\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.2262 - accuracy: 0.5310 - val_loss: 1.6275 - val_accuracy: 0.5120\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2164 - accuracy: 0.5470 - val_loss: 1.6272 - val_accuracy: 0.5060\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.1853 - accuracy: 0.5510 - val_loss: 1.6268 - val_accuracy: 0.5060\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2468 - accuracy: 0.5370 - val_loss: 1.6261 - val_accuracy: 0.5040\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1937 - accuracy: 0.5480 - val_loss: 1.6259 - val_accuracy: 0.5040\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1804 - accuracy: 0.5505 - val_loss: 1.6263 - val_accuracy: 0.5040\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2014 - accuracy: 0.5440 - val_loss: 1.6269 - val_accuracy: 0.5040\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.1664 - accuracy: 0.5525 - val_loss: 1.6263 - val_accuracy: 0.5040\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.1871 - accuracy: 0.5450 - val_loss: 1.6268 - val_accuracy: 0.5040\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.2415 - accuracy: 0.5435 - val_loss: 1.6264 - val_accuracy: 0.5040\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2071 - accuracy: 0.5305 - val_loss: 1.6263 - val_accuracy: 0.5060\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.2160 - accuracy: 0.5490 - val_loss: 1.6269 - val_accuracy: 0.5080\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1826 - accuracy: 0.5285 - val_loss: 1.6273 - val_accuracy: 0.5100\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2045 - accuracy: 0.5310 - val_loss: 1.6271 - val_accuracy: 0.5060\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2047 - accuracy: 0.5510 - val_loss: 1.6277 - val_accuracy: 0.5080\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2229 - accuracy: 0.5350 - val_loss: 1.6275 - val_accuracy: 0.5100\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.2244 - accuracy: 0.5335 - val_loss: 1.6275 - val_accuracy: 0.5080\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.2222 - accuracy: 0.5340 - val_loss: 1.6279 - val_accuracy: 0.5100\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.1939 - accuracy: 0.5545 - val_loss: 1.6274 - val_accuracy: 0.5100\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1847 - accuracy: 0.5415 - val_loss: 1.6270 - val_accuracy: 0.5100\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2439 - accuracy: 0.5295 - val_loss: 1.6276 - val_accuracy: 0.5100\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.1546 - accuracy: 0.5510 - val_loss: 1.6269 - val_accuracy: 0.5140\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.2009 - accuracy: 0.5330 - val_loss: 1.6269 - val_accuracy: 0.5140\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2163 - accuracy: 0.5340 - val_loss: 1.6273 - val_accuracy: 0.5140\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.2267 - accuracy: 0.5305 - val_loss: 1.6280 - val_accuracy: 0.5120\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.1950 - accuracy: 0.5375 - val_loss: 1.6283 - val_accuracy: 0.5120\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.2166 - accuracy: 0.5530 - val_loss: 1.6286 - val_accuracy: 0.5100\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2149 - accuracy: 0.5410 - val_loss: 1.6284 - val_accuracy: 0.5100\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.1795 - accuracy: 0.5455 - val_loss: 1.6282 - val_accuracy: 0.5120\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2142 - accuracy: 0.5375 - val_loss: 1.6279 - val_accuracy: 0.5120\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2238 - accuracy: 0.5325 - val_loss: 1.6284 - val_accuracy: 0.5140\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1991 - accuracy: 0.5395 - val_loss: 1.6286 - val_accuracy: 0.5140\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1908 - accuracy: 0.5475 - val_loss: 1.6289 - val_accuracy: 0.5140\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2448 - accuracy: 0.5325 - val_loss: 1.6297 - val_accuracy: 0.5140\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2165 - accuracy: 0.5375 - val_loss: 1.6294 - val_accuracy: 0.5140\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.1951 - accuracy: 0.5455 - val_loss: 1.6298 - val_accuracy: 0.5140\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1912 - accuracy: 0.5460 - val_loss: 1.6300 - val_accuracy: 0.5140\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2135 - accuracy: 0.5370 - val_loss: 1.6296 - val_accuracy: 0.5140\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1858 - accuracy: 0.5375 - val_loss: 1.6295 - val_accuracy: 0.5140\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1790 - accuracy: 0.5515 - val_loss: 1.6292 - val_accuracy: 0.5140\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1961 - accuracy: 0.5415 - val_loss: 1.6292 - val_accuracy: 0.5100\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1893 - accuracy: 0.5370 - val_loss: 1.6290 - val_accuracy: 0.5080\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.1951 - accuracy: 0.5495 - val_loss: 1.6291 - val_accuracy: 0.5080\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2003 - accuracy: 0.5485 - val_loss: 1.6284 - val_accuracy: 0.5080\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1795 - accuracy: 0.5385 - val_loss: 1.6286 - val_accuracy: 0.5080\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.1883 - accuracy: 0.5430 - val_loss: 1.6287 - val_accuracy: 0.5080\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.1927 - accuracy: 0.5440 - val_loss: 1.6282 - val_accuracy: 0.5060\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1671 - accuracy: 0.5500 - val_loss: 1.6279 - val_accuracy: 0.5060\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2066 - accuracy: 0.5305 - val_loss: 1.6281 - val_accuracy: 0.5040\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1830 - accuracy: 0.5355 - val_loss: 1.6281 - val_accuracy: 0.5060\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.1949 - accuracy: 0.5465 - val_loss: 1.6285 - val_accuracy: 0.5060\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1993 - accuracy: 0.5370 - val_loss: 1.6290 - val_accuracy: 0.5060\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2211 - accuracy: 0.5410 - val_loss: 1.6296 - val_accuracy: 0.5060\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1891 - accuracy: 0.5460 - val_loss: 1.6303 - val_accuracy: 0.5080\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2353 - accuracy: 0.5215 - val_loss: 1.6302 - val_accuracy: 0.5060\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.2195 - accuracy: 0.5310 - val_loss: 1.6292 - val_accuracy: 0.5080\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2033 - accuracy: 0.5325 - val_loss: 1.6293 - val_accuracy: 0.5080\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.2468 - accuracy: 0.5290 - val_loss: 1.6304 - val_accuracy: 0.5080\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2411 - accuracy: 0.5250 - val_loss: 1.6299 - val_accuracy: 0.5080\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1975 - accuracy: 0.5545 - val_loss: 1.6300 - val_accuracy: 0.5100\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1539 - accuracy: 0.5465 - val_loss: 1.6301 - val_accuracy: 0.5100\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2227 - accuracy: 0.5275 - val_loss: 1.6293 - val_accuracy: 0.5080\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2076 - accuracy: 0.5440 - val_loss: 1.6295 - val_accuracy: 0.5100\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2151 - accuracy: 0.5300 - val_loss: 1.6295 - val_accuracy: 0.5100\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2145 - accuracy: 0.5460 - val_loss: 1.6297 - val_accuracy: 0.5100\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2286 - accuracy: 0.5380 - val_loss: 1.6293 - val_accuracy: 0.5100\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2113 - accuracy: 0.5365 - val_loss: 1.6291 - val_accuracy: 0.5100\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.2171 - accuracy: 0.5305 - val_loss: 1.6289 - val_accuracy: 0.5100\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2052 - accuracy: 0.5320 - val_loss: 1.6294 - val_accuracy: 0.5100\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2067 - accuracy: 0.5435 - val_loss: 1.6295 - val_accuracy: 0.5100\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.1980 - accuracy: 0.5445 - val_loss: 1.6292 - val_accuracy: 0.5100\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 660us/step - loss: 1.2265 - accuracy: 0.5300 - val_loss: 1.6294 - val_accuracy: 0.5080\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 655us/step - loss: 1.1707 - accuracy: 0.5525 - val_loss: 1.6299 - val_accuracy: 0.5080\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 613us/step - loss: 1.1999 - accuracy: 0.5370 - val_loss: 1.6299 - val_accuracy: 0.5100\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.1881 - accuracy: 0.5425 - val_loss: 1.6303 - val_accuracy: 0.5100\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1934 - accuracy: 0.5350 - val_loss: 1.6302 - val_accuracy: 0.5080\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2079 - accuracy: 0.5385 - val_loss: 1.6301 - val_accuracy: 0.5080\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.1435 - accuracy: 0.5770 - val_loss: 1.6302 - val_accuracy: 0.5060\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2038 - accuracy: 0.5400 - val_loss: 1.6305 - val_accuracy: 0.5060\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1810 - accuracy: 0.5580 - val_loss: 1.6305 - val_accuracy: 0.5060\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2084 - accuracy: 0.5335 - val_loss: 1.6296 - val_accuracy: 0.5060\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1719 - accuracy: 0.5565 - val_loss: 1.6296 - val_accuracy: 0.5080\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2365 - accuracy: 0.5260 - val_loss: 1.6298 - val_accuracy: 0.5080\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1972 - accuracy: 0.5360 - val_loss: 1.6303 - val_accuracy: 0.5060\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2024 - accuracy: 0.5395 - val_loss: 1.6302 - val_accuracy: 0.5080\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2010 - accuracy: 0.5415 - val_loss: 1.6300 - val_accuracy: 0.5080\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1893 - accuracy: 0.5485 - val_loss: 1.6300 - val_accuracy: 0.5080\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 1.2037 - accuracy: 0.5480 - val_loss: 1.6300 - val_accuracy: 0.5080\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2185 - accuracy: 0.5350 - val_loss: 1.6307 - val_accuracy: 0.5080\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1773 - accuracy: 0.5490 - val_loss: 1.6301 - val_accuracy: 0.5080\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2309 - accuracy: 0.5360 - val_loss: 1.6300 - val_accuracy: 0.5080\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2041 - accuracy: 0.5345 - val_loss: 1.6305 - val_accuracy: 0.5080\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.1858 - accuracy: 0.5400 - val_loss: 1.6311 - val_accuracy: 0.5080\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1913 - accuracy: 0.5450 - val_loss: 1.6303 - val_accuracy: 0.5080\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.1560 - accuracy: 0.5575 - val_loss: 1.6310 - val_accuracy: 0.5080\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2114 - accuracy: 0.5225 - val_loss: 1.6311 - val_accuracy: 0.5080\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.2132 - accuracy: 0.5380 - val_loss: 1.6311 - val_accuracy: 0.5080\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.1995 - accuracy: 0.5405 - val_loss: 1.6313 - val_accuracy: 0.5080\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2084 - accuracy: 0.5360 - val_loss: 1.6318 - val_accuracy: 0.5100\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1882 - accuracy: 0.5470 - val_loss: 1.6314 - val_accuracy: 0.5100\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.1988 - accuracy: 0.5390 - val_loss: 1.6318 - val_accuracy: 0.5100\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.1840 - accuracy: 0.5445 - val_loss: 1.6321 - val_accuracy: 0.5100\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.2080 - accuracy: 0.5505 - val_loss: 1.6325 - val_accuracy: 0.5100\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2142 - accuracy: 0.5245 - val_loss: 1.6324 - val_accuracy: 0.5080\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1981 - accuracy: 0.5320 - val_loss: 1.6319 - val_accuracy: 0.5080\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.1978 - accuracy: 0.5420 - val_loss: 1.6320 - val_accuracy: 0.5080\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.1513 - accuracy: 0.5525 - val_loss: 1.6317 - val_accuracy: 0.5080\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 592us/step - loss: 1.1754 - accuracy: 0.5405 - val_loss: 1.6317 - val_accuracy: 0.5060\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1635 - accuracy: 0.5650 - val_loss: 1.6315 - val_accuracy: 0.5080\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2296 - accuracy: 0.5350 - val_loss: 1.6313 - val_accuracy: 0.5080\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2077 - accuracy: 0.5490 - val_loss: 1.6309 - val_accuracy: 0.5080\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.2301 - accuracy: 0.5285 - val_loss: 1.6304 - val_accuracy: 0.5080\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.2051 - accuracy: 0.5425 - val_loss: 1.6307 - val_accuracy: 0.5060\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1934 - accuracy: 0.5375 - val_loss: 1.6300 - val_accuracy: 0.5100\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2119 - accuracy: 0.5470 - val_loss: 1.6298 - val_accuracy: 0.5100\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.2489 - accuracy: 0.5255 - val_loss: 1.6299 - val_accuracy: 0.5100\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1935 - accuracy: 0.5505 - val_loss: 1.6297 - val_accuracy: 0.5060\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1890 - accuracy: 0.5475 - val_loss: 1.6288 - val_accuracy: 0.5080\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.2066 - accuracy: 0.5375 - val_loss: 1.6279 - val_accuracy: 0.5080\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.1919 - accuracy: 0.5375 - val_loss: 1.6278 - val_accuracy: 0.5080\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1946 - accuracy: 0.5330 - val_loss: 1.6274 - val_accuracy: 0.5060\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.2401 - accuracy: 0.5235 - val_loss: 1.6279 - val_accuracy: 0.5040\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 1.1963 - accuracy: 0.5335 - val_loss: 1.6278 - val_accuracy: 0.5020\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 1.1915 - accuracy: 0.5410 - val_loss: 1.6277 - val_accuracy: 0.5040\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 613us/step - loss: 1.2089 - accuracy: 0.5375 - val_loss: 1.6279 - val_accuracy: 0.5020\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.2091 - accuracy: 0.5380 - val_loss: 1.6288 - val_accuracy: 0.5020\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.2049 - accuracy: 0.5310 - val_loss: 1.6284 - val_accuracy: 0.5020\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.2278 - accuracy: 0.5255 - val_loss: 1.6276 - val_accuracy: 0.5020\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1729 - accuracy: 0.5540 - val_loss: 1.6281 - val_accuracy: 0.5040\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.2439 - accuracy: 0.5230 - val_loss: 1.6284 - val_accuracy: 0.5060\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1986 - accuracy: 0.5385 - val_loss: 1.6291 - val_accuracy: 0.5040\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.1888 - accuracy: 0.5540 - val_loss: 1.6296 - val_accuracy: 0.5040\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.1841 - accuracy: 0.5445 - val_loss: 1.6294 - val_accuracy: 0.5040\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 551us/step - loss: 1.1810 - accuracy: 0.5425 - val_loss: 1.6293 - val_accuracy: 0.5060\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.1931 - accuracy: 0.5425 - val_loss: 1.6292 - val_accuracy: 0.5040\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.1741 - accuracy: 0.5450 - val_loss: 1.6293 - val_accuracy: 0.5040\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.1327 - accuracy: 0.5570 - val_loss: 1.6291 - val_accuracy: 0.5040\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 604us/step - loss: 1.2096 - accuracy: 0.5345 - val_loss: 1.6294 - val_accuracy: 0.5020\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1752 - accuracy: 0.5440 - val_loss: 1.6299 - val_accuracy: 0.5040\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.1801 - accuracy: 0.5500 - val_loss: 1.6297 - val_accuracy: 0.5040\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.2081 - accuracy: 0.5315 - val_loss: 1.6301 - val_accuracy: 0.5060\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2328 - accuracy: 0.5275 - val_loss: 1.6305 - val_accuracy: 0.5080\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1685 - accuracy: 0.5450 - val_loss: 1.6307 - val_accuracy: 0.5060\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1859 - accuracy: 0.5540 - val_loss: 1.6299 - val_accuracy: 0.5060\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.2139 - accuracy: 0.5415 - val_loss: 1.6299 - val_accuracy: 0.5060\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1877 - accuracy: 0.5510 - val_loss: 1.6302 - val_accuracy: 0.5080\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2158 - accuracy: 0.5300 - val_loss: 1.6301 - val_accuracy: 0.5100\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2060 - accuracy: 0.5375 - val_loss: 1.6299 - val_accuracy: 0.5080\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2285 - accuracy: 0.5315 - val_loss: 1.6298 - val_accuracy: 0.5080\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2034 - accuracy: 0.5460 - val_loss: 1.6298 - val_accuracy: 0.5060\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2085 - accuracy: 0.5250 - val_loss: 1.6295 - val_accuracy: 0.5060\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1885 - accuracy: 0.5315 - val_loss: 1.6296 - val_accuracy: 0.5080\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2278 - accuracy: 0.5285 - val_loss: 1.6292 - val_accuracy: 0.5060\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.1898 - accuracy: 0.5470 - val_loss: 1.6292 - val_accuracy: 0.5060\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2195 - accuracy: 0.5345 - val_loss: 1.6294 - val_accuracy: 0.5060\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.1846 - accuracy: 0.5405 - val_loss: 1.6293 - val_accuracy: 0.5060\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2329 - accuracy: 0.5250 - val_loss: 1.6301 - val_accuracy: 0.5060\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.2211 - accuracy: 0.5360 - val_loss: 1.6299 - val_accuracy: 0.5060\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.2066 - accuracy: 0.5290 - val_loss: 1.6300 - val_accuracy: 0.5060\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1851 - accuracy: 0.5375 - val_loss: 1.6311 - val_accuracy: 0.5060\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1797 - accuracy: 0.5570 - val_loss: 1.6313 - val_accuracy: 0.5060\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.2153 - accuracy: 0.5315 - val_loss: 1.6310 - val_accuracy: 0.5060\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.1933 - accuracy: 0.5500 - val_loss: 1.6303 - val_accuracy: 0.5060\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 609us/step - loss: 1.2146 - accuracy: 0.5280 - val_loss: 1.6303 - val_accuracy: 0.5060\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1807 - accuracy: 0.5535 - val_loss: 1.6303 - val_accuracy: 0.5080\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.2080 - accuracy: 0.5380 - val_loss: 1.6308 - val_accuracy: 0.5100\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.2006 - accuracy: 0.5365 - val_loss: 1.6314 - val_accuracy: 0.5080\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.1844 - accuracy: 0.5435 - val_loss: 1.6317 - val_accuracy: 0.5100\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.2026 - accuracy: 0.5315 - val_loss: 1.6309 - val_accuracy: 0.5080\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 658us/step - loss: 1.2061 - accuracy: 0.5255 - val_loss: 1.6303 - val_accuracy: 0.5060\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 627us/step - loss: 1.1804 - accuracy: 0.5465 - val_loss: 1.6305 - val_accuracy: 0.5060\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 679us/step - loss: 1.2460 - accuracy: 0.5365 - val_loss: 1.6305 - val_accuracy: 0.5080\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 639us/step - loss: 1.1991 - accuracy: 0.5430 - val_loss: 1.6307 - val_accuracy: 0.5080\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.1898 - accuracy: 0.5365 - val_loss: 1.6308 - val_accuracy: 0.5080\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.2610 - accuracy: 0.5285 - val_loss: 1.6165 - val_accuracy: 0.5060\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 544us/step - loss: 1.2095 - accuracy: 0.5345 - val_loss: 1.6442 - val_accuracy: 0.4980\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 1.1634 - accuracy: 0.5590 - val_loss: 1.6531 - val_accuracy: 0.5100\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 596us/step - loss: 1.2058 - accuracy: 0.5530 - val_loss: 1.6602 - val_accuracy: 0.4980\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.2164 - accuracy: 0.5350 - val_loss: 1.6719 - val_accuracy: 0.4980\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 2s 791us/step - loss: 1.2223 - accuracy: 0.5260 - val_loss: 1.6858 - val_accuracy: 0.4940\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 647us/step - loss: 1.2088 - accuracy: 0.5380 - val_loss: 1.6733 - val_accuracy: 0.5020\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 2s 818us/step - loss: 1.1911 - accuracy: 0.5310 - val_loss: 1.6508 - val_accuracy: 0.5060\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 749us/step - loss: 1.1888 - accuracy: 0.5355 - val_loss: 1.6389 - val_accuracy: 0.5040\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 688us/step - loss: 1.2365 - accuracy: 0.5310 - val_loss: 1.6437 - val_accuracy: 0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 2s 802us/step - loss: 1.2116 - accuracy: 0.5485 - val_loss: 1.6358 - val_accuracy: 0.5260\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1832 - accuracy: 0.5540 - val_loss: 1.6331 - val_accuracy: 0.5160\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.2044 - accuracy: 0.5440 - val_loss: 1.6416 - val_accuracy: 0.5180\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 599us/step - loss: 1.1904 - accuracy: 0.5545 - val_loss: 1.6421 - val_accuracy: 0.5160\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 666us/step - loss: 1.2283 - accuracy: 0.5230 - val_loss: 1.6346 - val_accuracy: 0.5120\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 589us/step - loss: 1.1998 - accuracy: 0.5555 - val_loss: 1.6410 - val_accuracy: 0.5200\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 640us/step - loss: 1.1836 - accuracy: 0.5415 - val_loss: 1.6506 - val_accuracy: 0.5160\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 611us/step - loss: 1.2006 - accuracy: 0.5380 - val_loss: 1.6542 - val_accuracy: 0.5100\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.1890 - accuracy: 0.5410 - val_loss: 1.6327 - val_accuracy: 0.5100\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 664us/step - loss: 1.1652 - accuracy: 0.5425 - val_loss: 1.6254 - val_accuracy: 0.5140\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 608us/step - loss: 1.1686 - accuracy: 0.5605 - val_loss: 1.6405 - val_accuracy: 0.5220\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.1862 - accuracy: 0.5430 - val_loss: 1.6676 - val_accuracy: 0.5160\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1398 - accuracy: 0.5515 - val_loss: 1.6759 - val_accuracy: 0.5040\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.1701 - accuracy: 0.5370 - val_loss: 1.6583 - val_accuracy: 0.5100\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1888 - accuracy: 0.5445 - val_loss: 1.6576 - val_accuracy: 0.5080\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.1750 - accuracy: 0.5540 - val_loss: 1.6515 - val_accuracy: 0.5080\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1888 - accuracy: 0.5560 - val_loss: 1.6393 - val_accuracy: 0.5100\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 721us/step - loss: 1.2056 - accuracy: 0.5330 - val_loss: 1.6132 - val_accuracy: 0.5160\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.2243 - accuracy: 0.5250 - val_loss: 1.6104 - val_accuracy: 0.5140\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 665us/step - loss: 1.1925 - accuracy: 0.5435 - val_loss: 1.6188 - val_accuracy: 0.5160\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 2s 865us/step - loss: 1.2346 - accuracy: 0.5345 - val_loss: 1.6283 - val_accuracy: 0.5200\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 2s 763us/step - loss: 1.2261 - accuracy: 0.5230 - val_loss: 1.6544 - val_accuracy: 0.5120\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 1.2024 - accuracy: 0.5405 - val_loss: 1.6632 - val_accuracy: 0.5180\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.1904 - accuracy: 0.5535 - val_loss: 1.6757 - val_accuracy: 0.5140\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.2073 - accuracy: 0.5295 - val_loss: 1.6933 - val_accuracy: 0.5160\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 619us/step - loss: 1.1752 - accuracy: 0.5495 - val_loss: 1.6818 - val_accuracy: 0.5100\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 2s 804us/step - loss: 1.1877 - accuracy: 0.5460 - val_loss: 1.6565 - val_accuracy: 0.5260\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 2s 751us/step - loss: 1.2060 - accuracy: 0.5365 - val_loss: 1.6301 - val_accuracy: 0.5180\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 2s 860us/step - loss: 1.1855 - accuracy: 0.5505 - val_loss: 1.6416 - val_accuracy: 0.5200\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 2s 928us/step - loss: 1.1830 - accuracy: 0.5510 - val_loss: 1.6494 - val_accuracy: 0.5060\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 2s 919us/step - loss: 1.2101 - accuracy: 0.5450 - val_loss: 1.6504 - val_accuracy: 0.5100\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 2s 972us/step - loss: 1.2064 - accuracy: 0.5365 - val_loss: 1.6555 - val_accuracy: 0.5100\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 2s 864us/step - loss: 1.1830 - accuracy: 0.5365 - val_loss: 1.6638 - val_accuracy: 0.4960\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 2s 777us/step - loss: 1.1748 - accuracy: 0.5595 - val_loss: 1.6623 - val_accuracy: 0.5060\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 2s 823us/step - loss: 1.1868 - accuracy: 0.5380 - val_loss: 1.6624 - val_accuracy: 0.5080\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 612us/step - loss: 1.1968 - accuracy: 0.5390 - val_loss: 1.6680 - val_accuracy: 0.5140\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1564 - accuracy: 0.5535 - val_loss: 1.6757 - val_accuracy: 0.5180\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.1781 - accuracy: 0.5485 - val_loss: 1.6712 - val_accuracy: 0.5160\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 647us/step - loss: 1.1772 - accuracy: 0.5550 - val_loss: 1.6775 - val_accuracy: 0.5060\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 652us/step - loss: 1.1832 - accuracy: 0.5520 - val_loss: 1.6898 - val_accuracy: 0.5120\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 687us/step - loss: 1.1762 - accuracy: 0.5430 - val_loss: 1.6973 - val_accuracy: 0.5060\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 654us/step - loss: 1.1670 - accuracy: 0.5600 - val_loss: 1.7001 - val_accuracy: 0.5080\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 660us/step - loss: 1.1590 - accuracy: 0.5550 - val_loss: 1.7016 - val_accuracy: 0.5120\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.1975 - accuracy: 0.5390 - val_loss: 1.6929 - val_accuracy: 0.5160\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 645us/step - loss: 1.1858 - accuracy: 0.5440 - val_loss: 1.6927 - val_accuracy: 0.5260\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.1524 - accuracy: 0.5610 - val_loss: 1.6989 - val_accuracy: 0.5160\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.1581 - accuracy: 0.5510 - val_loss: 1.7077 - val_accuracy: 0.5120\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1899 - accuracy: 0.5410 - val_loss: 1.6996 - val_accuracy: 0.5100\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.1957 - accuracy: 0.5520 - val_loss: 1.6681 - val_accuracy: 0.5060\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1883 - accuracy: 0.5450 - val_loss: 1.6671 - val_accuracy: 0.5020\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.1517 - accuracy: 0.5570 - val_loss: 1.6551 - val_accuracy: 0.5100\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.1470 - accuracy: 0.5465 - val_loss: 1.6839 - val_accuracy: 0.5180\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.2036 - accuracy: 0.5560 - val_loss: 1.7039 - val_accuracy: 0.5120\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.2118 - accuracy: 0.5305 - val_loss: 1.7070 - val_accuracy: 0.4980\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 542us/step - loss: 1.1857 - accuracy: 0.5520 - val_loss: 1.7135 - val_accuracy: 0.4860\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1433 - accuracy: 0.5725 - val_loss: 1.7163 - val_accuracy: 0.4980\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.1721 - accuracy: 0.5605 - val_loss: 1.7089 - val_accuracy: 0.5020\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 1.1687 - accuracy: 0.5620 - val_loss: 1.7106 - val_accuracy: 0.4980\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 1.1508 - accuracy: 0.5600 - val_loss: 1.6876 - val_accuracy: 0.5040\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.1948 - accuracy: 0.5535 - val_loss: 1.6723 - val_accuracy: 0.5020\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 1.1696 - accuracy: 0.5560 - val_loss: 1.6709 - val_accuracy: 0.4960\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1802 - accuracy: 0.5470 - val_loss: 1.6818 - val_accuracy: 0.4940\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.1672 - accuracy: 0.5475 - val_loss: 1.6958 - val_accuracy: 0.5140\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1399 - accuracy: 0.5550 - val_loss: 1.7032 - val_accuracy: 0.5240\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 520us/step - loss: 1.1443 - accuracy: 0.5495 - val_loss: 1.7022 - val_accuracy: 0.5260\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1631 - accuracy: 0.5545 - val_loss: 1.7054 - val_accuracy: 0.5180\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1756 - accuracy: 0.5500 - val_loss: 1.6963 - val_accuracy: 0.5260\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1637 - accuracy: 0.5545 - val_loss: 1.6776 - val_accuracy: 0.5380\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1560 - accuracy: 0.5610 - val_loss: 1.6726 - val_accuracy: 0.5300\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.1957 - accuracy: 0.5545 - val_loss: 1.6696 - val_accuracy: 0.5260\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 1.1577 - accuracy: 0.5550 - val_loss: 1.6879 - val_accuracy: 0.5140\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1600 - accuracy: 0.5620 - val_loss: 1.7133 - val_accuracy: 0.5100\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1515 - accuracy: 0.5550 - val_loss: 1.7244 - val_accuracy: 0.5240\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1522 - accuracy: 0.5740 - val_loss: 1.7364 - val_accuracy: 0.5220\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1547 - accuracy: 0.5615 - val_loss: 1.7563 - val_accuracy: 0.5220\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1458 - accuracy: 0.5500 - val_loss: 1.7627 - val_accuracy: 0.5220\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1629 - accuracy: 0.5520 - val_loss: 1.7446 - val_accuracy: 0.5160\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1402 - accuracy: 0.5620 - val_loss: 1.7274 - val_accuracy: 0.5120\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1420 - accuracy: 0.5600 - val_loss: 1.7072 - val_accuracy: 0.5100\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1266 - accuracy: 0.5830 - val_loss: 1.7036 - val_accuracy: 0.5200\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1605 - accuracy: 0.5670 - val_loss: 1.7132 - val_accuracy: 0.5120\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1292 - accuracy: 0.5725 - val_loss: 1.7236 - val_accuracy: 0.5180\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1443 - accuracy: 0.5775 - val_loss: 1.7359 - val_accuracy: 0.5040\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1532 - accuracy: 0.5665 - val_loss: 1.7423 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.1434 - accuracy: 0.5655 - val_loss: 1.7516 - val_accuracy: 0.5020\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1239 - accuracy: 0.5705 - val_loss: 1.7496 - val_accuracy: 0.5060\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.1737 - accuracy: 0.5680 - val_loss: 1.7499 - val_accuracy: 0.5080\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.1512 - accuracy: 0.5685 - val_loss: 1.7556 - val_accuracy: 0.5060\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.1556 - accuracy: 0.5690 - val_loss: 1.7671 - val_accuracy: 0.4980\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1329 - accuracy: 0.5560 - val_loss: 1.7723 - val_accuracy: 0.4980\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1391 - accuracy: 0.5560 - val_loss: 1.7641 - val_accuracy: 0.5040\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.1902 - accuracy: 0.5405 - val_loss: 1.7579 - val_accuracy: 0.5140\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.1485 - accuracy: 0.5590 - val_loss: 1.7692 - val_accuracy: 0.5160\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 547us/step - loss: 1.1688 - accuracy: 0.5595 - val_loss: 1.7751 - val_accuracy: 0.5080\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1417 - accuracy: 0.5610 - val_loss: 1.7628 - val_accuracy: 0.5120\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1568 - accuracy: 0.5595 - val_loss: 1.7560 - val_accuracy: 0.5100\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.1507 - accuracy: 0.5635 - val_loss: 1.7429 - val_accuracy: 0.5240\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.1087 - accuracy: 0.5675 - val_loss: 1.7440 - val_accuracy: 0.5140\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 545us/step - loss: 1.1154 - accuracy: 0.5835 - val_loss: 1.7407 - val_accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1648 - accuracy: 0.5560 - val_loss: 1.7722 - val_accuracy: 0.5200\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1725 - accuracy: 0.5580 - val_loss: 1.7868 - val_accuracy: 0.5420\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.1301 - accuracy: 0.5665 - val_loss: 1.7630 - val_accuracy: 0.5360\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.1650 - accuracy: 0.5515 - val_loss: 1.7392 - val_accuracy: 0.5280\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1345 - accuracy: 0.5620 - val_loss: 1.7340 - val_accuracy: 0.5160\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1682 - accuracy: 0.5530 - val_loss: 1.7524 - val_accuracy: 0.5220\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 546us/step - loss: 1.1120 - accuracy: 0.5795 - val_loss: 1.7693 - val_accuracy: 0.5180\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1163 - accuracy: 0.5805 - val_loss: 1.7627 - val_accuracy: 0.4960\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.1183 - accuracy: 0.5740 - val_loss: 1.7615 - val_accuracy: 0.4900\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1227 - accuracy: 0.5715 - val_loss: 1.7686 - val_accuracy: 0.4980\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 646us/step - loss: 1.1426 - accuracy: 0.5675 - val_loss: 1.7783 - val_accuracy: 0.5080\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 628us/step - loss: 1.1326 - accuracy: 0.5615 - val_loss: 1.7803 - val_accuracy: 0.5080\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.1466 - accuracy: 0.5670 - val_loss: 1.7799 - val_accuracy: 0.5040\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.0998 - accuracy: 0.5870 - val_loss: 1.7882 - val_accuracy: 0.5060\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.1695 - accuracy: 0.5630 - val_loss: 1.7983 - val_accuracy: 0.5040\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1410 - accuracy: 0.5550 - val_loss: 1.8114 - val_accuracy: 0.4980\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.1137 - accuracy: 0.5755 - val_loss: 1.7953 - val_accuracy: 0.4960\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.1177 - accuracy: 0.5700 - val_loss: 1.7742 - val_accuracy: 0.5100\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1119 - accuracy: 0.5645 - val_loss: 1.7687 - val_accuracy: 0.5180\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1205 - accuracy: 0.5730 - val_loss: 1.7654 - val_accuracy: 0.5140\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.1263 - accuracy: 0.5725 - val_loss: 1.7543 - val_accuracy: 0.5240\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1145 - accuracy: 0.5745 - val_loss: 1.7866 - val_accuracy: 0.5180\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.0949 - accuracy: 0.5675 - val_loss: 1.7858 - val_accuracy: 0.5140\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.0909 - accuracy: 0.5855 - val_loss: 1.7785 - val_accuracy: 0.5080\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.1082 - accuracy: 0.5830 - val_loss: 1.7924 - val_accuracy: 0.5160\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1436 - accuracy: 0.5755 - val_loss: 1.7923 - val_accuracy: 0.5120\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.1004 - accuracy: 0.5820 - val_loss: 1.8099 - val_accuracy: 0.5180\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1304 - accuracy: 0.5695 - val_loss: 1.8265 - val_accuracy: 0.5220\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1051 - accuracy: 0.5810 - val_loss: 1.8040 - val_accuracy: 0.5120\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.0852 - accuracy: 0.5770 - val_loss: 1.7648 - val_accuracy: 0.5180\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 549us/step - loss: 1.1415 - accuracy: 0.5765 - val_loss: 1.7473 - val_accuracy: 0.5260\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1108 - accuracy: 0.5735 - val_loss: 1.7510 - val_accuracy: 0.5260\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.1327 - accuracy: 0.5900 - val_loss: 1.7762 - val_accuracy: 0.5220\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.1394 - accuracy: 0.5660 - val_loss: 1.7743 - val_accuracy: 0.5240\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1269 - accuracy: 0.5755 - val_loss: 1.7605 - val_accuracy: 0.5320\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 542us/step - loss: 1.1312 - accuracy: 0.5670 - val_loss: 1.7418 - val_accuracy: 0.5480\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 535us/step - loss: 1.0863 - accuracy: 0.5810 - val_loss: 1.7518 - val_accuracy: 0.5320\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.1190 - accuracy: 0.5845 - val_loss: 1.7786 - val_accuracy: 0.5220\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.0910 - accuracy: 0.5860 - val_loss: 1.8317 - val_accuracy: 0.5260\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1007 - accuracy: 0.5730 - val_loss: 1.8293 - val_accuracy: 0.5180\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.1110 - accuracy: 0.5745 - val_loss: 1.8195 - val_accuracy: 0.5160\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0830 - accuracy: 0.6010 - val_loss: 1.8181 - val_accuracy: 0.5180\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 1.0719 - accuracy: 0.5845 - val_loss: 1.8101 - val_accuracy: 0.5260\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1055 - accuracy: 0.5745 - val_loss: 1.8004 - val_accuracy: 0.5360\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.1270 - accuracy: 0.5885 - val_loss: 1.8190 - val_accuracy: 0.5300\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1126 - accuracy: 0.5775 - val_loss: 1.8289 - val_accuracy: 0.5360\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 540us/step - loss: 1.1427 - accuracy: 0.5740 - val_loss: 1.8006 - val_accuracy: 0.5240\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.0896 - accuracy: 0.5900 - val_loss: 1.8195 - val_accuracy: 0.5200\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 545us/step - loss: 1.1238 - accuracy: 0.5820 - val_loss: 1.8268 - val_accuracy: 0.5180\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 617us/step - loss: 1.0825 - accuracy: 0.5955 - val_loss: 1.8363 - val_accuracy: 0.5200\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0789 - accuracy: 0.5915 - val_loss: 1.8463 - val_accuracy: 0.5300\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.1299 - accuracy: 0.5770 - val_loss: 1.8199 - val_accuracy: 0.5200\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.1380 - accuracy: 0.5690 - val_loss: 1.8195 - val_accuracy: 0.5200\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.1158 - accuracy: 0.5665 - val_loss: 1.8159 - val_accuracy: 0.5200\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.0931 - accuracy: 0.5845 - val_loss: 1.8199 - val_accuracy: 0.5260\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.1262 - accuracy: 0.5715 - val_loss: 1.7804 - val_accuracy: 0.5220\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.1155 - accuracy: 0.5645 - val_loss: 1.7704 - val_accuracy: 0.5320\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.0875 - accuracy: 0.5935 - val_loss: 1.7997 - val_accuracy: 0.5260\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 539us/step - loss: 1.1064 - accuracy: 0.5835 - val_loss: 1.8193 - val_accuracy: 0.5160\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 537us/step - loss: 1.0875 - accuracy: 0.5950 - val_loss: 1.8457 - val_accuracy: 0.5240\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.1051 - accuracy: 0.5835 - val_loss: 1.8510 - val_accuracy: 0.5300\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 541us/step - loss: 1.0857 - accuracy: 0.5885 - val_loss: 1.8411 - val_accuracy: 0.5360\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 543us/step - loss: 1.1468 - accuracy: 0.5785 - val_loss: 1.8232 - val_accuracy: 0.5180\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.1152 - accuracy: 0.5980 - val_loss: 1.8342 - val_accuracy: 0.5200\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 548us/step - loss: 1.0793 - accuracy: 0.5890 - val_loss: 1.8319 - val_accuracy: 0.5140\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.0705 - accuracy: 0.5955 - val_loss: 1.8113 - val_accuracy: 0.5180\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 544us/step - loss: 1.1165 - accuracy: 0.5695 - val_loss: 1.8214 - val_accuracy: 0.5100\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 1.0899 - accuracy: 0.5850 - val_loss: 1.7960 - val_accuracy: 0.5120\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.1011 - accuracy: 0.5785 - val_loss: 1.8202 - val_accuracy: 0.5300\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 523us/step - loss: 1.0889 - accuracy: 0.5885 - val_loss: 1.8280 - val_accuracy: 0.5180\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.1254 - accuracy: 0.5790 - val_loss: 1.8340 - val_accuracy: 0.5160\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.0680 - accuracy: 0.5915 - val_loss: 1.8179 - val_accuracy: 0.5140\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.1151 - accuracy: 0.5855 - val_loss: 1.8321 - val_accuracy: 0.5280\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1158 - accuracy: 0.5965 - val_loss: 1.8528 - val_accuracy: 0.5160\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.0725 - accuracy: 0.5870 - val_loss: 1.8995 - val_accuracy: 0.5280\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1010 - accuracy: 0.5940 - val_loss: 1.8971 - val_accuracy: 0.5200\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 524us/step - loss: 1.0831 - accuracy: 0.5925 - val_loss: 1.8889 - val_accuracy: 0.5220\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 530us/step - loss: 1.0655 - accuracy: 0.6025 - val_loss: 1.8896 - val_accuracy: 0.5020\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.0995 - accuracy: 0.5850 - val_loss: 1.8889 - val_accuracy: 0.5040\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 527us/step - loss: 1.1029 - accuracy: 0.5720 - val_loss: 1.8864 - val_accuracy: 0.5060\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.0798 - accuracy: 0.5865 - val_loss: 1.8805 - val_accuracy: 0.5080\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.0870 - accuracy: 0.5895 - val_loss: 1.8502 - val_accuracy: 0.5060\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 525us/step - loss: 1.1019 - accuracy: 0.5880 - val_loss: 1.8521 - val_accuracy: 0.5100\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 522us/step - loss: 1.1114 - accuracy: 0.5785 - val_loss: 1.8694 - val_accuracy: 0.5100\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1321 - accuracy: 0.5710 - val_loss: 1.8688 - val_accuracy: 0.5020\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 1.1086 - accuracy: 0.5770 - val_loss: 1.8312 - val_accuracy: 0.4940\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.1238 - accuracy: 0.5805 - val_loss: 1.8514 - val_accuracy: 0.4980\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 526us/step - loss: 1.0985 - accuracy: 0.5850 - val_loss: 1.8557 - val_accuracy: 0.5060\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.1015 - accuracy: 0.5715 - val_loss: 1.8580 - val_accuracy: 0.5200\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 534us/step - loss: 1.0864 - accuracy: 0.5780 - val_loss: 1.8570 - val_accuracy: 0.5260\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 531us/step - loss: 1.0541 - accuracy: 0.5895 - val_loss: 1.8659 - val_accuracy: 0.5200\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.1063 - accuracy: 0.5855 - val_loss: 1.8714 - val_accuracy: 0.5180\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0958 - accuracy: 0.5845 - val_loss: 1.8741 - val_accuracy: 0.5160\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.0895 - accuracy: 0.5960 - val_loss: 1.8750 - val_accuracy: 0.5160\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 1.0891 - accuracy: 0.5815 - val_loss: 1.8747 - val_accuracy: 0.5160\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.1046 - accuracy: 0.5705 - val_loss: 1.8761 - val_accuracy: 0.5160\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0666 - accuracy: 0.5870 - val_loss: 1.8774 - val_accuracy: 0.5160\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.0708 - accuracy: 0.5900 - val_loss: 1.8777 - val_accuracy: 0.5120\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1041 - accuracy: 0.5785 - val_loss: 1.8778 - val_accuracy: 0.5100\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.1027 - accuracy: 0.5865 - val_loss: 1.8733 - val_accuracy: 0.5160\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.0858 - accuracy: 0.5890 - val_loss: 1.8741 - val_accuracy: 0.5100\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 623us/step - loss: 1.0898 - accuracy: 0.5865 - val_loss: 1.8705 - val_accuracy: 0.5140\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 1.1151 - accuracy: 0.5925 - val_loss: 1.8698 - val_accuracy: 0.5160\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.0466 - accuracy: 0.6035 - val_loss: 1.8673 - val_accuracy: 0.5180\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 1.0683 - accuracy: 0.5905 - val_loss: 1.8677 - val_accuracy: 0.5180\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.0904 - accuracy: 0.5975 - val_loss: 1.8686 - val_accuracy: 0.5180\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.0913 - accuracy: 0.5890 - val_loss: 1.8692 - val_accuracy: 0.5200\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 612us/step - loss: 1.0558 - accuracy: 0.5950 - val_loss: 1.8722 - val_accuracy: 0.5180\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 1.0936 - accuracy: 0.5805 - val_loss: 1.8774 - val_accuracy: 0.5160\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.0465 - accuracy: 0.6035 - val_loss: 1.8808 - val_accuracy: 0.5180\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 600us/step - loss: 1.0608 - accuracy: 0.5915 - val_loss: 1.8791 - val_accuracy: 0.5200\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.0957 - accuracy: 0.5800 - val_loss: 1.8806 - val_accuracy: 0.5200\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.0418 - accuracy: 0.5995 - val_loss: 1.8786 - val_accuracy: 0.5160\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.0390 - accuracy: 0.6005 - val_loss: 1.8815 - val_accuracy: 0.5180\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.0514 - accuracy: 0.6095 - val_loss: 1.8827 - val_accuracy: 0.5200\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0527 - accuracy: 0.6020 - val_loss: 1.8796 - val_accuracy: 0.5220\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.0632 - accuracy: 0.5940 - val_loss: 1.8784 - val_accuracy: 0.5220\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 582us/step - loss: 1.0436 - accuracy: 0.5980 - val_loss: 1.8771 - val_accuracy: 0.5240\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 627us/step - loss: 1.0791 - accuracy: 0.5890 - val_loss: 1.8749 - val_accuracy: 0.5200\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 600us/step - loss: 1.0352 - accuracy: 0.6000 - val_loss: 1.8705 - val_accuracy: 0.5200\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.0813 - accuracy: 0.5895 - val_loss: 1.8740 - val_accuracy: 0.5220\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 637us/step - loss: 1.0659 - accuracy: 0.5820 - val_loss: 1.8743 - val_accuracy: 0.5220\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0704 - accuracy: 0.5935 - val_loss: 1.8748 - val_accuracy: 0.5160\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 1.0492 - accuracy: 0.5985 - val_loss: 1.8740 - val_accuracy: 0.5140\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 603us/step - loss: 1.0294 - accuracy: 0.6080 - val_loss: 1.8752 - val_accuracy: 0.5160\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0622 - accuracy: 0.5955 - val_loss: 1.8775 - val_accuracy: 0.5140\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0759 - accuracy: 0.5805 - val_loss: 1.8789 - val_accuracy: 0.5160\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.0759 - accuracy: 0.5910 - val_loss: 1.8778 - val_accuracy: 0.5180\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 625us/step - loss: 1.0715 - accuracy: 0.5975 - val_loss: 1.8760 - val_accuracy: 0.5220\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 637us/step - loss: 1.0561 - accuracy: 0.5995 - val_loss: 1.8751 - val_accuracy: 0.5240\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 614us/step - loss: 1.0486 - accuracy: 0.6060 - val_loss: 1.8757 - val_accuracy: 0.5220\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 600us/step - loss: 1.0602 - accuracy: 0.5970 - val_loss: 1.8732 - val_accuracy: 0.5220\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.0712 - accuracy: 0.6105 - val_loss: 1.8729 - val_accuracy: 0.5240\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 615us/step - loss: 1.0464 - accuracy: 0.6170 - val_loss: 1.8775 - val_accuracy: 0.5220\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 693us/step - loss: 1.0864 - accuracy: 0.5950 - val_loss: 1.8748 - val_accuracy: 0.5220\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 593us/step - loss: 1.0494 - accuracy: 0.6050 - val_loss: 1.8751 - val_accuracy: 0.5220\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0467 - accuracy: 0.6045 - val_loss: 1.8796 - val_accuracy: 0.5180\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 1.0631 - accuracy: 0.5990 - val_loss: 1.8763 - val_accuracy: 0.5180\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.0555 - accuracy: 0.6015 - val_loss: 1.8783 - val_accuracy: 0.5180\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.0931 - accuracy: 0.5850 - val_loss: 1.8730 - val_accuracy: 0.5140\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.0471 - accuracy: 0.5870 - val_loss: 1.8744 - val_accuracy: 0.5140\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 595us/step - loss: 1.0694 - accuracy: 0.5880 - val_loss: 1.8742 - val_accuracy: 0.5140\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.0298 - accuracy: 0.5965 - val_loss: 1.8754 - val_accuracy: 0.5160\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0543 - accuracy: 0.5990 - val_loss: 1.8797 - val_accuracy: 0.5160\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0775 - accuracy: 0.5890 - val_loss: 1.8832 - val_accuracy: 0.5180\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 603us/step - loss: 1.0524 - accuracy: 0.6010 - val_loss: 1.8840 - val_accuracy: 0.5200\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.0545 - accuracy: 0.6175 - val_loss: 1.8850 - val_accuracy: 0.5120\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.0928 - accuracy: 0.5780 - val_loss: 1.8830 - val_accuracy: 0.5160\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.0206 - accuracy: 0.6200 - val_loss: 1.8800 - val_accuracy: 0.5180\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 578us/step - loss: 1.0182 - accuracy: 0.6025 - val_loss: 1.8783 - val_accuracy: 0.5220\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.0726 - accuracy: 0.5860 - val_loss: 1.8781 - val_accuracy: 0.5220\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.0742 - accuracy: 0.5880 - val_loss: 1.8814 - val_accuracy: 0.5220\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 602us/step - loss: 1.0825 - accuracy: 0.6085 - val_loss: 1.8826 - val_accuracy: 0.5180\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.0806 - accuracy: 0.6065 - val_loss: 1.8813 - val_accuracy: 0.5200\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0473 - accuracy: 0.5970 - val_loss: 1.8856 - val_accuracy: 0.5220\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.0633 - accuracy: 0.6140 - val_loss: 1.8921 - val_accuracy: 0.5240\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0668 - accuracy: 0.6085 - val_loss: 1.8959 - val_accuracy: 0.5260\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 581us/step - loss: 1.0520 - accuracy: 0.6065 - val_loss: 1.8984 - val_accuracy: 0.5220\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 613us/step - loss: 1.0165 - accuracy: 0.6100 - val_loss: 1.8990 - val_accuracy: 0.5180\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0571 - accuracy: 0.6015 - val_loss: 1.9022 - val_accuracy: 0.5140\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0548 - accuracy: 0.5990 - val_loss: 1.8996 - val_accuracy: 0.5180\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.0380 - accuracy: 0.6070 - val_loss: 1.8999 - val_accuracy: 0.5180\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 586us/step - loss: 1.0603 - accuracy: 0.6090 - val_loss: 1.9004 - val_accuracy: 0.5180\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0645 - accuracy: 0.6125 - val_loss: 1.8978 - val_accuracy: 0.5220\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.0648 - accuracy: 0.5980 - val_loss: 1.8963 - val_accuracy: 0.5220\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.0291 - accuracy: 0.6045 - val_loss: 1.8949 - val_accuracy: 0.5260\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.0349 - accuracy: 0.6030 - val_loss: 1.8927 - val_accuracy: 0.5320\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 611us/step - loss: 1.0755 - accuracy: 0.5920 - val_loss: 1.8916 - val_accuracy: 0.5260\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.0233 - accuracy: 0.6285 - val_loss: 1.8939 - val_accuracy: 0.5280\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0610 - accuracy: 0.6000 - val_loss: 1.8967 - val_accuracy: 0.5260\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.0563 - accuracy: 0.6110 - val_loss: 1.9016 - val_accuracy: 0.5280\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0888 - accuracy: 0.5920 - val_loss: 1.9018 - val_accuracy: 0.5260\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 615us/step - loss: 1.0231 - accuracy: 0.6185 - val_loss: 1.9049 - val_accuracy: 0.5260\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.1030 - accuracy: 0.5895 - val_loss: 1.9061 - val_accuracy: 0.5260\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0594 - accuracy: 0.5985 - val_loss: 1.9031 - val_accuracy: 0.5260\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.1105 - accuracy: 0.5915 - val_loss: 1.9058 - val_accuracy: 0.5220\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.0875 - accuracy: 0.5770 - val_loss: 1.9072 - val_accuracy: 0.5240\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0531 - accuracy: 0.6025 - val_loss: 1.9031 - val_accuracy: 0.5120\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.0603 - accuracy: 0.5955 - val_loss: 1.9003 - val_accuracy: 0.5120\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 603us/step - loss: 1.0279 - accuracy: 0.6125 - val_loss: 1.8970 - val_accuracy: 0.5160\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0460 - accuracy: 0.6055 - val_loss: 1.8986 - val_accuracy: 0.5160\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.0882 - accuracy: 0.5965 - val_loss: 1.8972 - val_accuracy: 0.5120\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0387 - accuracy: 0.6050 - val_loss: 1.8978 - val_accuracy: 0.5080\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.0359 - accuracy: 0.5990 - val_loss: 1.8980 - val_accuracy: 0.5100\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0438 - accuracy: 0.5980 - val_loss: 1.8972 - val_accuracy: 0.5140\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0751 - accuracy: 0.5960 - val_loss: 1.9012 - val_accuracy: 0.5140\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0455 - accuracy: 0.6115 - val_loss: 1.9036 - val_accuracy: 0.5140\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.0890 - accuracy: 0.5960 - val_loss: 1.9061 - val_accuracy: 0.5160\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.1070 - accuracy: 0.5965 - val_loss: 1.9050 - val_accuracy: 0.5120\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.0387 - accuracy: 0.6075 - val_loss: 1.9067 - val_accuracy: 0.5140\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0688 - accuracy: 0.5900 - val_loss: 1.9055 - val_accuracy: 0.5120\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0949 - accuracy: 0.5940 - val_loss: 1.9027 - val_accuracy: 0.5140\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0756 - accuracy: 0.6020 - val_loss: 1.9064 - val_accuracy: 0.5140\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0351 - accuracy: 0.5915 - val_loss: 1.9101 - val_accuracy: 0.5160\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0269 - accuracy: 0.6150 - val_loss: 1.9103 - val_accuracy: 0.5100\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.0561 - accuracy: 0.5925 - val_loss: 1.9098 - val_accuracy: 0.5100\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0554 - accuracy: 0.6015 - val_loss: 1.9096 - val_accuracy: 0.5060\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 590us/step - loss: 1.0660 - accuracy: 0.6150 - val_loss: 1.9092 - val_accuracy: 0.5100\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0543 - accuracy: 0.5955 - val_loss: 1.9078 - val_accuracy: 0.5080\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0450 - accuracy: 0.6135 - val_loss: 1.9094 - val_accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0602 - accuracy: 0.6010 - val_loss: 1.9140 - val_accuracy: 0.5140\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0812 - accuracy: 0.6110 - val_loss: 1.9163 - val_accuracy: 0.5140\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0677 - accuracy: 0.5750 - val_loss: 1.9176 - val_accuracy: 0.5140\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0680 - accuracy: 0.6040 - val_loss: 1.9212 - val_accuracy: 0.5140\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 554us/step - loss: 1.0995 - accuracy: 0.5950 - val_loss: 1.9201 - val_accuracy: 0.5120\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0522 - accuracy: 0.5905 - val_loss: 1.9160 - val_accuracy: 0.5140\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0468 - accuracy: 0.6070 - val_loss: 1.9134 - val_accuracy: 0.5120\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0668 - accuracy: 0.5985 - val_loss: 1.9143 - val_accuracy: 0.5100\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.0529 - accuracy: 0.6305 - val_loss: 1.9140 - val_accuracy: 0.5120\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0295 - accuracy: 0.6100 - val_loss: 1.9169 - val_accuracy: 0.5100\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0174 - accuracy: 0.6170 - val_loss: 1.9177 - val_accuracy: 0.5160\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0366 - accuracy: 0.6110 - val_loss: 1.9209 - val_accuracy: 0.5120\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0557 - accuracy: 0.6010 - val_loss: 1.9253 - val_accuracy: 0.5140\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0629 - accuracy: 0.5915 - val_loss: 1.9204 - val_accuracy: 0.5140\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0681 - accuracy: 0.6030 - val_loss: 1.9159 - val_accuracy: 0.5120\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0474 - accuracy: 0.6100 - val_loss: 1.9152 - val_accuracy: 0.5140\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 606us/step - loss: 1.0580 - accuracy: 0.6015 - val_loss: 1.9153 - val_accuracy: 0.5200\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.0416 - accuracy: 0.6015 - val_loss: 1.9191 - val_accuracy: 0.5220\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 667us/step - loss: 1.0568 - accuracy: 0.5990 - val_loss: 1.9243 - val_accuracy: 0.5200\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.0686 - accuracy: 0.5905 - val_loss: 1.9263 - val_accuracy: 0.5180\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 647us/step - loss: 1.0280 - accuracy: 0.6085 - val_loss: 1.9271 - val_accuracy: 0.5140\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 585us/step - loss: 1.0740 - accuracy: 0.5890 - val_loss: 1.9261 - val_accuracy: 0.5140\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0275 - accuracy: 0.6105 - val_loss: 1.9226 - val_accuracy: 0.5200\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 583us/step - loss: 1.0262 - accuracy: 0.5975 - val_loss: 1.9204 - val_accuracy: 0.5240\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 574us/step - loss: 1.0438 - accuracy: 0.6090 - val_loss: 1.9213 - val_accuracy: 0.5180\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.0474 - accuracy: 0.5995 - val_loss: 1.9182 - val_accuracy: 0.5220\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.0683 - accuracy: 0.5920 - val_loss: 1.9180 - val_accuracy: 0.5240\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.0620 - accuracy: 0.5995 - val_loss: 1.9176 - val_accuracy: 0.5220\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 571us/step - loss: 1.0742 - accuracy: 0.6005 - val_loss: 1.9140 - val_accuracy: 0.5200\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0398 - accuracy: 0.5990 - val_loss: 1.9124 - val_accuracy: 0.5180\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0254 - accuracy: 0.6115 - val_loss: 1.9162 - val_accuracy: 0.5160\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0488 - accuracy: 0.5960 - val_loss: 1.9167 - val_accuracy: 0.5260\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0968 - accuracy: 0.5850 - val_loss: 1.9154 - val_accuracy: 0.5220\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 565us/step - loss: 1.0640 - accuracy: 0.5895 - val_loss: 1.9163 - val_accuracy: 0.5200\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0560 - accuracy: 0.6090 - val_loss: 1.9187 - val_accuracy: 0.5200\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0428 - accuracy: 0.6095 - val_loss: 1.9232 - val_accuracy: 0.5200\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0660 - accuracy: 0.5900 - val_loss: 1.9205 - val_accuracy: 0.5140\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 553us/step - loss: 1.0611 - accuracy: 0.5950 - val_loss: 1.9176 - val_accuracy: 0.5120\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0709 - accuracy: 0.5855 - val_loss: 1.9141 - val_accuracy: 0.5180\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0528 - accuracy: 0.6015 - val_loss: 1.9102 - val_accuracy: 0.5140\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0221 - accuracy: 0.6150 - val_loss: 1.9083 - val_accuracy: 0.5160\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0441 - accuracy: 0.5975 - val_loss: 1.9115 - val_accuracy: 0.5140\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0652 - accuracy: 0.5870 - val_loss: 1.9085 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 591us/step - loss: 1.0632 - accuracy: 0.6110 - val_loss: 1.9073 - val_accuracy: 0.5160\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.0621 - accuracy: 0.6065 - val_loss: 1.9075 - val_accuracy: 0.5140\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.0527 - accuracy: 0.6000 - val_loss: 1.9058 - val_accuracy: 0.5160\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0614 - accuracy: 0.5975 - val_loss: 1.9069 - val_accuracy: 0.5160\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 557us/step - loss: 1.0516 - accuracy: 0.6095 - val_loss: 1.9065 - val_accuracy: 0.5140\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0303 - accuracy: 0.6035 - val_loss: 1.9082 - val_accuracy: 0.5140\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0499 - accuracy: 0.6005 - val_loss: 1.9072 - val_accuracy: 0.5140\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 615us/step - loss: 1.0500 - accuracy: 0.6020 - val_loss: 1.9074 - val_accuracy: 0.5140\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0236 - accuracy: 0.5935 - val_loss: 1.9057 - val_accuracy: 0.5160\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.0490 - accuracy: 0.6115 - val_loss: 1.9074 - val_accuracy: 0.5140\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 575us/step - loss: 1.0193 - accuracy: 0.6140 - val_loss: 1.9102 - val_accuracy: 0.5180\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0948 - accuracy: 0.5905 - val_loss: 1.9139 - val_accuracy: 0.5200\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.0908 - accuracy: 0.5855 - val_loss: 1.9167 - val_accuracy: 0.5200\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.0456 - accuracy: 0.6085 - val_loss: 1.9162 - val_accuracy: 0.5220\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0733 - accuracy: 0.5995 - val_loss: 1.9170 - val_accuracy: 0.5200\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 605us/step - loss: 1.0994 - accuracy: 0.5895 - val_loss: 1.9188 - val_accuracy: 0.5220\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0706 - accuracy: 0.5905 - val_loss: 1.9132 - val_accuracy: 0.5220\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0663 - accuracy: 0.5945 - val_loss: 1.9086 - val_accuracy: 0.5220\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0552 - accuracy: 0.5970 - val_loss: 1.9042 - val_accuracy: 0.5260\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 576us/step - loss: 1.0796 - accuracy: 0.6150 - val_loss: 1.9093 - val_accuracy: 0.5260\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0711 - accuracy: 0.5970 - val_loss: 1.9085 - val_accuracy: 0.5220\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 572us/step - loss: 1.0434 - accuracy: 0.6160 - val_loss: 1.9061 - val_accuracy: 0.5160\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0576 - accuracy: 0.6115 - val_loss: 1.9062 - val_accuracy: 0.5160\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0413 - accuracy: 0.6015 - val_loss: 1.9049 - val_accuracy: 0.5180\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0220 - accuracy: 0.6130 - val_loss: 1.9054 - val_accuracy: 0.5180\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0044 - accuracy: 0.6180 - val_loss: 1.9094 - val_accuracy: 0.5180\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0784 - accuracy: 0.5825 - val_loss: 1.9117 - val_accuracy: 0.5220\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0501 - accuracy: 0.6060 - val_loss: 1.9146 - val_accuracy: 0.5200\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0271 - accuracy: 0.6105 - val_loss: 1.9170 - val_accuracy: 0.5220\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0476 - accuracy: 0.6140 - val_loss: 1.9161 - val_accuracy: 0.5180\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0793 - accuracy: 0.5930 - val_loss: 1.9167 - val_accuracy: 0.5180\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.0118 - accuracy: 0.6335 - val_loss: 1.9111 - val_accuracy: 0.5140\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 597us/step - loss: 1.0289 - accuracy: 0.6140 - val_loss: 1.9108 - val_accuracy: 0.5140\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0850 - accuracy: 0.6020 - val_loss: 1.9096 - val_accuracy: 0.5080\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0466 - accuracy: 0.6025 - val_loss: 1.9076 - val_accuracy: 0.5120\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 567us/step - loss: 1.0810 - accuracy: 0.5930 - val_loss: 1.9054 - val_accuracy: 0.5180\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 570us/step - loss: 1.0442 - accuracy: 0.5875 - val_loss: 1.9069 - val_accuracy: 0.5220\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.1020 - accuracy: 0.5895 - val_loss: 1.9134 - val_accuracy: 0.5200\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0234 - accuracy: 0.6040 - val_loss: 1.9173 - val_accuracy: 0.5180\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 594us/step - loss: 1.0469 - accuracy: 0.5895 - val_loss: 1.9212 - val_accuracy: 0.5180\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0185 - accuracy: 0.6275 - val_loss: 1.9227 - val_accuracy: 0.5180\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 1.0380 - accuracy: 0.6085 - val_loss: 1.9189 - val_accuracy: 0.5180\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 564us/step - loss: 1.0156 - accuracy: 0.6155 - val_loss: 1.9177 - val_accuracy: 0.5180\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 563us/step - loss: 1.0295 - accuracy: 0.6290 - val_loss: 1.9158 - val_accuracy: 0.5160\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 569us/step - loss: 1.0700 - accuracy: 0.6105 - val_loss: 1.9141 - val_accuracy: 0.5120\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.0262 - accuracy: 0.6040 - val_loss: 1.9128 - val_accuracy: 0.5180\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0371 - accuracy: 0.6135 - val_loss: 1.9120 - val_accuracy: 0.5160\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.0624 - accuracy: 0.5985 - val_loss: 1.9120 - val_accuracy: 0.5160\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.0309 - accuracy: 0.6210 - val_loss: 1.9143 - val_accuracy: 0.5160\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0654 - accuracy: 0.6035 - val_loss: 1.9150 - val_accuracy: 0.5140\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0372 - accuracy: 0.6135 - val_loss: 1.9161 - val_accuracy: 0.5160\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 568us/step - loss: 1.0444 - accuracy: 0.6145 - val_loss: 1.9150 - val_accuracy: 0.5160\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0285 - accuracy: 0.6130 - val_loss: 1.9166 - val_accuracy: 0.5160\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 561us/step - loss: 1.0884 - accuracy: 0.5870 - val_loss: 1.9167 - val_accuracy: 0.5160\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 580us/step - loss: 1.0287 - accuracy: 0.6100 - val_loss: 1.9156 - val_accuracy: 0.5160\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 566us/step - loss: 1.0842 - accuracy: 0.5935 - val_loss: 1.9152 - val_accuracy: 0.5160\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0466 - accuracy: 0.5945 - val_loss: 1.9150 - val_accuracy: 0.5160\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 558us/step - loss: 1.0200 - accuracy: 0.6105 - val_loss: 1.9157 - val_accuracy: 0.5160\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.0337 - accuracy: 0.6130 - val_loss: 1.9149 - val_accuracy: 0.5160\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 562us/step - loss: 1.0160 - accuracy: 0.6290 - val_loss: 1.9157 - val_accuracy: 0.5160\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 555us/step - loss: 1.0604 - accuracy: 0.6105 - val_loss: 1.9176 - val_accuracy: 0.5160\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 559us/step - loss: 1.0175 - accuracy: 0.6085 - val_loss: 1.9181 - val_accuracy: 0.5120\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 579us/step - loss: 1.0802 - accuracy: 0.6025 - val_loss: 1.9184 - val_accuracy: 0.5120\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 685us/step - loss: 1.0466 - accuracy: 0.6015 - val_loss: 1.9181 - val_accuracy: 0.5180\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 2s 799us/step - loss: 1.0488 - accuracy: 0.6170 - val_loss: 1.9193 - val_accuracy: 0.5180\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 2s 827us/step - loss: 1.0687 - accuracy: 0.5950 - val_loss: 1.9209 - val_accuracy: 0.5180\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 2s 766us/step - loss: 1.0347 - accuracy: 0.6010 - val_loss: 1.9206 - val_accuracy: 0.5160\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 730us/step - loss: 1.0315 - accuracy: 0.6085 - val_loss: 1.9207 - val_accuracy: 0.5160\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 641us/step - loss: 1.0507 - accuracy: 0.6200 - val_loss: 1.9196 - val_accuracy: 0.5160\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 1.0070 - accuracy: 0.6155 - val_loss: 1.9183 - val_accuracy: 0.5180\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 577us/step - loss: 1.0261 - accuracy: 0.6105 - val_loss: 1.9166 - val_accuracy: 0.5140\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 668us/step - loss: 1.0771 - accuracy: 0.5920 - val_loss: 1.9172 - val_accuracy: 0.5140\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 719us/step - loss: 1.0526 - accuracy: 0.6050 - val_loss: 1.9162 - val_accuracy: 0.5140\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 639us/step - loss: 1.0556 - accuracy: 0.6070 - val_loss: 1.9153 - val_accuracy: 0.5140\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 659us/step - loss: 1.0023 - accuracy: 0.6195 - val_loss: 1.9136 - val_accuracy: 0.5140\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 656us/step - loss: 1.0515 - accuracy: 0.6055 - val_loss: 1.9152 - val_accuracy: 0.5160\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 619us/step - loss: 1.0209 - accuracy: 0.6085 - val_loss: 1.9169 - val_accuracy: 0.5160\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 2s 773us/step - loss: 1.0736 - accuracy: 0.5940 - val_loss: 1.9165 - val_accuracy: 0.5140\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 678us/step - loss: 1.0549 - accuracy: 0.6050 - val_loss: 1.9165 - val_accuracy: 0.5160\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 2s 794us/step - loss: 1.0233 - accuracy: 0.6095 - val_loss: 1.9177 - val_accuracy: 0.5160\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 2s 973us/step - loss: 1.0385 - accuracy: 0.6100 - val_loss: 1.9179 - val_accuracy: 0.5160\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 727us/step - loss: 1.0285 - accuracy: 0.6120 - val_loss: 1.9180 - val_accuracy: 0.5180\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 595us/step - loss: 1.0562 - accuracy: 0.5995 - val_loss: 1.9192 - val_accuracy: 0.5180\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 612us/step - loss: 1.0442 - accuracy: 0.6035 - val_loss: 1.9195 - val_accuracy: 0.5180\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 723us/step - loss: 1.0683 - accuracy: 0.5975 - val_loss: 1.9191 - val_accuracy: 0.5180\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 2s 878us/step - loss: 1.0468 - accuracy: 0.5975 - val_loss: 1.9208 - val_accuracy: 0.5180\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 584us/step - loss: 1.0367 - accuracy: 0.6135 - val_loss: 1.9209 - val_accuracy: 0.5180\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.0308 - accuracy: 0.6255 - val_loss: 1.9217 - val_accuracy: 0.5200\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 634us/step - loss: 1.0436 - accuracy: 0.6170 - val_loss: 1.9227 - val_accuracy: 0.5180\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 2s 952us/step - loss: 1.0702 - accuracy: 0.5890 - val_loss: 1.9216 - val_accuracy: 0.5160\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 673us/step - loss: 1.0330 - accuracy: 0.6190 - val_loss: 1.9207 - val_accuracy: 0.5160\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 587us/step - loss: 1.0600 - accuracy: 0.6090 - val_loss: 1.9185 - val_accuracy: 0.5180\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 611us/step - loss: 1.0429 - accuracy: 0.6020 - val_loss: 1.9197 - val_accuracy: 0.5140\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 598us/step - loss: 1.0531 - accuracy: 0.6090 - val_loss: 1.9210 - val_accuracy: 0.5140\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 556us/step - loss: 1.0822 - accuracy: 0.5955 - val_loss: 1.9204 - val_accuracy: 0.5160\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 538us/step - loss: 1.0387 - accuracy: 0.6245 - val_loss: 1.9210 - val_accuracy: 0.5160\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 533us/step - loss: 1.0457 - accuracy: 0.6210 - val_loss: 1.9219 - val_accuracy: 0.5160\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 619us/step - loss: 1.0852 - accuracy: 0.5815 - val_loss: 1.9219 - val_accuracy: 0.5140\n",
      "--- 1323.4523620605469 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=50, batch_size=300)\n",
    "# print('lr=0.01, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=200, batch_size=250)\n",
    "# print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.000001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=200, batch_size=250)\n",
    "# print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=[X_test,y_test],epochs=50, batch_size=200)\n",
    "# print('lr=0.0001, train complete')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.argmax(model.predict(X_train), axis=1)\n",
    "accuracy_score(np.argmax(y_train, axis=1), a) \n",
    "pred=np.argmax(model.predict(X_test), axis=1)\n",
    "accuracy_score(np.argmax(y_test, axis=1), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(y)\n",
    "Y = Y[:,1:]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization(momentum = 0.88)(input_layer) \n",
    "x = Dense(22*10,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(22*8,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*4,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*2,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=4))(x) \n",
    "model = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 3.0605 - accuracy: 0.0915\n",
      "Epoch 2/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.6722 - accuracy: 0.1800\n",
      "Epoch 3/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.3326 - accuracy: 0.2590\n",
      "Epoch 4/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.1624 - accuracy: 0.2750\n",
      "Epoch 5/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 2.0459 - accuracy: 0.3095\n",
      "Epoch 6/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.9137 - accuracy: 0.3505\n",
      "Epoch 7/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.8161 - accuracy: 0.3820\n",
      "Epoch 8/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.7643 - accuracy: 0.4035\n",
      "Epoch 9/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6702 - accuracy: 0.4235\n",
      "Epoch 10/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.6019 - accuracy: 0.4630\n",
      "Epoch 11/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.5751 - accuracy: 0.4700\n",
      "Epoch 12/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.5444 - accuracy: 0.4725\n",
      "Epoch 13/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.5231 - accuracy: 0.4785\n",
      "Epoch 14/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.4361 - accuracy: 0.5045\n",
      "Epoch 15/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.4247 - accuracy: 0.5015\n",
      "Epoch 16/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.4051 - accuracy: 0.5110\n",
      "Epoch 17/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.3794 - accuracy: 0.5190\n",
      "Epoch 18/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.3223 - accuracy: 0.5405\n",
      "Epoch 19/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.2940 - accuracy: 0.5450\n",
      "Epoch 20/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.2917 - accuracy: 0.5420\n",
      "Epoch 21/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.2517 - accuracy: 0.5610\n",
      "Epoch 22/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.2256 - accuracy: 0.5770\n",
      "Epoch 23/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.1548 - accuracy: 0.5950\n",
      "Epoch 24/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.1559 - accuracy: 0.6010\n",
      "Epoch 25/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.1398 - accuracy: 0.6065\n",
      "Epoch 26/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0909 - accuracy: 0.6190\n",
      "Epoch 27/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0396 - accuracy: 0.6345\n",
      "Epoch 28/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0417 - accuracy: 0.6455\n",
      "Epoch 29/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0532 - accuracy: 0.6375\n",
      "Epoch 30/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9818 - accuracy: 0.6610\n",
      "Epoch 31/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0199 - accuracy: 0.6345\n",
      "Epoch 32/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9710 - accuracy: 0.6610\n",
      "Epoch 33/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9733 - accuracy: 0.6605\n",
      "Epoch 34/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9785 - accuracy: 0.6580\n",
      "Epoch 35/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9527 - accuracy: 0.6595\n",
      "Epoch 36/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9016 - accuracy: 0.6770\n",
      "Epoch 37/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8750 - accuracy: 0.6905\n",
      "Epoch 38/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.9042 - accuracy: 0.6825\n",
      "Epoch 39/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8895 - accuracy: 0.6985\n",
      "Epoch 40/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8523 - accuracy: 0.6980\n",
      "Epoch 41/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8334 - accuracy: 0.7165\n",
      "Epoch 42/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8361 - accuracy: 0.7115\n",
      "Epoch 43/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8532 - accuracy: 0.7075\n",
      "Epoch 44/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7976 - accuracy: 0.7220\n",
      "Epoch 45/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.8211 - accuracy: 0.7165\n",
      "Epoch 46/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7907 - accuracy: 0.7175\n",
      "Epoch 47/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7857 - accuracy: 0.7225\n",
      "Epoch 48/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7519 - accuracy: 0.7350\n",
      "Epoch 49/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7331 - accuracy: 0.7370\n",
      "Epoch 50/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6680 - accuracy: 0.7685\n",
      "Epoch 51/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7281 - accuracy: 0.7420\n",
      "Epoch 52/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6716 - accuracy: 0.7600\n",
      "Epoch 53/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6954 - accuracy: 0.7595\n",
      "Epoch 54/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6454 - accuracy: 0.7670\n",
      "Epoch 55/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6866 - accuracy: 0.7695\n",
      "Epoch 56/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.7206 - accuracy: 0.7510\n",
      "Epoch 57/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6694 - accuracy: 0.7795\n",
      "Epoch 58/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6545 - accuracy: 0.7805\n",
      "Epoch 59/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6028 - accuracy: 0.7920\n",
      "Epoch 60/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6501 - accuracy: 0.7875\n",
      "Epoch 61/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6543 - accuracy: 0.7825\n",
      "Epoch 62/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6270 - accuracy: 0.7795\n",
      "Epoch 63/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5788 - accuracy: 0.8005\n",
      "Epoch 64/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5634 - accuracy: 0.8070\n",
      "Epoch 65/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5781 - accuracy: 0.8065\n",
      "Epoch 66/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5674 - accuracy: 0.8010\n",
      "Epoch 67/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5462 - accuracy: 0.8165\n",
      "Epoch 68/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5668 - accuracy: 0.8005\n",
      "Epoch 69/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5306 - accuracy: 0.8205\n",
      "Epoch 70/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5380 - accuracy: 0.8160\n",
      "Epoch 71/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5046 - accuracy: 0.8380\n",
      "Epoch 72/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5390 - accuracy: 0.8145\n",
      "Epoch 73/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5343 - accuracy: 0.8245\n",
      "Epoch 74/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5090 - accuracy: 0.8305\n",
      "Epoch 75/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5237 - accuracy: 0.8205\n",
      "Epoch 76/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5240 - accuracy: 0.8190\n",
      "Epoch 77/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5155 - accuracy: 0.8280\n",
      "Epoch 78/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4808 - accuracy: 0.8365\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5406 - accuracy: 0.8255\n",
      "Epoch 80/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4956 - accuracy: 0.8265\n",
      "Epoch 81/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5067 - accuracy: 0.8260\n",
      "Epoch 82/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4232 - accuracy: 0.8575\n",
      "Epoch 83/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4719 - accuracy: 0.8395\n",
      "Epoch 84/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4303 - accuracy: 0.8515\n",
      "Epoch 85/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4456 - accuracy: 0.8535\n",
      "Epoch 86/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4756 - accuracy: 0.8380\n",
      "Epoch 87/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4008 - accuracy: 0.8550\n",
      "Epoch 88/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4262 - accuracy: 0.8650\n",
      "Epoch 89/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4326 - accuracy: 0.8550\n",
      "Epoch 90/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3937 - accuracy: 0.8670\n",
      "Epoch 91/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3944 - accuracy: 0.8730\n",
      "Epoch 92/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4157 - accuracy: 0.8560\n",
      "Epoch 93/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3823 - accuracy: 0.8750\n",
      "Epoch 94/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3611 - accuracy: 0.8710\n",
      "Epoch 95/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4075 - accuracy: 0.8700\n",
      "Epoch 96/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3510 - accuracy: 0.8770\n",
      "Epoch 97/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3687 - accuracy: 0.8765\n",
      "Epoch 98/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3778 - accuracy: 0.8710\n",
      "Epoch 99/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3594 - accuracy: 0.8820\n",
      "Epoch 100/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3623 - accuracy: 0.8855\n",
      "Epoch 101/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3876 - accuracy: 0.8690: 0s - loss: 0.3889 - ac\n",
      "Epoch 102/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3969 - accuracy: 0.8695\n",
      "Epoch 103/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3453 - accuracy: 0.8885\n",
      "Epoch 104/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3521 - accuracy: 0.8775\n",
      "Epoch 105/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3514 - accuracy: 0.8790\n",
      "Epoch 106/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3297 - accuracy: 0.8885\n",
      "Epoch 107/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3482 - accuracy: 0.8815\n",
      "Epoch 108/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3574 - accuracy: 0.8835\n",
      "Epoch 109/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3176 - accuracy: 0.8965\n",
      "Epoch 110/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3056 - accuracy: 0.8970\n",
      "Epoch 111/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3306 - accuracy: 0.8975\n",
      "Epoch 112/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3143 - accuracy: 0.8960\n",
      "Epoch 113/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3189 - accuracy: 0.9025\n",
      "Epoch 114/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3581 - accuracy: 0.8865\n",
      "Epoch 115/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3017 - accuracy: 0.9035\n",
      "Epoch 116/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2990 - accuracy: 0.8985\n",
      "Epoch 117/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3171 - accuracy: 0.8945\n",
      "Epoch 118/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3012 - accuracy: 0.8985\n",
      "Epoch 119/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3224 - accuracy: 0.8970\n",
      "Epoch 120/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3027 - accuracy: 0.8990\n",
      "Epoch 121/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2744 - accuracy: 0.9040\n",
      "Epoch 122/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2640 - accuracy: 0.9080\n",
      "Epoch 123/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2843 - accuracy: 0.9075\n",
      "Epoch 124/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3074 - accuracy: 0.9015\n",
      "Epoch 125/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2865 - accuracy: 0.9110\n",
      "Epoch 126/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2647 - accuracy: 0.9140\n",
      "Epoch 127/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2876 - accuracy: 0.9090\n",
      "Epoch 128/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2796 - accuracy: 0.9085\n",
      "Epoch 129/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3091 - accuracy: 0.9015\n",
      "Epoch 130/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2812 - accuracy: 0.9080\n",
      "Epoch 131/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2762 - accuracy: 0.9025\n",
      "Epoch 132/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3084 - accuracy: 0.8910\n",
      "Epoch 133/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2549 - accuracy: 0.9160\n",
      "Epoch 134/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2753 - accuracy: 0.9115\n",
      "Epoch 135/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2407 - accuracy: 0.9195\n",
      "Epoch 136/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2220 - accuracy: 0.9315\n",
      "Epoch 137/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2598 - accuracy: 0.9080\n",
      "Epoch 138/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2342 - accuracy: 0.9240\n",
      "Epoch 139/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2459 - accuracy: 0.9125\n",
      "Epoch 140/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2389 - accuracy: 0.9250\n",
      "Epoch 141/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9285\n",
      "Epoch 142/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2191 - accuracy: 0.9240\n",
      "Epoch 143/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2648 - accuracy: 0.9140\n",
      "Epoch 144/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2401 - accuracy: 0.9290\n",
      "Epoch 145/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2584 - accuracy: 0.9220\n",
      "Epoch 146/150\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2287 - accuracy: 0.9200\n",
      "Epoch 147/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2306 - accuracy: 0.9275\n",
      "Epoch 148/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2374 - accuracy: 0.9270\n",
      "Epoch 149/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2129 - accuracy: 0.9355\n",
      "Epoch 150/150\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2537 - accuracy: 0.9200\n",
      "training  model takes 596.602 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGKCAYAAAD+C2MGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3RU5dbH8e+mF2ki5Uq5ICKgKJYItgtWFFGxYUVF8ILttRewolexi11BQVRQVEBFsXsFCyACYgEuSlFAUem9Jvv945lAyiSZ1MlMfp+1ZmXmnDNn9plJsufp5u6IiIhIcigX7wBERESk6Cixi4iIJBEldhERkSSixC4iIpJElNhFRESSiBK7iIhIElFiFykkM3vBzNzMHo13LInCgvPN7DMzW2Fm28xsiZmNMrOj4h2fSCIzjWMXKTgzqwr8CdQE/gYaufv2+EZVuplZeWAUcBrwEvAusBJoAnQHTgHquPuauAUpksAqxDsAkQR3GiGpvw+cCJwAvBfXiKIws8ruviXecUT0B84EznT3MVn2jTSzzsC2wr5IKbtmkRKjqniRwrkIWAX0BDYBF0Y7yMzamdlbkWrnTWY218z6ZznmNDP72szWm9laM5tqZqdE9jWLVPf3zPKcIyPbj8ywbYKZfWVmJ5vZd2a2Bbg8su9KM5tsZivNbLWZTTGzrlHirW5m95vZfDPbYmZ/mtkYM2tgZgdFXrNblOcNj1Spl8/hfagEXA+Mj5LUAXD3j919Y4ZrmRDlPL+a2fAMj3tGYupoZm+a2WrgGzO7ycy2mlndKOeYbWZvZ3hczcweMLOFkecsNLNbzaxchmN2MbMnzWxR5H35y8w+NbPW0a5FJB5UYhcpIDPbHTgWGOLuyyJJ4nQzq+PuqzIc1x6YAMwDrgWWAC2B/TIc83/AE8DbhC8L64EDgWYFDG+vyPn+AywgVHUTOd8LwK+Ev/+TgffM7ER3/yASSyXgE2B/4D5gClALOJ5QRT7dzL4F+gLvZLiG2sBZwIPunppDXClAbWBcAa8rLyOB1wg1AhWAHyLXcDbwTIZYDwLaALdHHlcAPgL2JrxnPwKHRPbvSvgyAjCI0FRwC/ALUBc4PHJNIqWDu+umm24FuAE3Aw4cGnl8fOTxpVmO+wJYDFTL4Tw1gXXA2Fxeq1nk3D2zbD8ysv3IDNsmAGnA/nnEX46Q/D4G3smwvVfknKfk8tyeQCrwzwzbrgK2A41zed7ZkXMfH+N7PAGYEGX7r8DwLPE4MCjKsZ8Ak7Nse4zwZady5PEFked3zHLcrcBWoH7k8U/Ao/H+3dNNt9xuqooXKbgLgV/cfXLk8afAH2SojjezaoQS3UiPVC9HcRiwCzCkCGP71d1nZt0YqUZ/z8z+IiThbcBxQKsMh3UG/nT33ErVo4DVwL8zbOtLqGJfUujoC+6tKNteAQ4xs5awo3R+DvCG72yDPwH4DZhkZhXSb4QvPRUJpXeAb4GeZnaLmaXk1OQgEk9K7CIFYGYHE6ptx5pZ7Ug1dA1gLHCome0VObQO4e8st2SX3v5blAlxadYNZtYE+IxQtfx/hC8UBwMfAlWyxPN7bid3983Ai0DvSBL8F+H9eC6PuBZHfv4zhmsoiGzXDYwBNgA9Io87Aw0ICT9d/UhM27Lcpkb2p39G/wcMJtRqfAv8bWaDIl/gREoFJXaRgrko8vNmQue59NuVke3ppfZVhGrxRrmca3nkZ27HbI78rJRle7ZOYRHRxrGeQGgrP8vd33D3Ke4+DcialJbnEUu6ZwkJshuhtP4roZ06N9MIJf2TYzg/hOvOes0QvpxEk+263X0DoSR/fmRTD2CBu3+d4bAVwELCF51ot3cj51rv7v3dfU9C88hAwmd+Z4zXI1LslNhF8inSuewc4BvgqCi3mcAFZmaR6vevgB6RMe/RTCJ0luuTy8v+BWwB2mbZnq1Hey7SE/iOoWSRmoXDsxz3MdDQzHJNvu4+P3LsjYTOas+7e1oez9kKPAKcZGZnRDvGzI7LUAL+Ddgr8p6n7+9IqB3Jj1eAFmZ2POGLyCtZ9n9IGEe/3t2nRbktz3pCd//N3R8hdLTL+rmIxI16xYvk30mEkvL17j4h604zG0wozR4JfA7cAEwEJpvZI4Qq9z0Indv+z93XRYa+PWlmYwg9u9cReqVvdvcn3d3N7HVC1ffPwFxCUj8yH3F/SmhXfzkSxz+Au4BFZP6SP4LQdv6amd1H+AJTg9A58DF3/1+GY58h9IzfBgyLMY77gHbA65Eha+kT1DQGzgBOJzRhQGjL7wMMixzbHLgOyO/kNen9H4YSvuCMyLJ/JHAx8FnkvfmeUFPQgtAL/lR332hmkwk9+n8kfBnrFLmWl/IZj0jxiXfvPd10S7QbIZGtJede7rWAjWTutX0AIYGtJox3/x9wc5bnnUlIopsi5/8GOCnD/tqEkuZyQiJ8jpDco/WK/yqH2M6KvPZmYBah5mE4obNdxuN2AR4ilJi3EtquRxPpHZ7huPKE9us38/keGqFK/HNCc8U2whee14B/ZTm2L2Fo2SZC7cZB5Nwrfs9cXvOhyDGTcthfBRgQeX+2RN7jbyPbKkSOeQD4jvDFYgMhwV8V799J3XTLeNOUsiJSYGZ2HKE6/lh3/yze8YiI5ooXkQIwsxaE5oRBwBZ3PyjOIYlIhDrPiUhB3A58QKiyjjqNrojEh0rsIiIiSUQldhERkSSixC4iIpJEkmIc+2677ebNmjWLdxgiIiIlYvr06cvdvV60fUmR2Js1a8a0adPiHYaIiEiJMLPfctqnqngREZEkosQuIiKSRJTYRUREkogSu4iISBJRYhcREUkiSuwiIiJJRIldREQkiSTFOPZYbd68mWXLlrF582a2b98e73BEypSKFStSv359atasGe9QRJJamUnsa9as4a+//qJevXo0bNiQChUqYGbxDkukTHB3Nm3axO+//w6g5C5SjMpMVfzy5ctp3LgxderUoWLFikrqIiXIzKhWrRqNGjXi77//jnc4IkmtzCT2rVu3UrVq1XiHIVKmVa1alW3btsU7DJGkVmYSO6BSukic6W9QyhT3uLxsmUrsIiIiJeLjj6FJE1i2rMRfWoldRESSw1dfhYQab1OnwvnnQ5s28PDDJf7ySuxSZPr164eZ8eeffxbo+Zs3b8bMuPTSS4s4MhFJemvWwNlnw+235+95ixbBwIEwc2bOxzz8MIwenfP+tWthxgxYsCD8POUUePFFGDYMXnihxEvtSuxJxsxivv3666/xDrfU++6773a8X9OmTYt3OCKSk5tugi5dQnL9Lcelynf65ZdQqj7gAJg3D44/Hi69FJYvz3zcggVw331w7bXwxBPZz/P779ChA1xwARxzTDjPAw/ASSeFqvhzzinxUnuZGcdeVrzyyiuZHn/55ZcMGTKEPn368K9//SvTvnr16hXpa99zzz0MGDCAKlWqFOj5VapUYdOmTVSoUHp+LYcOHUqdOnV23E9JSYlzRCKSzYQJ8P778NNP4fGYMXDddeH+n39Cp04wfjzsuWfYtnUrdOsG3buHxF2rFqxaBQMGQLt28M030LhxOPauu+D//g8uvjgk7SVLwpeI3XYLpf2jj4ZLLoF+/aLH1q8f7L8/3HADFPH/3By5e8LfDjroIM/L7Nmz8zwmGb344osO+Isvvhjzc9LS0nz9+vXFF1SC2LRpk9epU8cvv/xyv+yyy7xWrVq+cePGeIcVk7Vr18Y7hByV1b9FKSbr17vvuaf7O++Exx9+6H7IITv333ije4sW7ocf7r59e9h2773uXbu6p6VlP9/AgeH5W7a4z57tXq+e++rVYd+yZe5nnOFes6Z7u3buTZq4DxqUd4yXX+5+002Fu84sgGmeQ05UVXwZ9+GHH2JmvPbaazz++OO0bt2aypUr8+STTwIwadIkLrzwQlq2bEm1atWoWbMmHTt25L333st2rmht7OnbFi5cyI033kijRo2oUqUKBx54IJ988kmm50drY8+47YsvvuCII46gWrVq1KtXj0svvZSNGzdmi+PTTz+lQ4cOVKlShX/84x/ccMMNO6rU77///pjfm7Fjx7Jq1SouuugievbsyZo1axgzZkyOx48aNYqOHTtSq1YtqlWrRuvWrbnmmmtITU3dcUxaWhrPPPMMBx98MLvssgs1atSgXbt23HPPPbm+j+kaNmzICSecEPX9+fDDDznssMOoXr063bt3B2Dx4sVce+21tGvXjtq1a1O1alXatm3LI488QlpaWrbzb968mYEDB7LffvtRtWpVateuTfv27Rk8eDAAAwcOxMz46quvsj13w4YN1KxZk65du8bw7ooUwNq1sHnzzsebNoX27KOOCj8hlKB//hkWL4YVK2DoUPjsMyhfHh57DObPh0cfhaeegmjDL2++GerXh+uvDyX4668PJXoIpfTRo0N1/bPPwvDhcM01ecfdvz907FjYq49Z6anzlLh64IEHWLNmDb169aJ+/frsscceALz55pvMnz+fc845h6ZNm7Js2TKGDx/OySefzJgxYzj99NNjOv+5555L1apVuemmm9i0aRODBg3ilFNOYd68eTRq1CjP50+dOpU333yTSy65hB49evDZZ58xePBgKlWqxBMZ2r0+++wzunTpQv369bnllluoUaMGo0aNYsKECfl+T4YOHUrr1q1p3749AG3atGHYsGH06NEj27HXX389jz76KPvuuy/XX389DRo0YN68eYwePZr777+f8uXL4+6cffbZjB49msMPP5zbbruNWrVqMXv2bEaPHs1tt92W7xjTff3117z66qv06dOHiy++mPLlywMwffp03n33Xbp160aLFi3YsmUL48eP54YbbmDRokU8/vjjO86xefNmjjnmGCZNmkSXLl246KKLqFSpEj/88ANvv/02ffv2pVevXtx5550MHTqUI444IlMMb775JuvWraN3794Fvg5JMmvXwttvQ0oK7L134c93wQXwww+hzfqkk+D006Fhw5Bk01WsGJL8mDGwciWccQb885+hM1v79vDGG6EqvVmz6K9Rrhy89FKIef360AEuq4oV4dBDY4+7ceOdVfslIaeifCLdVBWfs7yq4j/44AMHvF69er5ixYps+6NVya9bt86bN2/uBxxwQKbtN998swO+dOnSbNtOP/10T8tQ7fXFF1844AMGDNixbdOmTQ543759s20rX768z5gxI9PrHX300V65cmXfvHnzjm377befV6tWzRctWrRj25YtW/yggw5ywO+7776o70NWCxcudDPLdPz999/vZubz58/PdOzEiRMd8OOPP963bNmSaV/Ga37ppZcc8N69e2fa7u6empq643609zFdgwYN/Pjjj9/xOP39AfyLL77IdvyGDRuyvZa7e/fu3b1ixYq+fPnyHdvuuusuB/yuu+7KdnzG+E477TSvXr16tur+I444wuvXr+9bt27N9vyMyurfYpmyYIH7RRe516rl3qWL+267ud91V6jeLqh169xr1HB/+233ffd1b9AgVItv25b92PHj3fff371uXfeMf6+DB7sfdJB7Hr+j7u4+d677558XPN5ihqriJS+9evVi1113zba9evXqO+5v3LiRFStWsHnzZjp16sTMmTPZsmVLTOe/5pprMs06dsQRR1CpUiV++eWXmJ7fqVMnDjjggEzbjj76aLZs2cLixYsB+O233/jhhx8488wzadKkyY7jKlWqxFVXXRXT66QbNmwYZpapdH7BBRdQrlw5XnzxxUzHjhw5Egi1HpUqVcq0L+M1jxw5kvLly/Pggw9mm4GtXLnC/Sl26NAhW+dIgGrVqu14rS1btrBy5UqWL19O586d2bZtGzNmzMgUX/369enfv3+282SMr0+fPmzYsIFRo0bt2Pbzzz/z1VdfceGFF1KxYsVCXYskgG+/hddfD2PGZ8zIPMPa6tWhd3qjRjB3bujUNmNGeE7btqHDWp8+oZSddWa2L78Mw9ai+fjj0Pu8W7dwvhdegFdfhWidbY85BhYuhBNPhEjtIxBed+rUUOLOy157wZFH5n1cKaSqeIjezhJvJTwV4V577RV1+9KlS7n11lt59913WZ51GAhh1bz69evnef49Mv5xERJenTp1WLFiRUzxZX0+QN26dQFYsWIFe+65JwsXLgSgVatW2Y6Nti0naWlpDB8+nJSUFDZv3sy8efN27Gvfvj3Dhw/nrrvu2pHsfvnlFypWrEjbtm1zPe8vv/xC06ZNo36BKqycPr+tW7cycOBARowYwYIFC/Asv1erVq0CQs3d/Pnz6dixY56JuXPnzjRr1oyhQ4fy73//GwjNFgCXXHJJYS9FSrMZM8I48Z9+Ckl21aowVCwlJbRlV68O554Lxx0H996783lNmsC4cTBpUhgetmpVSMzTp8Nzz4Xq7zvuCMm+Zk145RXI0tTDO+/AqaeG+xUqhKr4nFSuHNrQo3zZpZBfohOBEjvEbT7f0qRatWrZtqWmpnLMMcewcOFCrr76ag466CBq1apFuXLlGDx4MKNHj47aASua9DbfrLImmvw+P+M5Yj1XXj7++GMWL17M4sWLadmyZY7HpHdii/V13T2mknlu86lv37496vZonx/AlVdeyfPPP8/555/PHXfcQb169ahYsSJTpkzh9ttvz/b5xTKXe7ly5ejduze33347s2bNolWrVrz88sscccQR+foCJcVk40b473+zJ7777gs/b7ghthJrRqtWhed98AHccguMHRuSJ4TObFdfDQcfDIcdBlu2hM5pWZnB4YfvfHz++aH9+4wzQjx//glz5oShZmeeCZdfHpI9wPbtYbhahk6meYrSF6asUGKXHE2bNo05c+YwcODAbNWzTz31VJyiylnz5s0BmDt3brZ90bblZNiwYVSvXp3hw4dH3d+rVy+GDh26I7G3atWKCRMmMGvWLPbbb78cz9uqVSs+/fRTVq5cmWupPX3fypUradiw4Y7ta9eujbmGI92IESPo3LkzI0aMyLT9p/TxvhFmxp577slPP/3Etm3b8iy19+rViwEDBjB06FA6derEn3/+yX3piUPi5/ffQ1X199/DtGlhTDbAX3/Bgw+G5Pv666F0fdBBmZ/rHm4Zv3xu3QpvvRUmZznjjFC1XqNG5udVqQKDB4cOZ4MHw7vvxvbFYZddwrGXXRaS/siR4cvCySeHWeCOPBJat4azzgpTxTZrFkr+kicldslReik5a4l0xowZjB8/Ph4h5apZs2a0bduW0aNHc8899+xoZ9+6dWumnvO5WbFiBe+88w7dunXjzDPPjHrMmDFjGDt2LMuXL2e33XbjvPPOY/DgwfTr14933nknU1J09x2l4PPPP5+PPvqIfv36MXjw4Eyl44zHpVerf/rpp+ydoSfxI488ko93I5yzQoUK2T6/tWvXZuoNny69VP/ggw9y6623ZjtXxnh33313unbtyiuvvMLs2bOpWbMmZ511Vr7ik3z65JMwmcrq1aEEvXp1uNWuHWZPa9AgTKRy+eVhtrN77w09wCFUS59zDjzzDIwYEdqeu3QJJeLmzUM19x13hHbp/feHffcNrzVpEuyzTxjiddhhucd30UXhlh+VKoUvGVk1bBi+KHTrFiaXeeedcF9iosQuOdpvv/3Ya6+9uOeee1i9ejUtW7Zkzpw5PP/88+y3336ZOl6VFo8++ihdunThkEMO4dJLL6VGjRq89tprO5JSXlXNr7zyClu3buWMM87I8ZgzzjiDUaNGMWLECK655ho6duzI1VdfzeOPP05KSgrdu3enQYMGLFiwgDfeeINZs2ZRpUoVevTowdixY3n++eeZM2cOJ598MjVr1mTu3LlMnDhxx/t54okn0rx5c26++WaWLl1K06ZNmThxIjNnzqRW+njaGJgZp59+Oi+99BLnn38+Rx55JH/++ScvvPAC9evXzzal8I033sj48eO57bbbmDx5MscccwyVKlXixx9/ZNGiRbz//vuZju/Tpw/jxo3jo48+om/fvjk2B0gR+OSTkDRPOikk8tq1wxCuWrXCmOopU+B//4PHHw9DwNavDyX0OXOgadPQjj1pUigZX3BBGA42aFAowdevH0rKAweG5D1zZhhS1rkzvPYaRGZeLHEdOkCvXtC3b6iBGDcuPnEkopy6yyfSTcPdchbrcLfXXnst6v558+b5aaed5nXr1vVq1ap5hw4d/N133811aFte29LlNHQr2nC3jNvSPfvssw745MmTM23/8MMPPSUlxStXruwNGzb06667bsfwuscffzz6GxWx7777euXKlXOduW39+vVetWpV33fffTNtf/nll/2QQw7x6tWre7Vq1bx169Z+7bXX+vb02a7cffv27f7YY495u3btvEqVKl6jRg1v166d33vvvZnONWvWLD/22GO9atWqXrt2bT/vvPN86dKlMb1nGa1bt86vvvpqb9KkiVeuXNn32msvf+ihh3z8+PFRP/eNGzf6gAEDvHXr1l6pUiWvXbu2t2/f3ocMGZLt3Kmpqd60aVMHfOrUqTm/qVmU1b/FAtuyxb1Vq50zq8XqnnvcL7jA/Ykn3E87Lfoxy5e7f/aZe4bhjKXK5s3ubdu6N28efZa4MoxchruZJ0HHsZSUFM9rgY45c+bQpk2bEopISpuRI0fSo0cP3nrrLU5N71krheLutGzZkurVq/P999/H/Lwy+bf4+++hFNylS/T9q1eHCVUuvjh7r+0HH4SJE+G99/I3gmfNGmjRIlR3jxmTvwlVSpM5c8KCLekzywkAZjbd3aMuXpH8/f6lTElLS2Pr1q2Ztm3ZsoXHHnuMypUrRx3rLQXzwQcfMH/+fPr27RvvUOIrLS30Fs/SITGTgQPDUK1oX4BSU0P7d//+oSd3xt/fJUtCYn/88fwPy61VK7S3t2iRuEkdwprmSur5ojZ2SSpr166lTZs2nH/++ey1114sW7aM1157jVmzZnHnnXfuGPsuBffpp58yf/587r33XnbffXd69uwZ75DiIzU1TFP6yCNhzvJ//GNnO3ZG69eHtuoBA8IQr2+/hapVd+6/+eZwrgULQvv3SSfBf/4TeoKPHBmWEk1flSy/BgwI06dKmaLELkmlatWqdO7cmbFjx+5YRKV169YMHjyYPn36xDm65HDbbbcxffp02rZtyzPPPFN2O83dfXeYVe3pp0PP7TZt4Isvwv2MXn01bOvXL3RM698/LEayfXv4YvD222E2tF12gTffDEPLLr44LGxy662FK62WKxfOK2WK2thFpEQlzN/inDmhXbt27dAz/Nhjw32AyZPhtNPgu+9CSR3CTGpjxoRq+XTucOCBcP/9YS3vlSvD2PIGDcL5mzULQ9L22afEL08Sm9rYRaRsy7B07g5DhoTZ1P7+O/u+9JL3woVhJrRhw0JCnjAB1q0LbeHPPrszqcPOlcdmzty5berUsMLZcceFx7vuGuZDf/zxMGnMrFlK6lLkVBUvIsnLPYzXvvtumD0bdt89bN+2De68M4zVbtMmLA5y1FFhspbvvw+dzl59NZTS033wAZx3XliT+6ijQok9o8qVQzX6Aw+ENnUIyb9v38w93Zs1y3nJUJEiUKYSu2eZPUtESlaJNv2tXRsmOPntNzjhBHjiiVAlDqFdu1WrMLvZokUh+T/wQCihu8OHH4Yq9Iy6dAml8SeeCO3l0fTtG1YT69w5zA73yy/w0EPFe50iWZSZxF6+fHm2bduWbVlNESk527dvp0K0ZTYLIzU1JO+MKwBu3x6qv9u1Cz3L//gjrEB2661hrvPnngu9zSHMzDZoUGyvVb9+7guR1KgRqusXLw7t8k2bQr16Bb40kYIoM23sNWrUYO3atfEOQ6RMW7duHVWqVCnak95xB+y9d1hSNN2gQSHJDh4cqsibNw/V6i+8EBYy+emnMPVqcdhnn1BD0KFD5jZ4kRJSZkrsu+66K4sWLQKgZs2aVKxYUdXyIiXE3dm0aRPLly+nadOmRXficePC2t2PPhqW+pw2LfQ8f+CB0HEt49/4jTeGZL5gQaiiV+2dJKkyk9grV65M06ZNWblyJb/++iup0XrJikixqVy5Mg0aNMheYv/iC6hQIe/Vw7KaPx8uuSQk90MOCe3ZF1wQ1iO/5ZbMVfMQquJbtAgd2ubNK9zFiJRiZWYcu4iUUqecEtrAv/02+rSpf/8dOrQ1aLBzW1paWJns4ovhyivDtm3bQm/1bdvCDHCRZYczmTAhrEf+7LPFcikiJSW3cexlpsQuIqVQamoY112tWlh6NH1O882b4fbb4aOPQtV5ixZhMpj0YWPjx4dkf8UVO89VsWIYkrZtW/SkDnDkkeEmksTKTOc5ESmFfvwx9DS/6aYwjCzdPfeE8eQvvBCGjVWsGIaopXvoodBmnrWEX6NGmARGpAxTYheR+Jk4Mczw1rNnKJ2nL286eDAMHw7t24ekPmAA3HVXqIL/5psw9rx79zgHL1I6KbGLSPykJ/ZatcLKZ08+Cb17w3337ZwlDqBr152l9ocfDjO8FfV4eJEkoc5zIhIfaWmhGn7mTGjcOIwv33vvkOg/+yx7Nft778HVV8OaNfDrr1q1TMo0LQIjInl7++2w0lhRWL8++uIqGc2eHUrqjRuHx61awb33wtCh0XvHd+0a2s/79lVSF8mF6rJEJBg4MPRSP+uswp1n/Xo45pgwV/v06aHHezTp1fAZ5TQHO4Rk/8knSuoieVCJXUTC5C6LFsGSJWF4WTSpqSFp52br1jADXNu2cMABobd7TqIl9rzUrq22dZE8KLGLSFii9Oyzw1Kko0dn3//332HFsn33DVO2RpOWFnq3V64cerU/8wy8+y68/372Y90LlthFJE/66itS1rmHxP7yy6FE3r9/5pL2pEkh6V94YSiJX3BBSNjlspQL+vcPpf5PPgml6tq1wznPPRcuuywsifr776FqvmpVqFJF65KLFAMldpGybsaMUM3evn34uXBh6HXerBlMngzdusGLL8JJJ4VZ3Y4+OrTH33bbznMMGQJvvRWOr1p15/ZOncLQtblzw6xyjRqFWeVWrQrD2kSkyCmxi5Q17nD33SFh779/KK2fd17onFahApx6KowZE0rmZ521M6lDGEv++uthnvJDf8IAACAASURBVPZVq8KXge3bw9KpX34Jdetmf72LLirZ6xMp49TGLpLMtm0LCTijqVPDIijHHw+XXgqjRoXq8nTdu4fkfe65ISmnJ/V0u+8On34ahqqNGhWWSB09Glq2LP7rEZE8aYIakWR2/fWhJP3NNzvHhvfpE6rZL7ssTNM6d25YPCXdtm1hJbWDDoIPP8x5QRURiRut7iZSFv35Z6hG33XX0KGtc2fYsCGUrn/6CerUgccey/68ihXhzTdDNb2SukjCUWIXSVYPPRTayTt0CKulde4cEvbhh2eehz2aY44pmRhFpMiVeBu7mZ1gZnPNbJ6ZZZtmysyamtnnZvadmf1gZieWdIwiCWHjxjAEbc89ISUFTjgBPv887Esvrd98c+gAt3QpfPFFWAZVvdFFklqJltjNrDzwNHAcsAT41szGufvsDIfdBrzh7s+a2d7A+0CzkoxTpNT744/Qq71VKxg/Pkzf+vPP0KNHuG3cGErr6SXz/v3hiitg+fIw57qIJK2SLrG3B+a5+wJ33wqMArplOcaBmpH7tYA/SjA+kdLvt99C9fppp8Err4TkfvDBYdnTmTPhf/+D558PpfV0PXqE5H/hhaENXUSSVkm3sTcCFmd4vATokOWYAcDHZvZ/QHXg2GgnMrM+QB+Apk2bFnmgIqXWs8+GIWm33JJ9X716YZW2P/7I3I5eqVKY2jV9JTURSVolXWKPshYjWcfbnQsMd/fGwInAK2aWLU53H+LuKe6eUq9evWIIVaQUSk2FESOgV6+cjzELM7xltc8+Yey5iCS1kk7sS4AmGR43JntVe2/gDQB3nwxUAXYrkehE4uWvv+D22/New/zzz8MY87ZtSyYuEUk4JZ3YvwVamllzM6sEnAOMy3LMIuAYADNrQ0jsy0o0SpGS5A59+4bZ3PbeGx59NCx/Gs1LL2mKVhHJVYkmdnffDlwJfATMIfR+n2Vmd5vZKZHDrgf+bWbfA68BPT0ZpscTycmIEWEN9AkT4KuvwmQyBx4IU6ZkPm7durCqWsbpX0VEsijxCWrc/X3CELaM2+7IcH82cHhJxyUSF7//HqZ9/eijsI5569ahk9sbb4Re72efHaro69YNC7N06hQ6yImI5EAzz4mUtBUrwmQxCxeGBH7FFXDAATv3m4WEfuyx0K8ftGgRFmz5+efMS6WKiEShxC5S0i65JCT3Aw4I48r//e/ox9WtG8ajP/hgWFo1LS37SmsiIllodTeRkrRtG+y2G8yfH36KiBRAbqu7aT12kZI0ZUpYt1xJXUSKiRK7SCxmzQpTssbqt99g0KAwjC0tbef2jz+G444r+vhERCKU2EVi0asXDBmS93GrV4flUVNSwpeBL78MyTxd+rroIiLFRIldJC/r1sH06WEYWm5WrAjrmLdpE5ZJfeGFMJTtqafC/pUrYfZsOOyw4o9ZRMos9YoXycvXX8P++8O338KaNTvnW9+yJSy4UrUq7LILXHMNnHgi3HdfGLIGYTKZm28OQ9umT4cjjgjj1UVEiokSu0heJk4MCXu33UJV+plnhu3PPhuGozVvDqtWhWVTb7ppZ1IHqFYNevYMx6ZX04uIFCMldpG8TJwI//lPmPFt/PiQ2FNT4cknYeRIOOSQ3J9/2WXhmKpV4eqrSyZmESmz1MYukpsNG+D77+HQQ6FrV/jgg9DL/f33wwQyHTrkfY4WLeDgg8OXgb33Lv6YRaRMU4ldJDeTJ4f29WrVYI89oE6d0Fb+xBOh9J2x2j03d9wRxrDHeryISAEpsYvkZuLEsPBKuq5d4aGH4KefoHv32M9zyCF5V9mLiBQBVcWL5GbiROjYcefjrl3hzTfh0kuhUqX4xSUikgMldpGcbNoUqt0Pz7CK8BFHhFvfvvGLS0QkF6qKF4nGPXSQ22cfqFFj5/aKFcNsciIipZQSu0hGq1fDVVeFaWCrVoV77ol3RCIi+aLELpLRLbeEpVUnTw4Tz4iIJBgldpF033wDb70V5nOvUyfe0YiIFIg6z4kAbN8eOsQ9/LCSuogkNCV2KRvcc9//+ONhytjzziuZeEREiokSuyS/BQugQYOwfGrWBL9hA1x7bSipP/OMZoYTkYSnxC7JYevWnPfdcQeceiq8/DKcdBLMnBlWaXvmGWjbNqyT/tNP0LJlycUrIlJM1HlOEt+nn8Jpp8HAgXD55VC+/M59338f9v/yC1SpAnfdFaaCbdo09Hp/7jk4/vj4xS4iUsTM82p7TAApKSk+bdq0eIch8XLKKaHk/eWXYQW1556D/fYL+7p2DYn7qqviG6OISBEys+nunhJtn0rsktgWLoRJk2DUqFAiHzwYjjsOjjkGOncOQ9fGjo13lCIiJUZt7JLYnnsOLrwwLKtarhxcdhnMmxdK8NdeG6rnK1eOd5QiIiVGVfGSuDZtCm3lkyfDnntm35+amrm9XUQkSeRWFa8SuySu11+HlJToSR2U1EWkTFIbuySWRx+F8ePD7HDTpoWx6SIisoMSuySOP/4Iq629/HKohj/7bDjxxHhHJSJSqiixS+J4+GG46KIwyYyIiESlNnYpnebMCT3bZ88Oj5ctg+HD4YYb4hqWiEhpp8QupY97GKrWvHkYi/7LLzBoUKh6b9Qo3tGJiJRqqoqX0uf998PEMz/+CK+8AsceC+vXw/Tp8Y5MRKTUU2KX0mXrVrjuutD7vVIl6N07jEdftAiaNYt3dCIipZ4Su5QuTz8dquAz9nbv0yd+8YiIJBgldik9Nm2C++6Dzz/XuugiIgWkznNSerzyCnToAPvsE+9IREQSlkrsUjqkpcFjj2kmORGRQlKJXUqHjz4KneWOOirekYiIJDQldikdBg0KveHVti4iUiiqipeis24djBkDPXtm3j5iRBiDXqcO1KsXJp1p0WLn/p9+CrdzzinRcEVEkpFK7FJ0xoyBSy6BVat2bnOHm26C2rVh2zaYOhUOPxz23z98AUhJgfbtoV+/UBUvIiKFohK7FJ0334Rq1eDjj8P0rwDffQe77AJ33rnzuNRUmDQpzAd/6aWw337heSIiUmhK7FI0Vq+Gr76CW28N66WnJ/bx46Fr18zHli8P//pXuImISJFSVbwUjXHjQo/2c86BDz4IpXKInthFRKTYKLFLwWzcCNu373w8ejR07w7//Cc0aADffhuWWp0zBzp2jF+cIiJljKriJf+2bg3Jum5deOcd2LIFJkwIM8dBKKG//z60bAnHHKNOcSIiJUiJXfJvwABo2DB0eDvrLDjtNOjUCWrVCvtPPDGMSW/ZUtXwIiIlTIld8ueLL+DFF+H778O49O7dQ8/255/fecxhh8GCBfDzz2H5VRERKTFK7BK7NWvgwgtDEq9fP2x7/XW491449dSdx1WsGCah+eUX2H33+MQqIlJGKbFL7B54AI4+Gk46aee2ypXh7ruzH3vNNfDHHyUXm4iIAErsEqvly2Hw4DDhTCwOPbR44xERkag03E1i8+ijoaNc06bxjkRERHKhErvkLb+ldRERiRuV2CVvKq2LiCQMldgld0uXqrQuIpJAVGKX3F1zTRinrtK6iEhCUIldcvbhhzBtWpiQRkREEkJMJXYzs+IOREqZTZvgiivg6ae1VrqISAKJtSr+NzO73cwKPY2YmZ1gZnPNbJ6Z9cvhmLPMbLaZzTKzVwv7mpJP7mFd9ZQUOOGEeEcjIiL5EGtV/H+BfsDtZvYe8Jy7f5zfFzOz8sDTwHHAEuBbMxvn7rMzHNMS6A8c7u6rzKx+fl9HCmHZMujdG5YsCSu0iYhIQompxO7uPYHdgRuAvYAPzWy+md2cz8TbHpjn7gvcfSswCuiW5Zh/A0+7+6rIa/+dj/NLYXzyCbRrB23awJQpYQU3ERFJKDH3inf3Ne7+hLu3BToBk4ABwCIzG2VmR8ZwmkbA4gyPl0S2ZbQXsJeZfW1mU8wsal2wmfUxs2lmNm3ZsmWxXoZEk5YG//kPXHQRjBgR5oTXGuoiIgmpoL3ivwbqAXsCHYCTgO5mNh24yN3n5PC8aJ3wPEpMLYEjgcbAl2bW1t1XZ3qS+xBgCEBKSkrWc0isNmwIk8+sXRt6wGs1NhGRhJavcexm1sTM7iaUut8AVhOq0msCJwBVgZdyOcUSoEmGx42BrEuALQHecfdt7r4QmEtI9FIchgwJP//7XyV1EZEkEOtwt5MjneYWAJcDrwJ7uXsXd3/X3dPc/RPgOmD/XE71LdDSzJqbWSXgHGBclmPeBo6KvO5uhKr5Bfm5KIlRaio89RTcdltYQ11ERBJerFXx7xCS8iXAKHffksNx84GROZ3E3beb2ZXAR0B5YJi7z4rUAkxz93GRfZ3NbDaQCtzo7itijFPy4/33oW5dOOSQeEciIiJFxNzzbp42swPdfUYJxFMgKSkpPm3atHiHkXiOPRZ69oQePeIdiYiI5IOZTXf3lGj7Ym1jX2xme+Vw8r0iVeaSSGbNCrfu3eMdiYiIFKFYE/szwPU57Ls2sl8SyZNPhsVdKleOdyQiIlKEYm1jPwK4Iod9HwNPFU04UiKWLYM33oDZs/M+VkREEkqsJfY6wJoc9q0F6hZNOFIiBg2Cs8/WzHIiIkko1hL7EsJENJ9F2dcBWFpkEUnxWrUKBg+G6dPjHYmIiBSDWEvso4FbzKxrxo2Rx/0Ik9VIInjySTjlFGjWLN6RiIhIMYi1xH430BEYZ2Z/Ar8T5nhvCEwB7iqe8KRIrVsXEvvXX8c7EhERKSYxJXZ332hmnYALCEuu1gXmETrOjXD37cUXohSZZ58NY9f3ijpyUUREkkDMi8C4+zZgWOQmiSZ9+th33ol3JCIiUozytQiMJLDx46FRIzjggHhHIiIixSjmEruZHQ9cCrQCqmTZ7e7eoigDkyL23HNhQhoREUlqsa7udiLwPlANaA38D1hEWII1DfiiuAKUIrBwIUydGtZdFxGRpBZrVfztwNPAiZHHt7n7kcA+hFXaPij60KTIDBkCF14IVavGOxIRESlmsSb21sC7hNK5E6nCd/efgQGExC+lwfbtoff7v/4FDz0EixfDsGHQt2+8IxMRkRIQa2JPA7Z7WON1GdA0w74/ALWvlwZffQUHHRTmgb/mmjAXfJs20LYttGoV7+hERKQExNp5bi7QLHJ/GnCNmX0NbCes+vZrkUcm+bN5M3TrFkrr3buDGZxxBjz+eCjFi4hImRBrYh8JtIncvxP4lDB/PEAqcF4RxyX5NX487L9/9g5yNWvGJx4REYmLWGeeezrD/elmti9wAqGX/KfurvU/423ECOjRI95RiIhInOWZ2M2sEnAZ8Jm7/wTg7kuAF4o5NonVypXw3//C8OHxjkREROIsz85z7r4VuB/YtfjDkQJ580044QSoVSvekYiISJzF2it+DrBHcQYihfDKK3DBBfGOQkRESoFYE/sdwO2RtnUpTRYsgLlz4fjj4x2JiIiUArH2ir8Z2AX4zsx+BZYSJqpJ5+7eqYhjk1g8+SScfTZUrBjvSEREpBSINbGnAur5Xto88gi89x58oan6RUQkiHW425HFHIfk19NPh9vEifCPf8Q7GhERKSViXrZVSpHXXoMHH4QJE6BJk3hHIyIipUhMid3MOuZ1jLurPrgkTJsGV10Vxq03bx7vaEREpJSJtcQ+gcyd5aIpX7hQJKoXXwzzvnfvDuvWwemnh2VY99UABRERyS7WxH5UlG11gZOATsCVRRaR7LR9O9x4I6SkwHXXQZ060Ls3nHZavCMTEZFSKtbOcxNz2DXWzAYBJwMfFFlUEkyZAo0bw4cfwh9/wDffhBXcREREchDrBDW5GQ+cledRkn/vvQcnnxzu7757KKmXK4qPTEREklVRZIlWQFoRnEeyevddOOmkeEchIiIJJNZe8RdG2VwJaAv0BsYWZVBCmCp2+XI4+OB4RyIiIgkk1s5zw3PYvgV4Hbi6SKKRncaPh65dVfUuIiL5EmtijzZgerO7/1WUwUgG770HffvGOwoREUkwsfaK/624A5EM1q2DyZNh9Oh4RyIiIgkmpnpeMzvJzKKOVTezK8zsxKINq4x75x049FCoUSPekYiISIKJtQH3dqB6DvuqRvZLYbmHhV2uuw769493NCIikoBibWNvDczIYd9M4LaiCacMmz8f7rgDZs0K1fAtWsQ7IhERSUCxltjLAbvksK8GULFowiljUlPhoYegXTs4/HBo2FBJXURECiXWEvv3wPnAW1H2nQ/8UGQRlRWbN0OPHmGs+lNPwWGHQXmtoyMiIoUTa2J/BBhjZm8CzwNLgEZAH+A0oHvxhJek1qwJc743aAAffQSVK8c7IhERSRKxDnd7y8yuBu4FTo9sNmA9cJW7a+a5/Lj2Wthzz7D8qiagERGRIhRriR13f9LMhgOHEZZsXQ5Mcvf1xRRb8po8GUaNUlIXEZEiF3NiB3D3dcBHxRRL2bB+Pfz2G+y9d7wjERGRJBTrBDU3m9mTOex7wsxuLNqwktj330PbtlBRAwlERKToxVoXfDE593yfGdkvsZgxAw48MN5RiIhIkoo1sTcFfslh3wLgn0UTThkwfboSu4iIFJtYE/tGwvC2aBoTlm+VWMyYAQcdFO8oREQkScWa2L8EbjSzTAOuI4+vj+yXvGzaBPPmhTZ2ERGRYhBrr/gBwCTgZzMbAfxOKMH3IAx961kcwSWdH3+EVq00IY2IiBSbWCeo+d7MjgIeBm4mlPTTgK+AM9z9++ILMYmofV1ERIpZzDOkuPtUd+9IWPSlMVDD3Y8EqpvZsGKKL7mofV1ERIpZvqc+c/dNQDWgv5ktBD4HzirqwJKShrqJiEgxizmxm1ktM+tjZl8Bc4FbgVXAZcDuxRRf8ti6FebMgf32i3ckIiKSxHJtYzezcsAJwIXAKUAV4A/gaeAK4Bp3/6K4g0wKs2bBHntAtWrxjkRERJJYjondzB4mrLVeH9hMWIv9JeBToCZwZUkEmDQ++wwOPTTeUYiISJLLrcR+HeDA+0BPd1+RvsPMvLgDSyruMGwYDB4c70hERCTJ5dbGPgxYB3QF5prZU2bWvmTCSjJTpkBqKhxxRLwjERGRJJdjYnf3S4CGhElopgOXApPNbA5hLLtK7bF64QXo1QvM4h2JiIgkuVx7xbv7Znd/1d2PB5oAtwCpQD/AgPvNrIeZVSn+UBPUunUwdixcdFG8IxERkTIgPxPULHX3B9y9LdABeAZoCbwMLI31PGZ2gpnNNbN5ZtYvl+PONDM3s5RYz10qvfEGdOoEDRvGOxIRESkD8j1BDYC7f+vuVxLGr58JTIzleWZWnjBUrguwN3Cume0d5bgawFXANwWJr1R54QXo3TveUYiISBlRoMSezt23uftYdz81xqe0B+a5+wJ33wqMArpFOe4/wIOEYXaJ63//g19/hS5d4h2JiIiUEYVK7AXQCFic4fESsqzzbmYHAE3c/b2SDKxYjBgB550HFWJdRE9ERKRwSjrjROsWvqN3fWSmu0HEsAysmfUB+gA0bdq0iMIrQmlpMHJk6DgnIiJSQkq6xL6E0Ls+XWPCFLXpagBtgQlm9itwCDAuWgc6dx/i7inunlKvXr1iDLmAJk2C6tVh//3jHYmIiJQhJZ3YvwVamllzM6sEnAOMS9/p7mvcfTd3b+buzYApwCnuPq2E4yy8ESOgRw+NXRcRkRJVolXx7r7dzK4EPgLKA8PcfZaZ3Q1Mc/dxuZ8hQWzZAqNHh2VaRURESlCJ9+py9/cJ889n3HZHDsceWRIxFbkPPoC2baE0tv2LiEhSK+mq+LIhvRpeRESkhCmxF7XUVPj0UzjllHhHIiIiZZASe1GbORMaNYL69eMdiYiIlEFK7EVt4sQwN7yIiEgcKLEXNSV2ERGJIyX2opSWBl9+qcQuIiJxo8RelH78EerV0xKtIiISN0rsRUnV8CIiEmdK7EVJiV1EROJMib2ouMMXXyixi4hIXCmxF5XZs6FmTWjcON6RiIhIGabEXlRUDS8iIqWAEntRmToVDj003lGIiEgZp8ReVGbOhAMOiHcUIiJSximxF4UtW+Dnn2GffeIdiYiIlHFK7EVh9mzYYw+oWjXekYiISBmnxF4UvvtO1fAiIlIqKLEXhZkzYf/94x2FiIiIEnuRUIldRERKCSX2wkpLg++/h3bt4h2JiIiIEnuhLVwItWtD3brxjkRERESJvdBUDS8iIqWIEnthqeOciIiUIkrshaUSu4iIlCJK7IWlEruIiJQiSuyF8fffsHEj/POf8Y5EREQEUGIvnOnTQzW8WbwjERERAZTYC2fyZDjkkHhHISIisoMSe2FMngyHHRbvKERERHZQYi+o1FSYOlUldhERKVWU2Atq1ixo2BB22y3ekYiIiOygxF5QqoYXEZFSSIm9oCZNgkMPjXcUIiIimSixF5RK7CIiUgopsRfEsmVhcpq99453JCIiIpkosRfElCnQoQOU09snIiKlizJTQah9XURESikl9oJQ+7qIiJRSSuz5tXJlWKq1Q4d4RyIiIpKNEnt+PfEEnHkm1KoV70hERESyqRDvABLK2rXw9NOhKl5ERKQUUok9P555Bo4/HvbcM96RiIiIRKUSe6w2bIBBg+Dzz+MdiYiISI5UYo/VkCHwr39pUhoRESnVlNhj9cEHcPHF8Y5CREQkV0rssfrjD2jSJN5RiIiI5EqJPVZLl8I//hHvKERERHKlxB6LLVtg3TqoWzfekYiIiORKiT0Wf/4JDRpo0RcRESn1lKlisXQp7L57vKMQERHJkxJ7LNS+LiIiCUKJPRZK7CIikiCU2GPxxx9K7CIikhCU2GOhEruIiCQIJfZYKLGLiEiCUGKPhRK7iIgkCCX2WCixi4hIglBiz8v27bByJdSvH+9IRERE8qTEnpe//gpTyVbQ0vUiIlL6KbHnRdXwIiKSQJTY86LELiIiCaTEE7uZnWBmc81snpn1i7L/OjObbWY/mNlnZvbPko4xEyV2ERFJICWa2M2sPPA00AXYGzjXzPbOcth3QIq77weMBh4syRizUWIXEZEEUtIl9vbAPHdf4O5bgVFAt4wHuPvn7r4x8nAK0LiEY8xMiV1ERBJISSf2RsDiDI+XRLblpDfwQbFGlBcldhERSSAlPYbLomzzqAea9QBSgE457O8D9AFo2rRpUcWX3R9/aC12ERFJGCVdYl8CNMnwuDHwR9aDzOxY4FbgFHffEu1E7j7E3VPcPaVevXrFEiygEruIiCSUkk7s3wItzay5mVUCzgHGZTzAzA4ABhOS+t8lHF9maWnw99/QsGFcwxAREYlViSZ2d98OXAl8BMwB3nD3WWZ2t5mdEjnsIWAX4E0zm2lm43I4XfFbvhxq1oRKleIWgoiISH6U+Dyp7v4+8H6WbXdkuH9sSceUI1XDi4hIgtHMc7lRYhcRkQSjxJ4bJXYREUkwSuy5+fNPdZwTEZGEosSem7//1jrsIiKSUJTYc/P339CgQbyjEBERiZkSe27++ksldhERSShK7LlRiV1ERBKMEntuVGIXEZEEo8Sek9RUWLkSinMeehERkSKmxJ6TlSuhVi2oUOKT84mIiBSYEntOVA0vIiIJSIk9J+o4JyIiCUiJPScqsYuISAJSYs+JSuwiIpKAlNhzoulkRUQkASmx50RV8SIikoCU2HOiqngREUlASuw5UYldREQSkBJ7TlRiFxGRBKTEHo27SuwiIpKQlNij2bABzGCXXeIdiYiISL4osUejoW4iIpKglNijUTW8iIgkKCX2aNRxTkREEpQSezQqsYuISIJSYo9GJXYREUlQSuzRqPOciIgkKCX2aFQVLyIiCUqJPRpVxYuISIJSYo9GJXYREUlQSuzRqMQuIiIJSok9q+3bYc0a2HXXeEciIiKSb0rsWS1bBnXrQvny8Y5EREQk35TYs6pcGQYMiHcUIiIiBaLEntWuu8Kll8Y7ChERkQJRYhcREUkiSuwiIiJJRIldREQkiSixi4iIJBEldhERkSSixC4iIpJElNhFRESSiBK7iIhIElFiFxERSSJK7CIiIklEiV1ERCSJKLGLiIgkESV2ERGRJGLuHu8YCs3MlgG/FeEpdwOWF+H5SpNkvbZkvS5I3mtL1uuC5L22ZL0uSLxr+6e714u2IykSe1Ezs2nunhLvOIpDsl5bsl4XJO+1Jet1QfJeW7JeFyTXtakqXkREJIkosYuIiCQRJfbohsQ7gGKUrNeWrNcFyXttyXpdkLzXlqzXBUl0bWpjFxERSSIqsYuIiCQRJfYszOwEM5trZvPMrF+84ykoM2tiZp+b2Rwzm2VmV0e272pmn5jZL5GfdeIda0GYWXkz+87M3os8bm5m30Su63UzqxTvGAvCzGqb2Wgz+1/kszs0iT6zayO/iz+Z2WtmViURPzczG2Zmf5vZTxm2Rf2MLHgi8v/kBzM7MH6R5y2Ha3so8vv4g5m9ZWa1M+zrH7m2uWZ2fHyizlu068qw7wYzczPbLfI4oT6zaJTYMzCz8sDTQBdgb+BcM9s7vlEV2HbgendvAxwCXBG5ln7AZ+7eEvgs8jgRXQ3MyfD4AWBQ5LpWAb3jElXhPQ586O6tgXaEa0z4z8zMGgFXASnu3hYoD5xDYn5uw4ETsmzL6TPqArSM3PoAz5ZQjAU1nOzX9gnQ1t33A34G+gNE/p+cA+wTec4zkf+hpdFwsl8XZtYEOA5YlGFzon1m2SixZ9YemOfuC9x9KzAK6BbnmArE3Ze6+4zI/XWEBNGIcD0vRQ57CTg1PhEWnJk1BroCL0QeG3A0MDpySKJeV02gIzAUwN23uvtqkuAzi6gAVDWzCkA1YCkJ+Lm5+xfAyiybc/qMugEvezAFqG1m/yiZSPMv2rW5+8fuvj3ycArQOHK/GzDK3be4+0JgHuF/aKmTw2cGMAi4CcjY2SyhPrNolNgzawQszvB4SWRbQjOzZsABwDdAA3dfCiH5A/XjF1mBPUb4Y0yLX0vVTQAABixJREFUPK4LrM7wzydRP7c9gGXAi5FmhhfMrDpJ8Jm5++/Aw4SS0VJgDTCd5PjcIOfPKNn+p/QCPojcT+hrM7NTgN/d/fssuxL6ukCJPSuLsi2hhw2Y2S7AGOAad18b73gKy8xOAv529+kZN0c5NBE/twrAgcCz7n4AsIEErHaPJtLm3A1oDuwOVCdUeWaViJ9bbpLldxMzu5XQxDcyfVOUwxLi2sysGnArcEe03VG2JcR1pVNiz2wJ0CTD48bAH3GKpdDMrCIhqY9097GRzX+lVytFfv4dr/gK6HDgFDP7ldBUcjShBF87UsULifu5LQGWuPs3kcejCYk+0T8zgGOBhe6+zN23AWOBw0iOzw1y/oyS4n+KmV0EnASc7zvHSCfytbUgfMn8PvK/pDEww8waktjXBSixZ/Ut0DLSU7cSoWPIuDjHVCCRduehwBx3fzTDrnHARZH7FwHvlHRsheHu/d29sbs3I3w+/3X384HPgTMjhyXcdQG4+5/AYjNrFdl0DDCbBP/MIhYBh5hZtcjvZvq1JfznFpHTZzQOuDDS0/oQYE16lX2iMLMTgJuBU9x9Y4Zd44BzzKyymTUndDabGo8Y88vdf3T3+u7eLPK/ZAlwYORvMOE/M9xdtww34ERCz8/5wK3xjqcQ13EEofroB2Bm5HYioT36M+CXyM9d4x1rIa7xSOC9yP09CP9U5gFvApXjHV8Br2l/YFrkc3sbqJMsnxlwF/A/4CfgFaByIn5uwGuEfgLbCAmhd06fEaFa9+nI/5MfCaMC4n4N+by2eYQ25/T/I89lOP7WyLXNBbrEO/78XFeW/b8CuyXiZxbtppnnREREkoiq4kVERJKIEruIiEgSUWIXERFJIkrsIiIiSUSJXUREJIkosYskATPrGVmhKtptdZxjG25mS+IZg0hZUiHvQ0QkgXQnjNPNaHu0A0UkOSmxiySXme4+L95BiEj8qCpepAz5//buJ8TKKozj+PdHmxQykGIUtXAhRAjWpohAcaFICeKmLCewRdifRYvSxQQKMljoqkUWRaTOKKEQBf2BIdIK2hQtQqjRiDaTf9Dc1NAYzuPiOddeXu+lmRqIzv19Nu897z3vee/M5rnn3Oc9T2PJfrWk9yX9JumSpNckzWv1XSzpsKSLkqYkfSdpsMuYyyWNSDpX+v0k6dUu/e6V9KWkSUlnJD3den+RpEOSfinjnJX0oaT/XTU7s/+SZ+xmdbmpUVSlYzoiplvnRoFjwAGyhvYusuLaNoBSLvZzckvbIXJL0UFgRNL8iHiz9FtObgk7Cewmt1RdBqxv3W8BcJQs2LMHeBJ4XdJ4RJwofUaAO4Ed5X4D5J7y8//JP8KsXzmwm9Xlhy7nPiIrczV9HBEvltdjkgLYI2lvRJwmA+8KYG1EnCz9PpE0AAxLejsirpL7v88DVkVEswLWodb9bgGe7QRxSV+Qwf8xshAMwAPAUEQcaVx3fEZ/tZld58BuVpfN3Jg81y0r/lir/S4wTM7eTwOrgYlGUO8YBd4B7iYLZKwnC/H8XVnLycbMnIiYknQGuKPR52tgR6n+9hlwKlzMwmzWHNjN6nJqhslz53u0l5TjQrIaVtu5xvuQVc1m8ijb5S7npoCbG+1HyeX8neSS/VlJbwDDXX5KMLMenDxn1p8GerQnyvFXYFGX6zrnLpXjRf76MvCvRMSFiHguIpYAdwEHyaX+7XMxvlm/cGA360+PtNpbgGkyEQ4ycW6ppAdb/R4HLgDfl/YYsFHS4rn8cBExHhFD5Ex/5VyObVY7L8Wb1eUeSbd1Of9NRDQ3qnlI0n4yMN9HLoEfLolzkLPl54H3JL1ELrdvBdYB20viHOW6h4GvJO0FfiRn8Bsi4oZH43qRdCvwKXCETAD8E9hEZuWPzXQcM3NgN6tNryzy28ll845B4AXgGeAK8BbQyZInIn6XtAbYB7xCZrWPA09ExGij38+S7icT714u/SaAD2b5uf8AvgWeIh95my732xoRsx3LrK/JSadm/UPSNjKrfYV3qDOrk39jNzMzq4gDu5mZWUW8FG9mZlYRz9jNzMwq4sBuZmZWEQd2MzOzijiwm5mZVcSB3czMrCIO7GZmZhW5BpfLQMZG5i3kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model_his = model.fit(X_train,y_train,epochs=150)\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(model_his.history['accuracy'],'r',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)\n",
    "print(\"training  model takes %s seconds\" % round((time.time() - start_time),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 55.8 percent\n",
      "testing model takes 0.297 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pred2 = model.predict(X_test)\n",
    "pred_lst2 = [] \n",
    "for i in range(len(pred2)):\n",
    "    arr = pred2[i]\n",
    "    idx = np.argwhere(arr == np.max(arr))\n",
    "    pred_lst2.append(idx[0][0])\n",
    "tst_labl = np.argmax(y_test, axis=-1)\n",
    "acc = accuracy_score(pred_lst2, tst_labl)\n",
    "print(\"Test accuracy is %s percent\" % round(acc*100,3))\n",
    "print(\"testing model takes %s seconds\" % round((time.time() - t0),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization(momentum = 0.88)(input_layer) \n",
    "x = Dense(22*20,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(22*10,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*6,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*2,activation='relu',kernel_initializer=initializers.glorot_normal(seed=4))(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=4))(x) \n",
    "model2 = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 10s 5ms/step - loss: 3.0110 - accuracy: 0.0960\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 2.5602 - accuracy: 0.1985\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 2.3001 - accuracy: 0.2515\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 2.0881 - accuracy: 0.3070\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.9866 - accuracy: 0.3155\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.8342 - accuracy: 0.3795\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7881 - accuracy: 0.3930\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.7087 - accuracy: 0.4295\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.5828 - accuracy: 0.4565\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.5482 - accuracy: 0.4755\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.4927 - accuracy: 0.4840\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 1.4566 - accuracy: 0.5030\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 1.3683 - accuracy: 0.5260\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.3366 - accuracy: 0.5320\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 1.2967 - accuracy: 0.5535\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 1.2782 - accuracy: 0.5700\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.2255 - accuracy: 0.5755\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 1.2125 - accuracy: 0.5895\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 1.1867 - accuracy: 0.6025\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 1.1263 - accuracy: 0.6115\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 1.1141 - accuracy: 0.6255\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 1.0540 - accuracy: 0.6350\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.0806 - accuracy: 0.6270\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.0856 - accuracy: 0.6210\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.9964 - accuracy: 0.6615\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.9821 - accuracy: 0.6535\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.9551 - accuracy: 0.6770\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.9373 - accuracy: 0.6695\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.9046 - accuracy: 0.6870\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8565 - accuracy: 0.7005\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.9005 - accuracy: 0.6845\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.8638 - accuracy: 0.7070\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.8807 - accuracy: 0.6875\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.8116 - accuracy: 0.7145\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8179 - accuracy: 0.7165\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.7587 - accuracy: 0.7270\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.7384 - accuracy: 0.7400\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.7259 - accuracy: 0.7390\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.7234 - accuracy: 0.7550\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.6885 - accuracy: 0.7560\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.7160 - accuracy: 0.7515\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6215 - accuracy: 0.7840\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6708 - accuracy: 0.7680\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6795 - accuracy: 0.7610\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6680 - accuracy: 0.7725\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.7935\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6118 - accuracy: 0.7815\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.6031 - accuracy: 0.8015\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5436 - accuracy: 0.8070\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5591 - accuracy: 0.8085\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5573 - accuracy: 0.8070\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5679 - accuracy: 0.8030\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.5641 - accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.5688 - accuracy: 0.7965\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.5386 - accuracy: 0.7970\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.5232 - accuracy: 0.8180\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.5667 - accuracy: 0.7925\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.5372 - accuracy: 0.8135\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.4869 - accuracy: 0.8280\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5135 - accuracy: 0.8265\n",
      "Epoch 61/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4859 - accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4766 - accuracy: 0.8500\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4203 - accuracy: 0.8560\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4328 - accuracy: 0.8445\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4501 - accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.4440 - accuracy: 0.8510\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.4662 - accuracy: 0.8380\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.4073 - accuracy: 0.8530\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.4056 - accuracy: 0.8580\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4270 - accuracy: 0.8560\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.4228 - accuracy: 0.8570\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.3711 - accuracy: 0.8775\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3473 - accuracy: 0.8720\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3682 - accuracy: 0.8805\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3721 - accuracy: 0.8725\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3564 - accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3899 - accuracy: 0.8665\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3541 - accuracy: 0.8790\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.3585 - accuracy: 0.8775\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.3635 - accuracy: 0.8795\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.3430 - accuracy: 0.8875\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3589 - accuracy: 0.8790\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3594 - accuracy: 0.8785\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3472 - accuracy: 0.8805\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3574 - accuracy: 0.8920\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.3075 - accuracy: 0.8920\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 9s 4ms/step - loss: 0.3164 - accuracy: 0.8890\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.2810 - accuracy: 0.9085\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.3198 - accuracy: 0.8925\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.2660 - accuracy: 0.9090\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.2812 - accuracy: 0.9095\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 7s 4ms/step - loss: 0.2823 - accuracy: 0.9090\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2480 - accuracy: 0.9100\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3366 - accuracy: 0.8975\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 0.3004 - accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2631 - accuracy: 0.9100\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2757 - accuracy: 0.9115\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.2737 - accuracy: 0.9165\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.2669 - accuracy: 0.9080\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.2832 - accuracy: 0.9075\n",
      "training  model takes 668.732 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model2.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model_his = model2.fit(X_train,y_train,epochs=200)\n",
    "print(\"training  model takes %s seconds\" % round((time.time() - start_time),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curves')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(model_his.history['accuracy'],'r',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 52.6 percent\n",
      "testing model takes 0.305 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pred2 = model2.predict(X_test)\n",
    "pred_lst2 = [] \n",
    "for i in range(len(pred2)):\n",
    "    arr = pred2[i]\n",
    "    idx = np.argwhere(arr == np.max(arr))\n",
    "    pred_lst2.append(idx[0][0])\n",
    "tst_labl = np.argmax(y_test, axis=-1)\n",
    "acc = accuracy_score(pred_lst2, tst_labl)\n",
    "print(\"Test accuracy is %s percent\" % round(acc*100,3))\n",
    "print(\"testing model takes %s seconds\" % round((time.time() - t0),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
