{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Predictive analytics: model evaluation and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Set up the environment and Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.io import loadmat\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load():\n",
    "    def load_data(filename):\n",
    "        raw_data = pd.read_csv(filename)\n",
    "        raw_data['filename'] = [str(i).zfill(4)+'.jpg' for i in raw_data['Index'].tolist()]\n",
    "        raw_data['pointsname'] = [str(i).zfill(4)+'.mat' for i in raw_data['Index'].tolist()]\n",
    "        return raw_data\n",
    "\n",
    "    #read points data from mat data\n",
    "    def load_points(points_path,data):\n",
    "        n = data.shape[0]\n",
    "        points_data = np.zeros([n,3003,2])\n",
    "        start_time = time.time()\n",
    "        for i in range(n):\n",
    "            result = loadmat(points_path+data['pointsname'][i])\n",
    "            key = sorted(result.keys())[-1]\n",
    "            points = result[key]\n",
    "            distance_h = []\n",
    "            distance_v = []\n",
    "            for d in range(points.shape[0]-1):\n",
    "                for j in range(d+1,points.shape[0]):\n",
    "                    distance_h.append(abs(points[d,0]-points[j,0]))\n",
    "                    distance_v.append(abs(points[d,1]-points[j,1]))\n",
    "\n",
    "            points_data[i,:,0]=distance_h\n",
    "            points_data[i,:,1]=distance_v\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return points_data.reshape([2500,6006])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> Please modify the path in the following part to get different files.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.732297897338867 seconds ---\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/zhaoziqin/Desktop/train_set/'  # Please modify your own path\n",
    "data = load.load_data(path+'label.csv')\n",
    "points_path = '/Users/zhaoziqin/Desktop/train_set/points/'\n",
    "X = load.load_points(points_path,data)\n",
    "X = np.round(X,0)\n",
    "y= data['emotion_idx'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 6006)\n",
      "(500, 6006)\n",
      "(2000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Baseline Model --- GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Cross-Validation to find the more efficient estimator combination for baseline model and fitted by using this combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 521.2786290645599 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "baseline = GradientBoostingClassifier(n_estimators=100,max_depth= 1,learning_rate=0.1)\n",
    "gbm_model = baseline.fit(train_x,train_y) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the baseline model: 0.8380\n",
      "Testing Accuracy on the baseline model: 0.3820\n",
      "Prediction on Baseline: 0.035868167877197266 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.97      0.91        94\n",
      "           2       0.93      0.99      0.96        95\n",
      "           3       0.80      0.90      0.85       110\n",
      "           4       0.80      0.82      0.81        97\n",
      "           5       0.90      0.95      0.92        91\n",
      "           6       0.81      0.83      0.82        78\n",
      "           7       0.88      0.88      0.88        94\n",
      "           8       0.94      0.95      0.95       104\n",
      "           9       0.91      0.95      0.93        84\n",
      "          10       0.79      0.77      0.78        87\n",
      "          11       0.89      0.82      0.85        99\n",
      "          12       0.85      0.75      0.79        80\n",
      "          13       0.81      0.65      0.72        83\n",
      "          14       0.78      0.90      0.84        99\n",
      "          15       0.86      0.77      0.81        73\n",
      "          16       0.82      0.88      0.85        91\n",
      "          17       0.79      0.83      0.81       101\n",
      "          18       0.90      0.77      0.83        84\n",
      "          19       0.70      0.75      0.73        88\n",
      "          20       0.74      0.74      0.74        95\n",
      "          21       0.86      0.78      0.82        83\n",
      "          22       0.85      0.69      0.76        90\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.83      0.83      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.67      0.51        18\n",
      "           2       0.59      0.68      0.63        19\n",
      "           3       0.24      0.36      0.29        25\n",
      "           4       0.38      0.57      0.45        21\n",
      "           5       0.48      0.56      0.51        18\n",
      "           6       0.47      0.35      0.40        26\n",
      "           7       0.42      0.55      0.48        20\n",
      "           8       0.67      0.62      0.65        16\n",
      "           9       0.73      0.44      0.55        25\n",
      "          10       0.44      0.35      0.39        20\n",
      "          11       0.48      0.54      0.51        24\n",
      "          12       0.32      0.22      0.26        32\n",
      "          13       0.24      0.21      0.22        24\n",
      "          14       0.43      0.52      0.47        23\n",
      "          15       0.31      0.23      0.26        22\n",
      "          16       0.55      0.50      0.52        22\n",
      "          17       0.24      0.27      0.25        26\n",
      "          18       0.25      0.23      0.24        22\n",
      "          19       0.27      0.43      0.33        23\n",
      "          20       0.20      0.20      0.20        20\n",
      "          21       0.33      0.21      0.25        34\n",
      "          22       0.17      0.05      0.08        20\n",
      "\n",
      "    accuracy                           0.38       500\n",
      "   macro avg       0.39      0.40      0.38       500\n",
      "weighted avg       0.39      0.38      0.37       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_train_accuracy = gbm_model.score(train_x,train_y)\n",
    "baseline_test_accuracy = gbm_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the baseline model: %.4f\" % (baseline_train_accuracy))\n",
    "print(\"Testing Accuracy on the baseline model: %.4f\" % (baseline_test_accuracy))\n",
    "\n",
    "baseline_pred_train = gbm_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "baseline_pred_test = gbm_model.predict(test_x)\n",
    "print(\"Prediction on Baseline: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, baseline_pred_train))\n",
    "print(classification_report(test_y, baseline_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6a372890>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_baseline = confusion_matrix(test_y,baseline_pred_test)\n",
    "sns.heatmap(cm_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Candidate Advanced Model --- Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our advanced model, we chose different models to fit the train dataset. Here is the following models we picked as our candidate advanced models firstly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. XGBoost\n",
    " 2. Logistic Regression\n",
    " 3. Support Vector Machine (SVM)\n",
    " 4. LDA\n",
    " 5. Random Forest\n",
    " \n",
    "For each of these models, We have different python files for each model which contains the completed process. In each of model, we used Cross-Validation to find the best parameter combination and fit the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We used  GridSearch cross-validation to find the best parameter combination.\n",
    "'max_depth': range (1, 5, 1)\n",
    "\n",
    "'n_estimators': range(1, 200, 20)\n",
    "\n",
    "'learning_rate': [0.1, 0.01, 0.05]\n",
    "\n",
    "Results: Best Max Depth: 2 / Best N.estimators: 181 / Best Learning Rate: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1987.00168800354 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xgb = XGBClassifier(n_estimators = 181,max_depth=2,learning_rate=0.1)\n",
    "xgb_model = xgb.fit(train_x,train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the xgb model: 1.0000\n",
      "Testing Accuracy on the xgb model: 0.4920\n",
      "Prediction on XGBoost: 1.1762139797210693 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        94\n",
      "           2       1.00      1.00      1.00        95\n",
      "           3       1.00      1.00      1.00       110\n",
      "           4       1.00      1.00      1.00        97\n",
      "           5       1.00      1.00      1.00        91\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00        94\n",
      "           8       1.00      1.00      1.00       104\n",
      "           9       1.00      1.00      1.00        84\n",
      "          10       1.00      1.00      1.00        87\n",
      "          11       1.00      1.00      1.00        99\n",
      "          12       1.00      1.00      1.00        80\n",
      "          13       1.00      1.00      1.00        83\n",
      "          14       1.00      1.00      1.00        99\n",
      "          15       1.00      1.00      1.00        73\n",
      "          16       1.00      1.00      1.00        91\n",
      "          17       1.00      1.00      1.00       101\n",
      "          18       1.00      1.00      1.00        84\n",
      "          19       1.00      1.00      1.00        88\n",
      "          20       1.00      1.00      1.00        95\n",
      "          21       1.00      1.00      1.00        83\n",
      "          22       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.83      0.68        18\n",
      "           2       0.63      0.63      0.63        19\n",
      "           3       0.46      0.52      0.49        25\n",
      "           4       0.44      0.52      0.48        21\n",
      "           5       0.50      0.61      0.55        18\n",
      "           6       0.73      0.42      0.54        26\n",
      "           7       0.47      0.40      0.43        20\n",
      "           8       0.75      0.75      0.75        16\n",
      "           9       0.68      0.52      0.59        25\n",
      "          10       0.55      0.60      0.57        20\n",
      "          11       0.52      0.58      0.55        24\n",
      "          12       0.43      0.41      0.42        32\n",
      "          13       0.29      0.29      0.29        24\n",
      "          14       0.60      0.65      0.63        23\n",
      "          15       0.56      0.41      0.47        22\n",
      "          16       0.65      0.77      0.71        22\n",
      "          17       0.42      0.50      0.46        26\n",
      "          18       0.50      0.32      0.39        22\n",
      "          19       0.36      0.57      0.44        23\n",
      "          20       0.27      0.35      0.30        20\n",
      "          21       0.46      0.32      0.38        34\n",
      "          22       0.17      0.10      0.12        20\n",
      "\n",
      "    accuracy                           0.49       500\n",
      "   macro avg       0.50      0.50      0.49       500\n",
      "weighted avg       0.50      0.49      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_train_accuracy = xgb_model.score(train_x,train_y)\n",
    "xgb_test_accuracy = xgb_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the xgb model: %.4f\" % (xgb_train_accuracy))\n",
    "print(\"Testing Accuracy on the xgb model: %.4f\" % (xgb_test_accuracy))\n",
    "\n",
    "xgb_pred_train = xgb_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "xgb_pred_test = xgb_model.predict(test_x)\n",
    "print(\"Prediction on XGBoost: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, xgb_pred_train))\n",
    "print(classification_report(test_y, xgb_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We used GridSearchCV to fine the best parameter combination\n",
    "'C': [0.001,0.01, 1, 25,50,100] \n",
    "\n",
    "Result:\n",
    "\n",
    " 'C': 0.01,\n",
    " 'dual': False.\n",
    " 'fit_intercept': True,\n",
    " 'intercept_scaling': 1,\n",
    " 'max_iter': 300,\n",
    " 'multi_class': 'multinomial',\n",
    " 'penalty': 'l2',\n",
    " 'solver': 'lbfgs',\n",
    " 'tol': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.355353116989136 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "lr = LogisticRegression(C=0.01, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, max_iter=300,\n",
    "                   multi_class='multinomial', penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001)\n",
    "lr_model = lr.fit(train_x,train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the logistic regression model: 0.7725\n",
      "Testing Accuracy on the logistic regression model: 0.5140\n",
      "Prediction on Logistic Regression: 0.008421897888183594 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.89      0.87        94\n",
      "           2       0.93      0.94      0.93        95\n",
      "           3       0.83      0.85      0.84       110\n",
      "           4       0.76      0.76      0.76        97\n",
      "           5       0.85      0.89      0.87        91\n",
      "           6       0.77      0.77      0.77        78\n",
      "           7       0.80      0.79      0.80        94\n",
      "           8       0.93      0.95      0.94       104\n",
      "           9       0.92      0.93      0.92        84\n",
      "          10       0.67      0.64      0.66        87\n",
      "          11       0.81      0.81      0.81        99\n",
      "          12       0.68      0.66      0.67        80\n",
      "          13       0.64      0.64      0.64        83\n",
      "          14       0.77      0.83      0.80        99\n",
      "          15       0.71      0.67      0.69        73\n",
      "          16       0.80      0.80      0.80        91\n",
      "          17       0.80      0.77      0.79       101\n",
      "          18       0.70      0.71      0.71        84\n",
      "          19       0.62      0.66      0.64        88\n",
      "          20       0.76      0.64      0.70        95\n",
      "          21       0.67      0.64      0.65        83\n",
      "          22       0.61      0.63      0.62        90\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.77      0.77      0.77      2000\n",
      "weighted avg       0.77      0.77      0.77      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.78      0.67        18\n",
      "           2       0.85      0.58      0.69        19\n",
      "           3       0.55      0.64      0.59        25\n",
      "           4       0.42      0.52      0.47        21\n",
      "           5       0.62      0.89      0.73        18\n",
      "           6       0.48      0.46      0.47        26\n",
      "           7       0.52      0.60      0.56        20\n",
      "           8       0.59      0.81      0.68        16\n",
      "           9       0.90      0.72      0.80        25\n",
      "          10       0.45      0.45      0.45        20\n",
      "          11       0.52      0.50      0.51        24\n",
      "          12       0.44      0.34      0.39        32\n",
      "          13       0.43      0.38      0.40        24\n",
      "          14       0.56      0.65      0.60        23\n",
      "          15       0.55      0.55      0.55        22\n",
      "          16       0.57      0.73      0.64        22\n",
      "          17       0.54      0.54      0.54        26\n",
      "          18       0.64      0.41      0.50        22\n",
      "          19       0.19      0.17      0.18        23\n",
      "          20       0.32      0.35      0.33        20\n",
      "          21       0.52      0.35      0.42        34\n",
      "          22       0.20      0.20      0.20        20\n",
      "\n",
      "    accuracy                           0.51       500\n",
      "   macro avg       0.52      0.53      0.52       500\n",
      "weighted avg       0.52      0.51      0.51       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_train_accuracy = lr_model.score(train_x,train_y)\n",
    "lr_test_accuracy = lr_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the logistic regression model: %.4f\" % (lr_train_accuracy))\n",
    "print(\"Testing Accuracy on the logistic regression model: %.4f\" % (lr_test_accuracy))\n",
    "\n",
    "lr_pred_train = lr_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "lr_pred_test = lr_model.predict(test_x)\n",
    "print(\"Prediction on Logistic Regression: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, lr_pred_train))\n",
    "print(classification_report(test_y, lr_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We used GridSearchCV to find the best parameter combination of SVM.\n",
    "param= {'C': [0.0000001,0.000001,0.00001,0.0001,0.001,0.01,1]}\n",
    "\n",
    "Result: 'C':0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 18.18335795402527 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svc = SVC(kernel= 'linear', random_state = 123, C = 0.00001)\n",
    "svm = svc.fit(train_x,train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the logistic regression model: 0.8145\n",
      "Testing Accuracy on the logistic regression model: 0.4840\n",
      "Prediction on SVM: 5.256656885147095 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.97      0.92        94\n",
      "           2       0.96      0.96      0.96        95\n",
      "           3       0.87      0.82      0.85       110\n",
      "           4       0.75      0.81      0.78        97\n",
      "           5       0.90      0.95      0.92        91\n",
      "           6       0.79      0.78      0.79        78\n",
      "           7       0.87      0.87      0.87        94\n",
      "           8       0.94      0.98      0.96       104\n",
      "           9       0.93      0.95      0.94        84\n",
      "          10       0.70      0.79      0.74        87\n",
      "          11       0.86      0.76      0.81        99\n",
      "          12       0.66      0.71      0.69        80\n",
      "          13       0.65      0.61      0.63        83\n",
      "          14       0.75      0.89      0.81        99\n",
      "          15       0.85      0.71      0.78        73\n",
      "          16       0.89      0.89      0.89        91\n",
      "          17       0.81      0.78      0.79       101\n",
      "          18       0.82      0.74      0.78        84\n",
      "          19       0.69      0.70      0.70        88\n",
      "          20       0.82      0.68      0.75        95\n",
      "          21       0.72      0.78      0.75        83\n",
      "          22       0.78      0.68      0.73        90\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.82      0.81      0.81      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.72      0.65        18\n",
      "           2       0.68      0.68      0.68        19\n",
      "           3       0.40      0.56      0.47        25\n",
      "           4       0.41      0.57      0.48        21\n",
      "           5       0.54      0.83      0.65        18\n",
      "           6       0.50      0.46      0.48        26\n",
      "           7       0.45      0.45      0.45        20\n",
      "           8       0.59      0.62      0.61        16\n",
      "           9       0.78      0.72      0.75        25\n",
      "          10       0.38      0.40      0.39        20\n",
      "          11       0.55      0.46      0.50        24\n",
      "          12       0.54      0.44      0.48        32\n",
      "          13       0.36      0.33      0.35        24\n",
      "          14       0.62      0.70      0.65        23\n",
      "          15       0.65      0.59      0.62        22\n",
      "          16       0.48      0.59      0.53        22\n",
      "          17       0.50      0.46      0.48        26\n",
      "          18       0.37      0.32      0.34        22\n",
      "          19       0.17      0.17      0.17        23\n",
      "          20       0.33      0.30      0.32        20\n",
      "          21       0.52      0.35      0.42        34\n",
      "          22       0.14      0.10      0.12        20\n",
      "\n",
      "    accuracy                           0.48       500\n",
      "   macro avg       0.48      0.49      0.48       500\n",
      "weighted avg       0.48      0.48      0.48       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_train_accuracy = svm.score(train_x,train_y)\n",
    "svm_test_accuracy = svm.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the logistic regression model: %.4f\" % (svm_train_accuracy))\n",
    "print(\"Testing Accuracy on the logistic regression model: %.4f\" % (svm_test_accuracy))\n",
    "\n",
    "svm_pred_train = svm.predict(train_x)\n",
    "t1 = time.time()\n",
    "svm_pred_test = svm.predict(test_x)\n",
    "print(\"Prediction on SVM: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, svm_pred_train))\n",
    "print(classification_report(test_y, svm_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 68.76783013343811 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lda = LDA(solver='eigen', shrinkage=.1, n_components=2)\n",
    "lda_model = lda.fit(train_x, train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the LDA model: 0.8580\n",
      "Testing Accuracy on the LDA model: 0.5380\n",
      "Prediction on LDA: 0.007727146148681641 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.99      0.95        94\n",
      "           2       0.93      0.96      0.94        95\n",
      "           3       0.87      0.89      0.88       110\n",
      "           4       0.86      0.84      0.85        97\n",
      "           5       0.96      0.90      0.93        91\n",
      "           6       0.84      0.82      0.83        78\n",
      "           7       0.90      0.87      0.89        94\n",
      "           8       0.95      0.92      0.94       104\n",
      "           9       0.94      0.96      0.95        84\n",
      "          10       0.75      0.86      0.80        87\n",
      "          11       0.96      0.70      0.81        99\n",
      "          12       0.79      0.82      0.80        80\n",
      "          13       0.75      0.81      0.78        83\n",
      "          14       0.84      0.86      0.85        99\n",
      "          15       0.88      0.77      0.82        73\n",
      "          16       0.95      0.84      0.89        91\n",
      "          17       0.89      0.81      0.85       101\n",
      "          18       0.81      0.88      0.85        84\n",
      "          19       0.74      0.89      0.81        88\n",
      "          20       0.86      0.77      0.81        95\n",
      "          21       0.78      0.88      0.83        83\n",
      "          22       0.76      0.82      0.79        90\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.94      0.74        18\n",
      "           2       0.79      0.58      0.67        19\n",
      "           3       0.58      0.60      0.59        25\n",
      "           4       0.50      0.57      0.53        21\n",
      "           5       0.85      0.61      0.71        18\n",
      "           6       0.64      0.54      0.58        26\n",
      "           7       0.60      0.60      0.60        20\n",
      "           8       0.68      0.81      0.74        16\n",
      "           9       0.79      0.88      0.83        25\n",
      "          10       0.60      0.60      0.60        20\n",
      "          11       0.77      0.42      0.54        24\n",
      "          12       0.43      0.50      0.46        32\n",
      "          13       0.37      0.46      0.41        24\n",
      "          14       0.54      0.57      0.55        23\n",
      "          15       0.52      0.50      0.51        22\n",
      "          16       0.73      0.73      0.73        22\n",
      "          17       0.55      0.46      0.50        26\n",
      "          18       0.50      0.45      0.48        22\n",
      "          19       0.25      0.35      0.29        23\n",
      "          20       0.33      0.40      0.36        20\n",
      "          21       0.52      0.35      0.42        34\n",
      "          22       0.17      0.15      0.16        20\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.56      0.55      0.55       500\n",
      "weighted avg       0.55      0.54      0.54       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_train_accuracy = lda_model.score(train_x,train_y)\n",
    "lda_test_accuracy = lda_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the LDA model: %.4f\" % (lda_train_accuracy))\n",
    "print(\"Testing Accuracy on the LDA model: %.4f\" % (lda_test_accuracy))\n",
    "\n",
    "lda_pred_train = lda_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "lda_pred_test = lda_model.predict(test_x)\n",
    "print(\"Prediction on LDA: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, lda_pred_train))\n",
    "print(classification_report(test_y, lda_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7.890650987625122 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_leaf=1, max_features='sqrt')\n",
    "rf_model = rf.fit(train_x, train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the random forest model: 1.0000\n",
      "Testing Accuracy on the random forest model: 0.4040\n",
      "Prediction on Random Forest: 0.040242910385131836 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        94\n",
      "           2       1.00      1.00      1.00        95\n",
      "           3       1.00      1.00      1.00       110\n",
      "           4       1.00      1.00      1.00        97\n",
      "           5       1.00      1.00      1.00        91\n",
      "           6       1.00      1.00      1.00        78\n",
      "           7       1.00      1.00      1.00        94\n",
      "           8       1.00      1.00      1.00       104\n",
      "           9       1.00      1.00      1.00        84\n",
      "          10       1.00      1.00      1.00        87\n",
      "          11       1.00      1.00      1.00        99\n",
      "          12       1.00      1.00      1.00        80\n",
      "          13       1.00      1.00      1.00        83\n",
      "          14       1.00      1.00      1.00        99\n",
      "          15       1.00      1.00      1.00        73\n",
      "          16       1.00      1.00      1.00        91\n",
      "          17       1.00      1.00      1.00       101\n",
      "          18       1.00      1.00      1.00        84\n",
      "          19       1.00      1.00      1.00        88\n",
      "          20       1.00      1.00      1.00        95\n",
      "          21       1.00      1.00      1.00        83\n",
      "          22       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.50      0.40        18\n",
      "           2       0.58      0.74      0.65        19\n",
      "           3       0.28      0.48      0.35        25\n",
      "           4       0.37      0.62      0.46        21\n",
      "           5       0.50      0.67      0.57        18\n",
      "           6       0.60      0.35      0.44        26\n",
      "           7       0.28      0.25      0.26        20\n",
      "           8       0.50      0.81      0.62        16\n",
      "           9       0.70      0.56      0.62        25\n",
      "          10       0.43      0.30      0.35        20\n",
      "          11       0.42      0.58      0.49        24\n",
      "          12       0.40      0.31      0.35        32\n",
      "          13       0.24      0.17      0.20        24\n",
      "          14       0.34      0.61      0.44        23\n",
      "          15       0.36      0.23      0.28        22\n",
      "          16       0.70      0.64      0.67        22\n",
      "          17       0.44      0.42      0.43        26\n",
      "          18       0.39      0.32      0.35        22\n",
      "          19       0.24      0.17      0.20        23\n",
      "          20       0.20      0.15      0.17        20\n",
      "          21       0.33      0.24      0.28        34\n",
      "          22       0.20      0.05      0.08        20\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.40      0.42      0.39       500\n",
      "weighted avg       0.40      0.40      0.39       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_train_accuracy = rf_model.score(train_x,train_y)\n",
    "rf_test_accuracy = rf_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the random forest model: %.4f\" % (rf_train_accuracy))\n",
    "print(\"Testing Accuracy on the random forest model: %.4f\" % (rf_test_accuracy))\n",
    "\n",
    "rf_pred_train = rf_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "rf_pred_test = rf_model.predict(test_x)\n",
    "print(\"Prediction on Random Forest: %s seconds\" % (time.time() - t1))\n",
    "\n",
    "print(classification_report(train_y, rf_pred_train))\n",
    "print(classification_report(test_y, rf_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: \n",
    "## Ensemle with VotingClassifier : Combining the effective models to get the better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From our candidate advanced models 1-5, summary is in the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Model</th>\n",
       "      <th>Training Accuracy(%)</th>\n",
       "      <th>Testing Accuracy(%)</th>\n",
       "      <th>Fitting Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Baseline(GBM)</td>\n",
       "      <td>83.8</td>\n",
       "      <td>38.2</td>\n",
       "      <td>521s</td>\n",
       "      <td>0.036s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>100</td>\n",
       "      <td>49.2</td>\n",
       "      <td>1987s</td>\n",
       "      <td>1.18s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>77.25</td>\n",
       "      <td>51.4</td>\n",
       "      <td>15s</td>\n",
       "      <td>0.0084s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LDA</td>\n",
       "      <td>85.8</td>\n",
       "      <td>53.8</td>\n",
       "      <td>68.77s</td>\n",
       "      <td>0.0077s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>SVM</td>\n",
       "      <td>81.45</td>\n",
       "      <td>48.4</td>\n",
       "      <td>18.18s</td>\n",
       "      <td>5.26s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>100</td>\n",
       "      <td>40.4</td>\n",
       "      <td>7.9s</td>\n",
       "      <td>0.04s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Candidate Model Training Accuracy(%) Testing Accuracy(%) Fitting Time  \\\n",
       "1        Baseline(GBM)                 83.8                38.2         521s   \n",
       "2              XGBoost                  100                49.2        1987s   \n",
       "3  Logistic Regression                77.25                51.4          15s   \n",
       "4                  LDA                 85.8                53.8       68.77s   \n",
       "5                  SVM                81.45                48.4       18.18s   \n",
       "6        Random Forest                  100                40.4         7.9s   \n",
       "\n",
       "  Prediction Time  \n",
       "1          0.036s  \n",
       "2           1.18s  \n",
       "3         0.0084s  \n",
       "4         0.0077s  \n",
       "5           5.26s  \n",
       "6           0.04s  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = {'Candidate Model':['Baseline(GBM)', 'XGBoost', 'Logistic Regression', 'LDA','SVM','Random Forest'],\n",
    "         'Training Accuracy(%)':['83.8','100','77.25','85.8','81.45','100'],\n",
    "        'Testing Accuracy(%)':['38.2','49.2','51.4','53.8','48.4','40.4'],\n",
    "         'Fitting Time':['521s','1987s','15s','68.77s','18.18s','7.9s'],\n",
    "         'Prediction Time':['0.036s','1.18s','0.0084s','0.0077s','5.26s','0.04s']\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(chart,index = ['1','2','3','4','5','6'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to combine the effiective models showing above and to do a ensemble prediction. \n",
    "\n",
    "From all the candidate models, XGBoost, Logistic Regression, LDA and SVM have the higher testing accuracy. \n",
    "At the same time, XGBoost has the longer fitting time, so we did not pick XGBoost in our ensemble model.\n",
    "\n",
    "#### Ensemble : Logistic Regression, LDA and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 105.66939377784729 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('lda', lda), ('svm', svc)], \n",
    "    voting='hard',\n",
    "    weights=[1.5,1.5,1])\n",
    "eclf_model = eclf.fit(train_x, train_y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on the Ensemle model: 0.8405\n",
      "Testing Accuracy on the Ensemle model: 0.5460\n",
      "Prediction on Ensemle model: 6.695195913314819 seconds\n"
     ]
    }
   ],
   "source": [
    "eclf_train_accuracy = eclf_model.score(train_x,train_y)\n",
    "eclf_test_accuracy = eclf_model.score(test_x,test_y)\n",
    "print(\"Training Accuracy on the Ensemle model: %.4f\" % (eclf_train_accuracy))\n",
    "print(\"Testing Accuracy on the Ensemle model: %.4f\" % (eclf_test_accuracy))\n",
    "\n",
    "eclf_pred_train = eclf_model.predict(train_x)\n",
    "t1 = time.time()\n",
    "eclf_pred_test = eclf_model.predict(test_x)\n",
    "print(\"Prediction on Ensemle model: %s seconds\" % (time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a6b41ecd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_eclf = confusion_matrix(test_y,eclf_pred_test)\n",
    "sns.heatmap(cm_eclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Candidate Advanced Model --- Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of this model, install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)\n",
    "Y = Y[:,1:]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=1106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization(momentum = 0.88)(input_layer) \n",
    "x = Dense(22*10,activation='relu',kernel_initializer=initializers.glorot_normal(seed=6))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(22*8,activation='relu',kernel_initializer=initializers.glorot_normal(seed=6))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*4,activation='relu',kernel_initializer=initializers.glorot_normal(seed=6))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(22*2,activation='relu',kernel_initializer=initializers.glorot_normal(seed=6))(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=6))(x) \n",
    "model = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 13s 7ms/step - loss: 3.0633 - accuracy: 0.0810\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 2.6660 - accuracy: 0.1675\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 2.3384 - accuracy: 0.2355\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 2.0736 - accuracy: 0.2975\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.9892 - accuracy: 0.3215\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.9165 - accuracy: 0.3560\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.8152 - accuracy: 0.3890\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.7222 - accuracy: 0.4080\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.6400 - accuracy: 0.4460\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.5659 - accuracy: 0.4580\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.5425 - accuracy: 0.4740\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.4849 - accuracy: 0.5185\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.5087 - accuracy: 0.4995\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.4253 - accuracy: 0.5090\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.3252 - accuracy: 0.5420\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.2972 - accuracy: 0.5415\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.3197 - accuracy: 0.5390\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.2730 - accuracy: 0.5715\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.2335 - accuracy: 0.5775\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.2682 - accuracy: 0.5705\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.2016 - accuracy: 0.5820\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.1991 - accuracy: 0.5925\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.1825 - accuracy: 0.5850\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.1577 - accuracy: 0.6025\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 1.1052 - accuracy: 0.6060\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.1006 - accuracy: 0.6155\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.0746 - accuracy: 0.6210\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.0151 - accuracy: 0.6495\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 1.0177 - accuracy: 0.6625\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.0138 - accuracy: 0.6285\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 1.0096 - accuracy: 0.6395\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.9808 - accuracy: 0.6665\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.9250 - accuracy: 0.6705\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.9543 - accuracy: 0.6835\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8726 - accuracy: 0.6750\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8966 - accuracy: 0.6900\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8459 - accuracy: 0.7060\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.8626 - accuracy: 0.7080\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.8312 - accuracy: 0.7180\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.8822 - accuracy: 0.6950\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.8222 - accuracy: 0.7165\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.8104 - accuracy: 0.7305\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.8174 - accuracy: 0.7245\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.7686 - accuracy: 0.7330\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.7558 - accuracy: 0.7385\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.7978 - accuracy: 0.7360\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.8111 - accuracy: 0.7205\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.7725 - accuracy: 0.7440\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.6954 - accuracy: 0.7675\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.7420 - accuracy: 0.7465\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.7064 - accuracy: 0.7545\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6867 - accuracy: 0.7590\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6621 - accuracy: 0.7670\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.6256 - accuracy: 0.7830\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6641 - accuracy: 0.7745\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6493 - accuracy: 0.7765\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.6522 - accuracy: 0.7835\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6467 - accuracy: 0.7725\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5927 - accuracy: 0.7945\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.6282 - accuracy: 0.7905\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 7s 3ms/step - loss: 0.6012 - accuracy: 0.7940\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.5530 - accuracy: 0.8050\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5530 - accuracy: 0.8085\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5850 - accuracy: 0.8080\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5669 - accuracy: 0.7975\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5633 - accuracy: 0.8185\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5502 - accuracy: 0.8140\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5834 - accuracy: 0.8130\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5290 - accuracy: 0.8190\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.5299 - accuracy: 0.8260\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4845 - accuracy: 0.8405\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.5172 - accuracy: 0.8275\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4811 - accuracy: 0.8340\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.4462 - accuracy: 0.8515\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4525 - accuracy: 0.8470: 0s - loss: 0.4451 - ac\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4833 - accuracy: 0.8395\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.5088 - accuracy: 0.8340\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4279 - accuracy: 0.8585\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4273 - accuracy: 0.8550\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4504 - accuracy: 0.8560\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4352 - accuracy: 0.8560\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4441 - accuracy: 0.8535\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.4346 - accuracy: 0.8435\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.4096 - accuracy: 0.8585\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4191 - accuracy: 0.8555\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.4718 - accuracy: 0.8555\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.4168 - accuracy: 0.8625\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3947 - accuracy: 0.8710\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4376 - accuracy: 0.8470\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.4060 - accuracy: 0.8625\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3644 - accuracy: 0.8740\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3602 - accuracy: 0.8835\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3759 - accuracy: 0.8750\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.4130 - accuracy: 0.8705\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3903 - accuracy: 0.8740\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.3986 - accuracy: 0.8630\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.3403 - accuracy: 0.8835\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3576 - accuracy: 0.8810\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3767 - accuracy: 0.8795\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3279 - accuracy: 0.8930\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3392 - accuracy: 0.8920: 1s -\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3373 - accuracy: 0.8820\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3063 - accuracy: 0.9015\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.3507 - accuracy: 0.8785\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2996 - accuracy: 0.8980\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3497 - accuracy: 0.8830\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3151 - accuracy: 0.8975\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3488 - accuracy: 0.8900\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3158 - accuracy: 0.8940\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.3093 - accuracy: 0.8975\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3169 - accuracy: 0.9005\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.3092 - accuracy: 0.8805\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3090 - accuracy: 0.9010\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3164 - accuracy: 0.8965\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3144 - accuracy: 0.9000\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3072 - accuracy: 0.9070\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2904 - accuracy: 0.9025\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3241 - accuracy: 0.8930\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.3083 - accuracy: 0.9020\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3415 - accuracy: 0.8905\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2848 - accuracy: 0.9015\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.3013 - accuracy: 0.9055\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2976 - accuracy: 0.8980\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2593 - accuracy: 0.9140\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2767 - accuracy: 0.9130\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2259 - accuracy: 0.9305\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.2474 - accuracy: 0.9235\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2548 - accuracy: 0.9155\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2720 - accuracy: 0.9110\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2665 - accuracy: 0.9115\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2892 - accuracy: 0.9115\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2753 - accuracy: 0.9115\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2732 - accuracy: 0.9150\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2213 - accuracy: 0.9235\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2576 - accuracy: 0.9190\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2563 - accuracy: 0.9130\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2771 - accuracy: 0.9140\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2263 - accuracy: 0.9315\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2332 - accuracy: 0.9245\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2335 - accuracy: 0.9260\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2377 - accuracy: 0.9185\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2516 - accuracy: 0.9120\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2652 - accuracy: 0.9155\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2652 - accuracy: 0.9145: 0s - los\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2526 - accuracy: 0.9170\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2322 - accuracy: 0.9210\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2570 - accuracy: 0.9195\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2629 - accuracy: 0.9115\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2233 - accuracy: 0.9315\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2410 - accuracy: 0.9160\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2385 - accuracy: 0.9180\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2144 - accuracy: 0.9365\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2090 - accuracy: 0.9345\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2354 - accuracy: 0.9215\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2312 - accuracy: 0.9260\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2315 - accuracy: 0.9270\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2133 - accuracy: 0.9215\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2442 - accuracy: 0.9215\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2293 - accuracy: 0.9255\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2144 - accuracy: 0.9325\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2005 - accuracy: 0.9345\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2006 - accuracy: 0.9365\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1952 - accuracy: 0.9380\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2049 - accuracy: 0.9375\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2096 - accuracy: 0.9365\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2011 - accuracy: 0.9345\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2099 - accuracy: 0.9365\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2029 - accuracy: 0.9295\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2311 - accuracy: 0.9260\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9275\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1909 - accuracy: 0.9420\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2100 - accuracy: 0.9350\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1795 - accuracy: 0.9480\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2020 - accuracy: 0.9360\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.2349 - accuracy: 0.9280\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2011 - accuracy: 0.9330\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2191 - accuracy: 0.9370\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2035 - accuracy: 0.9340\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9350\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.1923 - accuracy: 0.9390\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1991 - accuracy: 0.9345\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1674 - accuracy: 0.9465\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2230 - accuracy: 0.9290\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1648 - accuracy: 0.9465\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1801 - accuracy: 0.9470\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1503 - accuracy: 0.9520\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 5s 3ms/step - loss: 0.1833 - accuracy: 0.9420\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1616 - accuracy: 0.9495\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.2174 - accuracy: 0.9315\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1907 - accuracy: 0.9390\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1757 - accuracy: 0.9495\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1732 - accuracy: 0.9435: 1s\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.2112 - accuracy: 0.9340\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1828 - accuracy: 0.9425\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.1778 - accuracy: 0.9435\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1628 - accuracy: 0.9550\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1635 - accuracy: 0.9470\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1810 - accuracy: 0.9400\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1693 - accuracy: 0.9460\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1614 - accuracy: 0.9465\n",
      "--- 993.6481537818909 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model_nn = model.fit(X_train,y_train,epochs=200)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curves')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(model_nn.history['accuracy'],'r',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 54.6 percent\n",
      "testing model takes 0.35124802589416504 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pred = model.predict(X_test)\n",
    "pred_list = [] \n",
    "for i in range(len(pred)):\n",
    "    arr = pred[i]\n",
    "    idx = np.argwhere(arr == np.max(arr))\n",
    "    pred_list.append(idx[0][0])\n",
    "tst_labl = np.argmax(y_test, axis=-1)\n",
    "accuracy = accuracy_score(pred_list, tst_labl)\n",
    "print(\"Test accuracy is %s percent\" % round(accuracy*100,3))\n",
    "print(\"testing model takes %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing : Ensemble Model VS Neutral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Model</th>\n",
       "      <th>Testing Accuracy(%)</th>\n",
       "      <th>Fitting Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ensemble Model</td>\n",
       "      <td>54.6</td>\n",
       "      <td>106s</td>\n",
       "      <td>6.7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Neutral Network</td>\n",
       "      <td>55</td>\n",
       "      <td>994s</td>\n",
       "      <td>0.35s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Candidate Model Testing Accuracy(%) Fitting Time Prediction Time\n",
       "1   Ensemble Model                54.6         106s            6.7s\n",
       "2  Neutral Network                  55         994s           0.35s"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = {'Candidate Model':['Ensemble Model','Neutral Network'],\n",
    "        'Testing Accuracy(%)':['54.6','55'],\n",
    "         'Fitting Time':['106s','994s'],\n",
    "         'Prediction Time':['6.7s','0.35s']}\n",
    "df_c = pd.DataFrame(compare,index = ['1','2'])\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/eclf.m']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save ensemble model\n",
    "joblib.dump(eclf,'../output/eclf.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/nn.m']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save nn model\n",
    "joblib.dump(model_nn,'../output/nn.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Advanced Model (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
